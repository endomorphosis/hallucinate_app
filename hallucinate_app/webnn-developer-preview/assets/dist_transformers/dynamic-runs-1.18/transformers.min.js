var e,t,n={"?2ce3":
/*!**********************************!*\
  !*** onnxruntime-node (ignored) ***!
  \**********************************/()=>{},"?7a2c":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/()=>{},"?a42a":
/*!**********************!*\
  !*** path (ignored) ***!
  \**********************/()=>{},"?2b25":
/*!***********************!*\
  !*** sharp (ignored) ***!
  \***********************/()=>{},"?569f":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/()=>{},"?3f59":
/*!**********************!*\
  !*** path (ignored) ***!
  \**********************/()=>{},"?154a":
/*!*********************!*\
  !*** url (ignored) ***!
  \*********************/()=>{},"./node_modules/@huggingface/jinja/dist/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/@huggingface/jinja/dist/index.js ***!
  \*******************************************************/(e,t,n)=>{n.r(t),n.d(t,{Environment:()=>H,Interpreter:()=>X,Template:()=>K,parse:()=>I,tokenize:()=>u});var r=Object.freeze({Text:"Text",NumericLiteral:"NumericLiteral",BooleanLiteral:"BooleanLiteral",StringLiteral:"StringLiteral",Identifier:"Identifier",Equals:"Equals",OpenParen:"OpenParen",CloseParen:"CloseParen",OpenStatement:"OpenStatement",CloseStatement:"CloseStatement",OpenExpression:"OpenExpression",CloseExpression:"CloseExpression",OpenSquareBracket:"OpenSquareBracket",CloseSquareBracket:"CloseSquareBracket",OpenCurlyBracket:"OpenCurlyBracket",CloseCurlyBracket:"CloseCurlyBracket",Comma:"Comma",Dot:"Dot",Colon:"Colon",Pipe:"Pipe",CallOperator:"CallOperator",AdditiveBinaryOperator:"AdditiveBinaryOperator",MultiplicativeBinaryOperator:"MultiplicativeBinaryOperator",ComparisonBinaryOperator:"ComparisonBinaryOperator",UnaryOperator:"UnaryOperator",Set:"Set",If:"If",For:"For",In:"In",Is:"Is",NotIn:"NotIn",Else:"Else",EndIf:"EndIf",ElseIf:"ElseIf",EndFor:"EndFor",And:"And",Or:"Or",Not:"UnaryOperator"}),i=Object.freeze({set:r.Set,for:r.For,in:r.In,is:r.Is,if:r.If,else:r.Else,endif:r.EndIf,elif:r.ElseIf,endfor:r.EndFor,and:r.And,or:r.Or,not:r.Not,"not in":r.NotIn,true:r.BooleanLiteral,false:r.BooleanLiteral}),s=class{constructor(e,t){this.value=e,this.type=t}};function o(e){return/\w/.test(e)}function a(e){return/[0-9]/.test(e)}var l=[["{%",r.OpenStatement],["%}",r.CloseStatement],["{{",r.OpenExpression],["}}",r.CloseExpression],["(",r.OpenParen],[")",r.CloseParen],["{",r.OpenCurlyBracket],["}",r.CloseCurlyBracket],["[",r.OpenSquareBracket],["]",r.CloseSquareBracket],[",",r.Comma],[".",r.Dot],[":",r.Colon],["|",r.Pipe],["<=",r.ComparisonBinaryOperator],[">=",r.ComparisonBinaryOperator],["==",r.ComparisonBinaryOperator],["!=",r.ComparisonBinaryOperator],["<",r.ComparisonBinaryOperator],[">",r.ComparisonBinaryOperator],["+",r.AdditiveBinaryOperator],["-",r.AdditiveBinaryOperator],["*",r.MultiplicativeBinaryOperator],["/",r.MultiplicativeBinaryOperator],["%",r.MultiplicativeBinaryOperator],["=",r.Equals]],d=new Map([["n","\n"],["t","\t"],["r","\r"],["b","\b"],["f","\f"],["v","\v"],["'","'"],['"','"'],["\\","\\"]]);function u(e,t={}){const n=[],u=function(e,t={}){return e.endsWith("\n")&&(e=e.slice(0,-1)),e=e.replace(/{#.*?#}/gs,"{##}"),t.lstrip_blocks&&(e=e.replace(/^[ \t]*({[#%])/gm,"$1")),t.trim_blocks&&(e=e.replace(/([#%]})\n/g,"$1")),e.replace(/{##}/g,"").replace(/-%}\s*/g,"%}").replace(/\s*{%-/g,"{%").replace(/-}}\s*/g,"}}").replace(/\s*{{-/g,"{{")}(e,t);let c=0;const p=e=>{let t="";for(;e(u[c]);)if("\\"!==u[c]){if(t+=u[c++],c>=u.length)throw new SyntaxError("Unexpected end of input")}else{if(++c,c>=u.length)throw new SyntaxError("Unexpected end of input");const e=u[c++],n=d.get(e);if(void 0===n)throw new SyntaxError(`Unexpected escaped character: ${e}`);t+=n}return t};e:for(;c<u.length;){const e=n.at(-1)?.type;if(void 0===e||e===r.CloseStatement||e===r.CloseExpression){let e="";for(;c<u.length&&("{"!==u[c]||"%"!==u[c+1]&&"{"!==u[c+1]);)e+=u[c++];if(e.length>0){n.push(new s(e,r.Text));continue}}p((e=>/\s/.test(e)));const t=u[c];if("-"===t||"+"===t){const e=n.at(-1)?.type;if(e===r.Text||void 0===e)throw new SyntaxError(`Unexpected character: ${t}`);switch(e){case r.Identifier:case r.NumericLiteral:case r.BooleanLiteral:case r.StringLiteral:case r.CloseParen:case r.CloseSquareBracket:break;default:{++c;const e=p(a);n.push(new s(`${t}${e}`,e.length>0?r.NumericLiteral:r.UnaryOperator));continue}}}for(const[e,t]of l){if(u.slice(c,c+e.length)===e){n.push(new s(e,t)),c+=e.length;continue e}}if("'"!==t&&'"'!==t)if(a(t)){const e=p(a);n.push(new s(e,r.NumericLiteral))}else{if(!o(t))throw new SyntaxError(`Unexpected character: ${t}`);{const e=p(o),t=Object.hasOwn(i,e)?i[e]:r.Identifier;t===r.In&&n.at(-1)?.type===r.Not?(n.pop(),n.push(new s("not in",r.NotIn))):n.push(new s(e,t))}}else{++c;const e=p((e=>e!==t));n.push(new s(e,r.StringLiteral)),++c}}return n}var c=class{type="Statement"},p=class extends c{constructor(e){super(),this.body=e}type="Program"},h=class extends c{constructor(e,t,n){super(),this.test=e,this.body=t,this.alternate=n}type="If"},f=class extends c{constructor(e,t,n){super(),this.loopvar=e,this.iterable=t,this.body=n}type="For"},m=class extends c{constructor(e,t){super(),this.assignee=e,this.value=t}type="Set"},g=class extends c{type="Expression"},_=class extends g{constructor(e,t,n){super(),this.object=e,this.property=t,this.computed=n}type="MemberExpression"},w=class extends g{constructor(e,t){super(),this.callee=e,this.args=t}type="CallExpression"},y=class extends g{constructor(e){super(),this.value=e}type="Identifier"},b=class extends g{constructor(e){super(),this.value=e}type="Literal"},v=class extends b{type="NumericLiteral"},x=class extends b{type="StringLiteral"},M=class extends b{type="BooleanLiteral"},T=class extends b{type="ArrayLiteral"},k=class extends b{type="TupleLiteral"},$=class extends b{type="ObjectLiteral"},S=class extends g{constructor(e,t,n){super(),this.operator=e,this.left=t,this.right=n}type="BinaryExpression"},C=class extends g{constructor(e,t){super(),this.operand=e,this.filter=t}type="FilterExpression"},P=class extends g{constructor(e,t,n){super(),this.operand=e,this.negate=t,this.test=n}type="TestExpression"},E=class extends g{constructor(e,t){super(),this.operator=e,this.argument=t}type="UnaryExpression"},A=class extends g{constructor(e=void 0,t=void 0,n=void 0){super(),this.start=e,this.stop=t,this.step=n}type="SliceExpression"},F=class extends g{constructor(e,t){super(),this.key=e,this.value=t}type="KeywordArgumentExpression"};function I(e){const t=new p([]);let n=0;function i(t,r){const i=e[n++];if(!i||i.type!==t)throw new Error(`Parser Error: ${r}. ${i.type} !== ${t}.`);return i}function s(){switch(e[n].type){case r.Text:return new x(i(r.Text,"Expected text token").value);case r.OpenStatement:return function(){let t;switch(i(r.OpenStatement,"Expected opening statement token"),e[n].type){case r.Set:++n,t=l(),i(r.CloseStatement,"Expected closing statement token");break;case r.If:++n,t=d(),i(r.OpenStatement,"Expected {% token"),i(r.EndIf,"Expected endif token"),i(r.CloseStatement,"Expected %} token");break;case r.For:++n,t=function(){const e=u(!0);if(!(e instanceof y||e instanceof k))throw new SyntaxError(`Expected identifier/tuple for the loop variable, got ${e.type} instead`);i(r.In,"Expected `in` keyword following loop variable");const t=c();i(r.CloseStatement,"Expected closing statement token");const n=[];for(;o(r.OpenStatement,r.EndFor);)n.push(s());return new f(e,t,n)}(),i(r.OpenStatement,"Expected {% token"),i(r.EndFor,"Expected endfor token"),i(r.CloseStatement,"Expected %} token");break;default:throw new SyntaxError(`Unknown statement type: ${e[n].type}`)}return t}();case r.OpenExpression:return function(){i(r.OpenExpression,"Expected opening expression token");const e=c();return i(r.CloseExpression,"Expected closing expression token"),e}();default:throw new SyntaxError(`Unexpected token type: ${e[n].type}`)}}function o(...t){return n+t.length<=e.length&&t.some(((t,r)=>t!==e[n+r].type))}function a(...t){return n+t.length<=e.length&&t.every(((t,r)=>t===e[n+r].type))}function l(){const e=c();if(a(r.Equals)){++n;const t=l();return new m(e,t)}return e}function d(){const t=c();i(r.CloseStatement,"Expected closing statement token");const o=[],l=[];for(;e[n]?.type!==r.OpenStatement||e[n+1]?.type!==r.ElseIf&&e[n+1]?.type!==r.Else&&e[n+1]?.type!==r.EndIf;)o.push(s());if(e[n]?.type===r.OpenStatement&&e[n+1]?.type!==r.EndIf)if(++n,a(r.ElseIf))i(r.ElseIf,"Expected elseif token"),l.push(d());else for(i(r.Else,"Expected else token"),i(r.CloseStatement,"Expected closing statement token");e[n]?.type!==r.OpenStatement||e[n+1]?.type!==r.EndIf;)l.push(s());return new h(t,o,l)}function u(e=!1){const t=e?N:c,i=[t()],s=a(r.Comma);for(;s&&(++n,i.push(t()),a(r.Comma)););return s?new k(i):i[0]}function c(){return function(){const e=g();if(a(r.If)){++n;const t=g();i(r.Else,"Expected else token");const s=g();return new h(t,[e],[s])}return e}()}function g(){let t=b();for(;a(r.Or);){const r=e[n];++n;const i=b();t=new S(r,t,i)}return t}function b(){let t=I();for(;a(r.And);){const r=e[n];++n;const i=I();t=new S(r,t,i)}return t}function I(){let t;for(;a(r.Not);){const r=e[n];++n;const i=I();t=new E(r,i)}return t??function(){let t=z();for(;a(r.ComparisonBinaryOperator)||a(r.In)||a(r.NotIn);){const r=e[n];++n;const i=z();t=new S(r,t,i)}return t}()}function z(){let t=D();for(;a(r.AdditiveBinaryOperator);){const r=e[n];++n;const i=D();t=new S(r,t,i)}return t}function B(){const t=function(){let t=N();for(;a(r.Dot)||a(r.OpenSquareBracket);){const s=e[n];let o;++n;const a=s.type!==r.Dot;if(a)o=L(),i(r.CloseSquareBracket,"Expected closing square bracket");else if(o=N(),"Identifier"!==o.type)throw new SyntaxError("Expected identifier following dot operator");t=new _(t,o,a)}return t}();return a(r.OpenParen)?O(t):t}function O(e){let t=new w(e,function(){i(r.OpenParen,"Expected opening parenthesis for arguments list");const e=function(){const e=[];for(;!a(r.CloseParen);){let t=c();if(a(r.Equals)){if(++n,!(t instanceof y))throw new SyntaxError("Expected identifier for keyword argument");const e=c();t=new F(t,e)}e.push(t),a(r.Comma)&&++n}return e}();return i(r.CloseParen,"Expected closing parenthesis for arguments list"),e}());return a(r.OpenParen)&&(t=O(t)),t}function L(){const e=[];let t=!1;for(;!a(r.CloseSquareBracket);)a(r.Colon)?(e.push(void 0),++n,t=!0):(e.push(c()),a(r.Colon)&&(++n,t=!0));if(0===e.length)throw new SyntaxError("Expected at least one argument for member/slice expression");if(t){if(e.length>3)throw new SyntaxError("Expected 0-3 arguments for slice expression");return new A(...e)}return e[0]}function D(){let t=R();for(;a(r.MultiplicativeBinaryOperator);){const r=e[n];++n;const i=R();t=new S(r,t,i)}return t}function R(){let e=function(){let e=B();for(;a(r.Pipe);){++n;let t=N();if(!(t instanceof y))throw new SyntaxError("Expected identifier for the filter");a(r.OpenParen)&&(t=O(t)),e=new C(e,t)}return e}();for(;a(r.Is);){++n;const t=a(r.Not);t&&++n;let i=N();if(i instanceof M&&(i=new y(i.value.toString())),!(i instanceof y))throw new SyntaxError("Expected identifier for the test");e=new P(e,t,i)}return e}function N(){const t=e[n];switch(t.type){case r.NumericLiteral:return++n,new v(Number(t.value));case r.StringLiteral:return++n,new x(t.value);case r.BooleanLiteral:return++n,new M("true"===t.value);case r.Identifier:return++n,new y(t.value);case r.OpenParen:{++n;const t=u();if(e[n].type!==r.CloseParen)throw new SyntaxError(`Expected closing parenthesis, got ${e[n].type} instead`);return++n,t}case r.OpenSquareBracket:{++n;const e=[];for(;!a(r.CloseSquareBracket);)e.push(c()),a(r.Comma)&&++n;return++n,new T(e)}case r.OpenCurlyBracket:{++n;const e=new Map;for(;!a(r.CloseCurlyBracket);){const t=c();i(r.Colon,"Expected colon between key and value in object literal");const s=c();e.set(t,s),a(r.Comma)&&++n}return++n,new $(e)}default:throw new SyntaxError(`Unexpected token: ${t.type}`)}}for(;n<e.length;)t.body.push(s());return t}function z(e,t,n=1){void 0===t&&(t=e,e=0);const r=[];for(let i=e;i<t;i+=n)r.push(i);return r}function B(e,t,n,r=1){const i=Math.sign(r);i>=0?(t=(t??=0)<0?Math.max(e.length+t,0):Math.min(t,e.length),n=(n??=e.length)<0?Math.max(e.length+n,0):Math.min(n,e.length)):(t=(t??=e.length-1)<0?Math.max(e.length+t,-1):Math.min(t,e.length-1),n=(n??=-1)<-1?Math.max(e.length+n,-1):Math.min(n,e.length-1));const s=[];for(let o=t;i*o<i*n;o+=r)s.push(e[o]);return s}function O(e){return e.replace(/\b\w/g,(e=>e.toUpperCase()))}var L=class{type="RuntimeValue";value;builtins=new Map;constructor(e=void 0){this.value=e}__bool__(){return new N(!!this.value)}},D=class extends L{type="NumericValue"},R=class extends L{type="StringValue";builtins=new Map([["upper",new G((()=>new R(this.value.toUpperCase())))],["lower",new G((()=>new R(this.value.toLowerCase())))],["strip",new G((()=>new R(this.value.trim())))],["title",new G((()=>new R(O(this.value))))],["length",new D(this.value.length)]])},N=class extends L{type="BooleanValue"},V=class extends L{type="ObjectValue";__bool__(){return new N(this.value.size>0)}builtins=new Map([["get",new G((([e,t])=>{if(!(e instanceof R))throw new Error(`Object key must be a string: got ${e.type}`);return this.value.get(e.value)??t??new q}))],["items",new G((()=>new j(Array.from(this.value.entries()).map((([e,t])=>new j([new R(e),t]))))))]])},j=class extends L{type="ArrayValue";builtins=new Map([["length",new D(this.value.length)]]);__bool__(){return new N(this.value.length>0)}},U=class extends j{type="TupleValue"},G=class extends L{type="FunctionValue"},q=class extends L{type="NullValue"},W=class extends L{type="UndefinedValue"},H=class{constructor(e){this.parent=e}variables=new Map([["namespace",new G((e=>{if(0===e.length)return new V(new Map);if(1!==e.length||!(e[0]instanceof V))throw new Error("`namespace` expects either zero arguments or a single object argument");return e[0]}))]]);tests=new Map([["boolean",e=>"BooleanValue"===e.type],["callable",e=>e instanceof G],["odd",e=>{if("NumericValue"!==e.type)throw new Error(`Cannot apply test "odd" to type: ${e.type}`);return e.value%2!=0}],["even",e=>{if("NumericValue"!==e.type)throw new Error(`Cannot apply test "even" to type: ${e.type}`);return e.value%2==0}],["false",e=>"BooleanValue"===e.type&&!e.value],["true",e=>"BooleanValue"===e.type&&e.value],["number",e=>"NumericValue"===e.type],["integer",e=>"NumericValue"===e.type&&Number.isInteger(e.value)],["iterable",e=>e instanceof j||e instanceof R],["lower",e=>{const t=e.value;return"StringValue"===e.type&&t===t.toLowerCase()}],["upper",e=>{const t=e.value;return"StringValue"===e.type&&t===t.toUpperCase()}],["none",e=>"NullValue"===e.type],["defined",e=>"UndefinedValue"!==e.type],["undefined",e=>"UndefinedValue"===e.type],["equalto",(e,t)=>e.value===t.value]]);set(e,t){return this.declareVariable(e,Q(t))}declareVariable(e,t){if(this.variables.has(e))throw new SyntaxError(`Variable already declared: ${e}`);return this.variables.set(e,t),t}setVariable(e,t){return this.variables.set(e,t),t}resolve(e){if(this.variables.has(e))return this;if(this.parent)return this.parent.resolve(e);throw new Error(`Unknown variable: ${e}`)}lookupVariable(e){try{return this.resolve(e).variables.get(e)??new W}catch{return new W}}},X=class{global;constructor(e){this.global=e??new H}run(e){return this.evaluate(e,this.global)}evaluateBinaryExpression(e,t){const n=this.evaluate(e.left,t);switch(e.operator.value){case"and":return n.__bool__().value?this.evaluate(e.right,t):n;case"or":return n.__bool__().value?n:this.evaluate(e.right,t)}const r=this.evaluate(e.right,t);switch(e.operator.value){case"==":return new N(n.value==r.value);case"!=":return new N(n.value!=r.value)}if(n instanceof W||r instanceof W)throw new Error("Cannot perform operation on undefined values");if(n instanceof q||r instanceof q)throw new Error("Cannot perform operation on null values");if(n instanceof D&&r instanceof D)switch(e.operator.value){case"+":return new D(n.value+r.value);case"-":return new D(n.value-r.value);case"*":return new D(n.value*r.value);case"/":return new D(n.value/r.value);case"%":return new D(n.value%r.value);case"<":return new N(n.value<r.value);case">":return new N(n.value>r.value);case">=":return new N(n.value>=r.value);case"<=":return new N(n.value<=r.value)}else if(n instanceof j&&r instanceof j){if("+"===e.operator.value)return new j(n.value.concat(r.value))}else if(r instanceof j){const t=void 0!==r.value.find((e=>e.value===n.value));switch(e.operator.value){case"in":return new N(t);case"not in":return new N(!t)}}if((n instanceof R||r instanceof R)&&"+"===e.operator.value)return new R(n.value.toString()+r.value.toString());if(n instanceof R&&r instanceof R)switch(e.operator.value){case"in":return new N(r.value.includes(n.value));case"not in":return new N(!r.value.includes(n.value))}if(n instanceof R&&r instanceof V)switch(e.operator.value){case"in":return new N(r.value.has(n.value));case"not in":return new N(!r.value.has(n.value))}throw new SyntaxError(`Unknown operator "${e.operator.value}" between ${n.type} and ${r.type}`)}evaluateFilterExpression(e,t){const n=this.evaluate(e.operand,t);if("Identifier"===e.filter.type){const t=e.filter;if(n instanceof j)switch(t.value){case"list":return n;case"first":return n.value[0];case"last":return n.value[n.value.length-1];case"length":return new D(n.value.length);case"reverse":return new j(n.value.reverse());case"sort":return new j(n.value.sort(((e,t)=>{if(e.type!==t.type)throw new Error(`Cannot compare different types: ${e.type} and ${t.type}`);switch(e.type){case"NumericValue":return e.value-t.value;case"StringValue":return e.value.localeCompare(t.value);default:throw new Error(`Cannot compare type: ${e.type}`)}})));default:throw new Error(`Unknown ArrayValue filter: ${t.value}`)}else if(n instanceof R)switch(t.value){case"length":return new D(n.value.length);case"upper":return new R(n.value.toUpperCase());case"lower":return new R(n.value.toLowerCase());case"title":return new R(O(n.value));case"capitalize":return new R(n.value.charAt(0).toUpperCase()+n.value.slice(1));case"trim":return new R(n.value.trim());default:throw new Error(`Unknown StringValue filter: ${t.value}`)}else{if(n instanceof D){if("abs"===t.value)return new D(Math.abs(n.value));throw new Error(`Unknown NumericValue filter: ${t.value}`)}if(n instanceof V)switch(t.value){case"items":return new j(Array.from(n.value.entries()).map((([e,t])=>new j([new R(e),t]))));case"length":return new D(n.value.size);default:throw new Error(`Unknown ObjectValue filter: ${t.value}`)}}throw new Error(`Cannot apply filter "${t.value}" to type: ${n.type}`)}if("CallExpression"===e.filter.type){const r=e.filter;if("Identifier"!==r.callee.type)throw new Error(`Unknown filter: ${r.callee.type}`);const i=r.callee.value;if(n instanceof j){if("selectattr"===i){if(n.value.some((e=>!(e instanceof V))))throw new Error("`selectattr` can only be applied to array of objects");if(r.args.some((e=>"StringLiteral"!==e.type)))throw new Error("arguments of `selectattr` must be strings");const[e,i,s]=r.args.map((e=>this.evaluate(e,t)));let o;if(i){const e=t.tests.get(i.value);if(!e)throw new Error(`Unknown test: ${i.value}`);o=e}else o=(...e)=>e[0].__bool__().value;const a=n.value.filter((t=>{const n=t.value.get(e.value);return!!n&&o(n,s)}));return new j(a)}throw new Error(`Unknown ArrayValue filter: ${i}`)}throw new Error(`Cannot apply filter "${i}" to type: ${n.type}`)}throw new Error(`Unknown filter: ${e.filter.type}`)}evaluateTestExpression(e,t){const n=this.evaluate(e.operand,t),r=t.tests.get(e.test.value);if(!r)throw new Error(`Unknown test: ${e.test.value}`);const i=r(n);return new N(e.negate?!i:i)}evaluateUnaryExpression(e,t){const n=this.evaluate(e.argument,t);if("not"===e.operator.value)return new N(!n.value);throw new SyntaxError(`Unknown operator: ${e.operator.value}`)}evalProgram(e,t){return this.evaluateBlock(e.body,t)}evaluateBlock(e,t){let n="";for(const r of e){const e=this.evaluate(r,t);"NullValue"!==e.type&&"UndefinedValue"!==e.type&&(n+=e.value)}return new R(n)}evaluateIdentifier(e,t){return t.lookupVariable(e.value)}evaluateCallExpression(e,t){const n=[],r=new Map;for(const i of e.args)if("KeywordArgumentExpression"===i.type){const e=i;r.set(e.key.value,this.evaluate(e.value,t))}else n.push(this.evaluate(i,t));r.size>0&&n.push(new V(r));const i=this.evaluate(e.callee,t);if("FunctionValue"!==i.type)throw new Error(`Cannot call something that is not a function: got ${i.type}`);return i.value(n,t)}evaluateSliceExpression(e,t,n){if(!(e instanceof j||e instanceof R))throw new Error("Slice object must be an array or string");const r=this.evaluate(t.start,n),i=this.evaluate(t.stop,n),s=this.evaluate(t.step,n);if(!(r instanceof D||r instanceof W))throw new Error("Slice start must be numeric or undefined");if(!(i instanceof D||i instanceof W))throw new Error("Slice stop must be numeric or undefined");if(!(s instanceof D||s instanceof W))throw new Error("Slice step must be numeric or undefined");return e instanceof j?new j(B(e.value,r.value,i.value,s.value)):new R(B(Array.from(e.value),r.value,i.value,s.value).join(""))}evaluateMemberExpression(e,t){const n=this.evaluate(e.object,t);let r,i;if(e.computed){if("SliceExpression"===e.property.type)return this.evaluateSliceExpression(n,e.property,t);r=this.evaluate(e.property,t)}else r=new R(e.property.value);if(n instanceof V){if(!(r instanceof R))throw new Error(`Cannot access property with non-string: got ${r.type}`);i=n.value.get(r.value)??n.builtins.get(r.value)}else if(n instanceof j||n instanceof R)if(r instanceof D)i=n.value.at(r.value),n instanceof R&&(i=new R(n.value.at(r.value)));else{if(!(r instanceof R))throw new Error(`Cannot access property with non-string/non-number: got ${r.type}`);i=n.builtins.get(r.value)}else{if(!(r instanceof R))throw new Error(`Cannot access property with non-string: got ${r.type}`);i=n.builtins.get(r.value)}return i instanceof L?i:new W}evaluateSet(e,t){const n=this.evaluate(e.value,t);if("Identifier"===e.assignee.type){const r=e.assignee.value;t.setVariable(r,n)}else{if("MemberExpression"!==e.assignee.type)throw new Error(`Invalid LHS inside assignment expression: ${JSON.stringify(e.assignee)}`);{const r=e.assignee,i=this.evaluate(r.object,t);if(!(i instanceof V))throw new Error("Cannot assign to member of non-object");if("Identifier"!==r.property.type)throw new Error("Cannot assign to member with non-identifier property");i.value.set(r.property.value,n)}}return new q}evaluateIf(e,t){const n=this.evaluate(e.test,t);return this.evaluateBlock(n.__bool__().value?e.body:e.alternate,t)}evaluateFor(e,t){const n=new H(t),r=this.evaluate(e.iterable,n);if(!(r instanceof j))throw new Error(`Expected iterable type in for loop: got ${r.type}`);let i="";for(let t=0;t<r.value.length;++t){const s=new Map([["index",new D(t+1)],["index0",new D(t)],["revindex",new D(r.value.length-t)],["revindex0",new D(r.value.length-t-1)],["first",new N(0===t)],["last",new N(t===r.value.length-1)],["length",new D(r.value.length)],["previtem",t>0?r.value[t-1]:new W],["nextitem",t<r.value.length-1?r.value[t+1]:new W]]);n.setVariable("loop",new V(s));const o=r.value[t];if("Identifier"===e.loopvar.type)n.setVariable(e.loopvar.value,o);else if("TupleLiteral"===e.loopvar.type){const t=e.loopvar;if("ArrayValue"!==o.type)throw new Error(`Cannot unpack non-iterable type: ${o.type}`);const r=o;if(t.value.length!==r.value.length)throw new Error(`Too ${t.value.length>r.value.length?"few":"many"} items to unpack`);for(let e=0;e<t.value.length;++e){if("Identifier"!==t.value[e].type)throw new Error(`Cannot unpack non-identifier type: ${t.value[e].type}`);n.setVariable(t.value[e].value,r.value[e])}}i+=this.evaluateBlock(e.body,n).value}return new R(i)}evaluate(e,t){if(void 0===e)return new W;switch(e.type){case"Program":return this.evalProgram(e,t);case"Set":return this.evaluateSet(e,t);case"If":return this.evaluateIf(e,t);case"For":return this.evaluateFor(e,t);case"NumericLiteral":return new D(Number(e.value));case"StringLiteral":return new R(e.value);case"BooleanLiteral":return new N(e.value);case"ArrayLiteral":return new j(e.value.map((e=>this.evaluate(e,t))));case"TupleLiteral":return new U(e.value.map((e=>this.evaluate(e,t))));case"ObjectLiteral":{const n=new Map;for(const[r,i]of e.value){const e=this.evaluate(r,t);if(!(e instanceof R))throw new Error(`Object keys must be strings: got ${e.type}`);n.set(e.value,this.evaluate(i,t))}return new V(n)}case"Identifier":return this.evaluateIdentifier(e,t);case"CallExpression":return this.evaluateCallExpression(e,t);case"MemberExpression":return this.evaluateMemberExpression(e,t);case"UnaryExpression":return this.evaluateUnaryExpression(e,t);case"BinaryExpression":return this.evaluateBinaryExpression(e,t);case"FilterExpression":return this.evaluateFilterExpression(e,t);case"TestExpression":return this.evaluateTestExpression(e,t);default:throw new SyntaxError(`Unknown node type: ${e.type}`)}}};function Q(e){switch(typeof e){case"number":return new D(e);case"string":return new R(e);case"boolean":return new N(e);case"object":return null===e?new q:Array.isArray(e)?new j(e.map(Q)):new V(new Map(Object.entries(e).map((([e,t])=>[e,Q(t)]))));case"function":return new G(((t,n)=>Q(e(...t.map((e=>e.value)))??null)));default:throw new Error(`Cannot convert to runtime value: ${e}`)}}var K=class{parsed;constructor(e){const t=u(e,{lstrip_blocks:!0,trim_blocks:!0});this.parsed=I(t)}render(e){const t=new H;t.set("false",!1),t.set("true",!0),t.set("raise_exception",(e=>{throw new Error(e)})),t.set("range",z);for(const[n,r]of Object.entries(e))t.set(n,r);return new X(t).run(this.parsed).value}}},"./node_modules/onnxruntime-common/dist/esm/backend-impl.js":
/*!******************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/backend-impl.js ***!
  \******************************************************************/(e,t,n)=>{n.r(t),n.d(t,{registerBackend:()=>s,resolveBackend:()=>o});const r=new Map,i=[],s=(e,t,n)=>{if(!t||"function"!=typeof t.init||"function"!=typeof t.createInferenceSessionHandler)throw new TypeError("not a valid backend");{const s=r.get(e);if(void 0===s)r.set(e,{backend:t,priority:n});else{if(s.priority>n)return;if(s.priority===n&&s.backend!==t)throw new Error(`cannot register backend "${e}" using priority ${n}`)}if(n>=0){const t=i.indexOf(e);-1!==t&&i.splice(t,1);for(let t=0;t<i.length;t++)if(r.get(i[t]).priority<=n)return void i.splice(t,0,e);i.push(e)}}},o=async e=>{const t=0===e.length?i:e,n=[];for(const e of t){const t=r.get(e);if(t){if(t.initialized)return t.backend;if(t.aborted)continue;const r=!!t.initPromise;try{return r||(t.initPromise=t.backend.init(e)),await t.initPromise,t.initialized=!0,t.backend}catch(i){r||n.push({name:e,err:i}),t.aborted=!0}finally{delete t.initPromise}}}throw new Error(`no available backend found. ERR: ${n.map((e=>`[${e.name}] ${e.err}`)).join(", ")}`)}},"./node_modules/onnxruntime-common/dist/esm/backend.js":
/*!*************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/backend.js ***!
  \*************************************************************/(e,t,n)=>{n.r(t),n.d(t,{registerBackend:()=>r.registerBackend});var r=n(/*! ./backend-impl.js */"./node_modules/onnxruntime-common/dist/esm/backend-impl.js")},"./node_modules/onnxruntime-common/dist/esm/env-impl.js":
/*!**************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/env-impl.js ***!
  \**************************************************************/(e,t,n)=>{n.r(t),n.d(t,{env:()=>s});var r=n(/*! ./version.js */"./node_modules/onnxruntime-common/dist/esm/version.js");let i="warning";const s={wasm:{},webgl:{},webgpu:{},versions:{common:r.version},set logLevel(e){if(void 0!==e){if("string"!=typeof e||-1===["verbose","info","warning","error","fatal"].indexOf(e))throw new Error(`Unsupported logging level: ${e}`);i=e}},get logLevel(){return i}};Object.defineProperty(s,"logLevel",{enumerable:!0})},"./node_modules/onnxruntime-common/dist/esm/env.js":
/*!*********************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/env.js ***!
  \*********************************************************/(e,t,n)=>{n.r(t),n.d(t,{env:()=>r});const r=n(/*! ./env-impl.js */"./node_modules/onnxruntime-common/dist/esm/env-impl.js").env},"./node_modules/onnxruntime-common/dist/esm/index.js":
/*!***********************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/index.js ***!
  \***********************************************************/(e,t,n)=>{n.r(t),n.d(t,{InferenceSession:()=>s.InferenceSession,TRACE:()=>a.TRACE,TRACE_FUNC_BEGIN:()=>a.TRACE_FUNC_BEGIN,TRACE_FUNC_END:()=>a.TRACE_FUNC_END,Tensor:()=>o.Tensor,TrainingSession:()=>l.TrainingSession,env:()=>i.env,registerBackend:()=>r.registerBackend});var r=n(/*! ./backend.js */"./node_modules/onnxruntime-common/dist/esm/backend.js"),i=n(/*! ./env.js */"./node_modules/onnxruntime-common/dist/esm/env.js"),s=n(/*! ./inference-session.js */"./node_modules/onnxruntime-common/dist/esm/inference-session.js"),o=n(/*! ./tensor.js */"./node_modules/onnxruntime-common/dist/esm/tensor.js"),a=n(/*! ./trace.js */"./node_modules/onnxruntime-common/dist/esm/trace.js"),l=(n(/*! ./onnx-value.js */"./node_modules/onnxruntime-common/dist/esm/onnx-value.js"),n(/*! ./training-session.js */"./node_modules/onnxruntime-common/dist/esm/training-session.js"))},"./node_modules/onnxruntime-common/dist/esm/inference-session-impl.js":
/*!****************************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/inference-session-impl.js ***!
  \****************************************************************************/(e,t,n)=>{n.r(t),n.d(t,{InferenceSession:()=>o});var r=n(/*! ./backend-impl.js */"./node_modules/onnxruntime-common/dist/esm/backend-impl.js"),i=n(/*! ./tensor.js */"./node_modules/onnxruntime-common/dist/esm/tensor.js"),s=n(/*! ./trace.js */"./node_modules/onnxruntime-common/dist/esm/trace.js");class o{constructor(e){this.handler=e}async run(e,t,n){(0,s.TRACE_FUNC_BEGIN)();const r={};let o={};if("object"!=typeof e||null===e||e instanceof i.Tensor||Array.isArray(e))throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");let a=!0;if("object"==typeof t){if(null===t)throw new TypeError("Unexpected argument[1]: cannot be null.");if(t instanceof i.Tensor)throw new TypeError("'fetches' cannot be a Tensor");if(Array.isArray(t)){if(0===t.length)throw new TypeError("'fetches' cannot be an empty array.");a=!1;for(const e of t){if("string"!=typeof e)throw new TypeError("'fetches' must be a string array or an object.");if(-1===this.outputNames.indexOf(e))throw new RangeError(`'fetches' contains invalid output name: ${e}.`);r[e]=null}if("object"==typeof n&&null!==n)o=n;else if(void 0!==n)throw new TypeError("'options' must be an object.")}else{let e=!1;const s=Object.getOwnPropertyNames(t);for(const n of this.outputNames)if(-1!==s.indexOf(n)){const s=t[n];(null===s||s instanceof i.Tensor)&&(e=!0,a=!1,r[n]=s)}if(e){if("object"==typeof n&&null!==n)o=n;else if(void 0!==n)throw new TypeError("'options' must be an object.")}else o=t}}else if(void 0!==t)throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");for(const t of this.inputNames)if(void 0===e[t])throw new Error(`input '${t}' is missing in 'feeds'.`);if(a)for(const e of this.outputNames)r[e]=null;const l=await this.handler.run(e,r,o),d={};for(const e in l)if(Object.hasOwnProperty.call(l,e)){const t=l[e];t instanceof i.Tensor?d[e]=t:d[e]=new i.Tensor(t.type,t.data,t.dims)}return(0,s.TRACE_FUNC_END)(),d}async release(){return this.handler.dispose()}static async create(e,t,n,i){let a;(0,s.TRACE_FUNC_BEGIN)();let l={};if("string"==typeof e){if(a=e,"object"==typeof t&&null!==t)l=t;else if(void 0!==t)throw new TypeError("'options' must be an object.")}else if(e instanceof Uint8Array){if(a=e,"object"==typeof t&&null!==t)l=t;else if(void 0!==t)throw new TypeError("'options' must be an object.")}else{if(!(e instanceof ArrayBuffer||"undefined"!=typeof SharedArrayBuffer&&e instanceof SharedArrayBuffer))throw new TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");{const r=e;let s=0,o=e.byteLength;if("object"==typeof t&&null!==t)l=t;else if("number"==typeof t){if(s=t,!Number.isSafeInteger(s))throw new RangeError("'byteOffset' must be an integer.");if(s<0||s>=r.byteLength)throw new RangeError(`'byteOffset' is out of range [0, ${r.byteLength}).`);if(o=e.byteLength-s,"number"==typeof n){if(o=n,!Number.isSafeInteger(o))throw new RangeError("'byteLength' must be an integer.");if(o<=0||s+o>r.byteLength)throw new RangeError(`'byteLength' is out of range (0, ${r.byteLength-s}].`);if("object"==typeof i&&null!==i)l=i;else if(void 0!==i)throw new TypeError("'options' must be an object.")}else if(void 0!==n)throw new TypeError("'byteLength' must be a number.")}else if(void 0!==t)throw new TypeError("'options' must be an object.");a=new Uint8Array(r,s,o)}}const d=(l.executionProviders||[]).map((e=>"string"==typeof e?e:e.name)),u=await(0,r.resolveBackend)(d),c=await u.createInferenceSessionHandler(a,l);return(0,s.TRACE_FUNC_END)(),new o(c)}startProfiling(){this.handler.startProfiling()}endProfiling(){this.handler.endProfiling()}get inputNames(){return this.handler.inputNames}get outputNames(){return this.handler.outputNames}}},"./node_modules/onnxruntime-common/dist/esm/inference-session.js":
/*!***********************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/inference-session.js ***!
  \***********************************************************************/(e,t,n)=>{n.r(t),n.d(t,{InferenceSession:()=>r});const r=n(/*! ./inference-session-impl.js */"./node_modules/onnxruntime-common/dist/esm/inference-session-impl.js").InferenceSession},"./node_modules/onnxruntime-common/dist/esm/onnx-value.js":
/*!****************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/onnx-value.js ***!
  \****************************************************************/(e,t,n)=>{n.r(t)},"./node_modules/onnxruntime-common/dist/esm/tensor-conversion-impl.js":
/*!****************************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/tensor-conversion-impl.js ***!
  \****************************************************************************/(e,t,n)=>{n.r(t),n.d(t,{tensorToDataURL:()=>r,tensorToImageData:()=>i});const r=(e,t)=>{const n="undefined"!=typeof document?document.createElement("canvas"):new OffscreenCanvas(1,1);n.width=e.dims[3],n.height=e.dims[2];const r=n.getContext("2d");if(null!=r){let i,s;void 0!==t?.tensorLayout&&"NHWC"===t.tensorLayout?(i=e.dims[2],s=e.dims[3]):(i=e.dims[3],s=e.dims[2]);const o=void 0!==t?.format?t.format:"RGB",a=t?.norm;let l,d;void 0===a||void 0===a.mean?l=[255,255,255,255]:"number"==typeof a.mean?l=[a.mean,a.mean,a.mean,a.mean]:(l=[a.mean[0],a.mean[1],a.mean[2],0],void 0!==a.mean[3]&&(l[3]=a.mean[3])),void 0===a||void 0===a.bias?d=[0,0,0,0]:"number"==typeof a.bias?d=[a.bias,a.bias,a.bias,a.bias]:(d=[a.bias[0],a.bias[1],a.bias[2],0],void 0!==a.bias[3]&&(d[3]=a.bias[3]));const u=s*i;let c=0,p=u,h=2*u,f=-1;"RGBA"===o?(c=0,p=u,h=2*u,f=3*u):"RGB"===o?(c=0,p=u,h=2*u):"RBG"===o&&(c=0,h=u,p=2*u);for(let t=0;t<s;t++)for(let n=0;n<i;n++){const i=(e.data[c++]-d[0])*l[0],s=(e.data[p++]-d[1])*l[1],o=(e.data[h++]-d[2])*l[2],a=-1===f?255:(e.data[f++]-d[3])*l[3];r.fillStyle="rgba("+i+","+s+","+o+","+a+")",r.fillRect(n,t,1,1)}if("toDataURL"in n)return n.toDataURL();throw new Error("toDataURL is not supported")}throw new Error("Can not access image data")},i=(e,t)=>{const n="undefined"!=typeof document?document.createElement("canvas").getContext("2d"):new OffscreenCanvas(1,1).getContext("2d");let r;if(null==n)throw new Error("Can not access image data");{let i,s,o;void 0!==t?.tensorLayout&&"NHWC"===t.tensorLayout?(i=e.dims[2],s=e.dims[1],o=e.dims[3]):(i=e.dims[3],s=e.dims[2],o=e.dims[1]);const a=void 0!==t&&void 0!==t.format?t.format:"RGB",l=t?.norm;let d,u;void 0===l||void 0===l.mean?d=[255,255,255,255]:"number"==typeof l.mean?d=[l.mean,l.mean,l.mean,l.mean]:(d=[l.mean[0],l.mean[1],l.mean[2],255],void 0!==l.mean[3]&&(d[3]=l.mean[3])),void 0===l||void 0===l.bias?u=[0,0,0,0]:"number"==typeof l.bias?u=[l.bias,l.bias,l.bias,l.bias]:(u=[l.bias[0],l.bias[1],l.bias[2],0],void 0!==l.bias[3]&&(u[3]=l.bias[3]));const c=s*i;if(void 0!==t&&(void 0!==t.format&&4===o&&"RGBA"!==t.format||3===o&&"RGB"!==t.format&&"BGR"!==t.format))throw new Error("Tensor format doesn't match input tensor dims");const p=4;let h=0,f=1,m=2,g=3,_=0,w=c,y=2*c,b=-1;"RGBA"===a?(_=0,w=c,y=2*c,b=3*c):"RGB"===a?(_=0,w=c,y=2*c):"RBG"===a&&(_=0,y=c,w=2*c),r=n.createImageData(i,s);for(let t=0;t<s*i;h+=p,f+=p,m+=p,g+=p,t++)r.data[h]=(e.data[_++]-u[0])*d[0],r.data[f]=(e.data[w++]-u[1])*d[1],r.data[m]=(e.data[y++]-u[2])*d[2],r.data[g]=-1===b?255:(e.data[b++]-u[3])*d[3]}return r}},"./node_modules/onnxruntime-common/dist/esm/tensor-factory-impl.js":
/*!*************************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/tensor-factory-impl.js ***!
  \*************************************************************************/(e,t,n)=>{n.r(t),n.d(t,{bufferToTensor:()=>i,tensorFromGpuBuffer:()=>a,tensorFromImage:()=>s,tensorFromPinnedBuffer:()=>l,tensorFromTexture:()=>o});var r=n(/*! ./tensor-impl.js */"./node_modules/onnxruntime-common/dist/esm/tensor-impl.js");const i=(e,t)=>{if(void 0===e)throw new Error("Image buffer must be defined");if(void 0===t.height||void 0===t.width)throw new Error("Image height and width must be defined");if("NHWC"===t.tensorLayout)throw new Error("NHWC Tensor layout is not supported yet");const{height:n,width:i}=t,s=t.norm??{mean:255,bias:0};let o,a;o="number"==typeof s.mean?[s.mean,s.mean,s.mean,s.mean]:[s.mean[0],s.mean[1],s.mean[2],s.mean[3]??255],a="number"==typeof s.bias?[s.bias,s.bias,s.bias,s.bias]:[s.bias[0],s.bias[1],s.bias[2],s.bias[3]??0];const l=void 0!==t.format?t.format:"RGBA",d=void 0!==t.tensorFormat&&void 0!==t.tensorFormat?t.tensorFormat:"RGB",u=n*i,c="RGBA"===d?new Float32Array(4*u):new Float32Array(3*u);let p=4,h=0,f=1,m=2,g=3,_=0,w=u,y=2*u,b=-1;"RGB"===l&&(p=3,h=0,f=1,m=2,g=-1),"RGBA"===d?b=3*u:"RBG"===d?(_=0,y=u,w=2*u):"BGR"===d&&(y=0,w=u,_=2*u);for(let t=0;t<u;t++,h+=p,m+=p,f+=p,g+=p)c[_++]=(e[h]+a[0])/o[0],c[w++]=(e[f]+a[1])/o[1],c[y++]=(e[m]+a[2])/o[2],-1!==b&&-1!==g&&(c[b++]=(e[g]+a[3])/o[3]);return"RGBA"===d?new r.Tensor("float32",c,[1,4,n,i]):new r.Tensor("float32",c,[1,3,n,i])},s=async(e,t)=>{const n="undefined"!=typeof HTMLImageElement&&e instanceof HTMLImageElement,r="undefined"!=typeof ImageData&&e instanceof ImageData,s="undefined"!=typeof ImageBitmap&&e instanceof ImageBitmap,o="string"==typeof e;let a,l=t??{};const d=()=>{if("undefined"!=typeof document)return document.createElement("canvas");if("undefined"!=typeof OffscreenCanvas)return new OffscreenCanvas(1,1);throw new Error("Canvas is not supported")},u=e=>e instanceof HTMLCanvasElement||e instanceof OffscreenCanvas?e.getContext("2d"):null;if(n){const n=d();n.width=e.width,n.height=e.height;const r=u(n);if(null==r)throw new Error("Can not access image data");{let n=e.height,i=e.width;if(void 0!==t&&void 0!==t.resizedHeight&&void 0!==t.resizedWidth&&(n=t.resizedHeight,i=t.resizedWidth),void 0!==t){if(l=t,void 0!==t.tensorFormat)throw new Error("Image input config format must be RGBA for HTMLImageElement");l.tensorFormat="RGBA",l.height=n,l.width=i}else l.tensorFormat="RGBA",l.height=n,l.width=i;r.drawImage(e,0,0),a=r.getImageData(0,0,i,n).data}}else{if(!r){if(s){if(void 0===t)throw new Error("Please provide image config with format for Imagebitmap");const n=d();n.width=e.width,n.height=e.height;const r=u(n);if(null!=r){const t=e.height,n=e.width;return r.drawImage(e,0,0,n,t),a=r.getImageData(0,0,n,t).data,l.height=t,l.width=n,i(a,l)}throw new Error("Can not access image data")}if(o)return new Promise(((t,n)=>{const r=d(),s=u(r);if(!e||!s)return n();const o=new Image;o.crossOrigin="Anonymous",o.src=e,o.onload=()=>{r.width=o.width,r.height=o.height,s.drawImage(o,0,0,r.width,r.height);const e=s.getImageData(0,0,r.width,r.height);l.height=r.height,l.width=r.width,t(i(e.data,l))}}));throw new Error("Input data provided is not supported - aborted tensor creation")}{let n,r;if(void 0!==t&&void 0!==t.resizedWidth&&void 0!==t.resizedHeight?(n=t.resizedHeight,r=t.resizedWidth):(n=e.height,r=e.width),void 0!==t&&(l=t),l.format="RGBA",l.height=n,l.width=r,void 0!==t){const t=d();t.width=r,t.height=n;const i=u(t);if(null==i)throw new Error("Can not access image data");i.putImageData(e,0,0),a=i.getImageData(0,0,r,n).data}else a=e.data}}if(void 0!==a)return i(a,l);throw new Error("Input data provided is not supported - aborted tensor creation")},o=(e,t)=>{const{width:n,height:i,download:s,dispose:o}=t,a=[1,i,n,4];return new r.Tensor({location:"texture",type:"float32",texture:e,dims:a,download:s,dispose:o})},a=(e,t)=>{const{dataType:n,dims:i,download:s,dispose:o}=t;return new r.Tensor({location:"gpu-buffer",type:n??"float32",gpuBuffer:e,dims:i,download:s,dispose:o})},l=(e,t,n)=>new r.Tensor({location:"cpu-pinned",type:e,data:t,dims:n??[t.length]})},"./node_modules/onnxruntime-common/dist/esm/tensor-impl-type-mapping.js":
/*!******************************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/tensor-impl-type-mapping.js ***!
  \******************************************************************************/(e,t,n)=>{n.r(t),n.d(t,{NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP:()=>i,NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP:()=>r,checkBigInt:()=>o});const r=new Map([["float32",Float32Array],["uint8",Uint8Array],["int8",Int8Array],["uint16",Uint16Array],["float16",Uint16Array],["int16",Int16Array],["int32",Int32Array],["bool",Uint8Array],["float64",Float64Array],["uint32",Uint32Array]]),i=new Map([[Float32Array,"float32"],[Uint8Array,"uint8"],[Int8Array,"int8"],[Uint16Array,"uint16"],[Int16Array,"int16"],[Int32Array,"int32"],[Float64Array,"float64"],[Uint32Array,"uint32"]]);let s=!1;const o=()=>{if(!s){s=!0;const e="undefined"!=typeof BigInt64Array&&"function"==typeof BigInt64Array.from,t="undefined"!=typeof BigUint64Array&&"function"==typeof BigUint64Array.from;e&&(r.set("int64",BigInt64Array),i.set(BigInt64Array,"int64")),t&&(r.set("uint64",BigUint64Array),i.set(BigUint64Array,"uint64"))}}},"./node_modules/onnxruntime-common/dist/esm/tensor-impl.js":
/*!*****************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/tensor-impl.js ***!
  \*****************************************************************/(e,t,n)=>{n.r(t),n.d(t,{Tensor:()=>a});var r=n(/*! ./tensor-conversion-impl.js */"./node_modules/onnxruntime-common/dist/esm/tensor-conversion-impl.js"),i=n(/*! ./tensor-factory-impl.js */"./node_modules/onnxruntime-common/dist/esm/tensor-factory-impl.js"),s=n(/*! ./tensor-impl-type-mapping.js */"./node_modules/onnxruntime-common/dist/esm/tensor-impl-type-mapping.js"),o=n(/*! ./tensor-utils-impl.js */"./node_modules/onnxruntime-common/dist/esm/tensor-utils-impl.js");class a{constructor(e,t,n){let r,i;if((0,s.checkBigInt)(),"object"==typeof e&&"location"in e)switch(this.dataLocation=e.location,r=e.type,i=e.dims,e.location){case"cpu-pinned":{const t=s.NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(r);if(!t)throw new TypeError(`unsupported type "${r}" to create tensor from pinned buffer`);if(!(e.data instanceof t))throw new TypeError(`buffer should be of type ${t.name}`);this.cpuData=e.data;break}case"texture":if("float32"!==r)throw new TypeError(`unsupported type "${r}" to create tensor from texture`);this.gpuTextureData=e.texture,this.downloader=e.download,this.disposer=e.dispose;break;case"gpu-buffer":if("float32"!==r&&"float16"!==r&&"int32"!==r&&"int64"!==r&&"uint32"!==r&&"bool"!==r)throw new TypeError(`unsupported type "${r}" to create tensor from gpu buffer`);this.gpuBufferData=e.gpuBuffer,this.downloader=e.download,this.disposer=e.dispose;break;default:throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`)}else{let o,a;if("string"==typeof e)if(r=e,a=n,"string"===e){if(!Array.isArray(t))throw new TypeError("A string tensor's data must be a string array.");o=t}else{const n=s.NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(e);if(void 0===n)throw new TypeError(`Unsupported tensor type: ${e}.`);if(Array.isArray(t)){if("float16"===e)throw new TypeError("Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.");o="uint64"===e||"int64"===e?n.from(t,BigInt):n.from(t)}else{if(!(t instanceof n))throw new TypeError(`A ${r} tensor's data must be type of ${n}`);o=t}}else if(a=t,Array.isArray(e)){if(0===e.length)throw new TypeError("Tensor type cannot be inferred from an empty array.");const t=typeof e[0];if("string"===t)r="string",o=e;else{if("boolean"!==t)throw new TypeError(`Invalid element type of data array: ${t}.`);r="bool",o=Uint8Array.from(e)}}else{const t=s.NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(e.constructor);if(void 0===t)throw new TypeError(`Unsupported type for tensor data: ${e.constructor}.`);r=t,o=e}if(void 0===a)a=[o.length];else if(!Array.isArray(a))throw new TypeError("A tensor's dims must be a number array");i=a,this.cpuData=o,this.dataLocation="cpu"}const a=(0,o.calculateSize)(i);if(this.cpuData&&a!==this.cpuData.length)throw new Error(`Tensor's size(${a}) does not match data length(${this.cpuData.length}).`);this.type=r,this.dims=i,this.size=a}static async fromImage(e,t){return(0,i.tensorFromImage)(e,t)}static fromTexture(e,t){return(0,i.tensorFromTexture)(e,t)}static fromGpuBuffer(e,t){return(0,i.tensorFromGpuBuffer)(e,t)}static fromPinnedBuffer(e,t,n){return(0,i.tensorFromPinnedBuffer)(e,t,n)}toDataURL(e){return(0,r.tensorToDataURL)(this,e)}toImageData(e){return(0,r.tensorToImageData)(this,e)}get data(){if(this.ensureValid(),!this.cpuData)throw new Error("The data is not on CPU. Use `getData()` to download GPU data to CPU, or use `texture` or `gpuBuffer` property to access the GPU data directly.");return this.cpuData}get location(){return this.dataLocation}get texture(){if(this.ensureValid(),!this.gpuTextureData)throw new Error("The data is not stored as a WebGL texture.");return this.gpuTextureData}get gpuBuffer(){if(this.ensureValid(),!this.gpuBufferData)throw new Error("The data is not stored as a WebGPU buffer.");return this.gpuBufferData}async getData(e){switch(this.ensureValid(),this.dataLocation){case"cpu":case"cpu-pinned":return this.data;case"texture":case"gpu-buffer":if(!this.downloader)throw new Error("The current tensor is not created with a specified data downloader.");if(this.isDownloading)throw new Error("The current tensor is being downloaded.");try{this.isDownloading=!0;const t=await this.downloader();return this.downloader=void 0,this.dataLocation="cpu",this.cpuData=t,e&&this.disposer&&(this.disposer(),this.disposer=void 0),t}finally{this.isDownloading=!1}default:throw new Error(`cannot get data from location: ${this.dataLocation}`)}}dispose(){if(this.isDownloading)throw new Error("The current tensor is being downloaded.");this.disposer&&(this.disposer(),this.disposer=void 0),this.cpuData=void 0,this.gpuTextureData=void 0,this.gpuBufferData=void 0,this.downloader=void 0,this.isDownloading=void 0,this.dataLocation="none"}ensureValid(){if("none"===this.dataLocation)throw new Error("The tensor is disposed.")}reshape(e){if(this.ensureValid(),this.downloader||this.disposer)throw new Error("Cannot reshape a tensor that owns GPU resource.");return(0,o.tensorReshape)(this,e)}}},"./node_modules/onnxruntime-common/dist/esm/tensor-utils-impl.js":
/*!***********************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/tensor-utils-impl.js ***!
  \***********************************************************************/(e,t,n)=>{n.r(t),n.d(t,{calculateSize:()=>i,tensorReshape:()=>s});var r=n(/*! ./tensor-impl.js */"./node_modules/onnxruntime-common/dist/esm/tensor-impl.js");const i=e=>{let t=1;for(let n=0;n<e.length;n++){const r=e[n];if("number"!=typeof r||!Number.isSafeInteger(r))throw new TypeError(`dims[${n}] must be an integer, got: ${r}`);if(r<0)throw new RangeError(`dims[${n}] must be a non-negative integer, got: ${r}`);t*=r}return t},s=(e,t)=>{switch(e.location){case"cpu":return new r.Tensor(e.type,e.data,t);case"cpu-pinned":return new r.Tensor({location:"cpu-pinned",data:e.data,type:e.type,dims:t});case"texture":return new r.Tensor({location:"texture",texture:e.texture,type:e.type,dims:t});case"gpu-buffer":return new r.Tensor({location:"gpu-buffer",gpuBuffer:e.gpuBuffer,type:e.type,dims:t});default:throw new Error(`tensorReshape: tensor location ${e.location} is not supported`)}}},"./node_modules/onnxruntime-common/dist/esm/tensor.js":
/*!************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/tensor.js ***!
  \************************************************************/(e,t,n)=>{n.r(t),n.d(t,{Tensor:()=>r});const r=n(/*! ./tensor-impl.js */"./node_modules/onnxruntime-common/dist/esm/tensor-impl.js").Tensor},"./node_modules/onnxruntime-common/dist/esm/trace.js":
/*!***********************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/trace.js ***!
  \***********************************************************/(e,t,n)=>{n.r(t),n.d(t,{TRACE:()=>i,TRACE_FUNC_BEGIN:()=>o,TRACE_FUNC_END:()=>a});var r=n(/*! ./env-impl.js */"./node_modules/onnxruntime-common/dist/esm/env-impl.js");const i=(e,t)=>{r.env.wasm.trace&&console.timeStamp(`${e}::ORT::${t}`)},s=(e,t)=>{const n=(new Error).stack?.split(/\r\n|\r|\n/g)||[];let r=!1;for(let s=0;s<n.length;s++){if(r&&!n[s].includes("TRACE_FUNC")){let r=`FUNC_${e}::${n[s].trim().split(" ")[1]}`;return t&&(r+=`::${t}`),void i("CPU",r)}n[s].includes("TRACE_FUNC")&&(r=!0)}},o=e=>{r.env.wasm.trace&&s("BEGIN",e)},a=e=>{r.env.wasm.trace&&s("END",e)}},"./node_modules/onnxruntime-common/dist/esm/training-session-impl.js":
/*!***************************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/training-session-impl.js ***!
  \***************************************************************************/(e,t,n)=>{n.r(t),n.d(t,{TrainingSession:()=>s});var r=n(/*! ./backend-impl.js */"./node_modules/onnxruntime-common/dist/esm/backend-impl.js"),i=n(/*! ./tensor.js */"./node_modules/onnxruntime-common/dist/esm/tensor.js");class s{constructor(e,t,n){this.handler=e,this.hasOptimizerModel=t,this.hasEvalModel=n}get trainingInputNames(){return this.handler.inputNames}get trainingOutputNames(){return this.handler.outputNames}get evalInputNames(){if(this.hasEvalModel)return this.handler.evalInputNames;throw new Error("This training session has no evalModel loaded.")}get evalOutputNames(){if(this.hasEvalModel)return this.handler.evalOutputNames;throw new Error("This training session has no evalModel loaded.")}static async create(e,t){const n=e.evalModel||"",i=e.optimizerModel||"",o=t||{},a=(o.executionProviders||[]).map((e=>"string"==typeof e?e:e.name)),l=await(0,r.resolveBackend)(a);if(l.createTrainingSessionHandler){const t=await l.createTrainingSessionHandler(e.checkpointState,e.trainModel,n,i,o);return new s(t,!!e.optimizerModel,!!e.evalModel)}throw new Error("Training backend could not be resolved. Make sure you're using the correct configuration & WebAssembly files.")}typeNarrowingForRunStep(e,t,n,r,s){const o={};let a={};if("object"!=typeof n||null===n||n instanceof i.Tensor||Array.isArray(n))throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");let l=!0;if("object"==typeof r){if(null===r)throw new TypeError("Unexpected argument[1]: cannot be null.");if(r instanceof i.Tensor)throw new TypeError("'fetches' cannot be a Tensor");if(Array.isArray(r)){if(0===r.length)throw new TypeError("'fetches' cannot be an empty array.");l=!1;for(const e of r){if("string"!=typeof e)throw new TypeError("'fetches' must be a string array or an object.");if(-1===t.indexOf(e))throw new RangeError(`'fetches' contains invalid output name: ${e}.`);o[e]=null}if("object"==typeof s&&null!==s)a=s;else if(void 0!==s)throw new TypeError("'options' must be an object.")}else{let e=!1;const n=Object.getOwnPropertyNames(r);for(const s of t)if(-1!==n.indexOf(s)){const t=r[s];(null===t||t instanceof i.Tensor)&&(e=!0,l=!1,o[s]=t)}if(e){if("object"==typeof s&&null!==s)a=s;else if(void 0!==s)throw new TypeError("'options' must be an object.")}else a=r}}else if(void 0!==r)throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");for(const t of e)if(void 0===n[t])throw new Error(`input '${t}' is missing in 'feeds'.`);if(l)for(const e of t)o[e]=null;return[o,a]}convertHandlerReturnTypeToMapOfTensors(e){const t={};for(const n in e)if(Object.hasOwnProperty.call(e,n)){const r=e[n];r instanceof i.Tensor?t[n]=r:t[n]=new i.Tensor(r.type,r.data,r.dims)}return t}async lazyResetGrad(){await this.handler.lazyResetGrad()}async runTrainStep(e,t,n){const[r,i]=this.typeNarrowingForRunStep(this.trainingInputNames,this.trainingOutputNames,e,t,n),s=await this.handler.runTrainStep(e,r,i);return this.convertHandlerReturnTypeToMapOfTensors(s)}async runOptimizerStep(e){if(!this.hasOptimizerModel)throw new Error("This TrainingSession has no OptimizerModel loaded.");await this.handler.runOptimizerStep(e||{})}async runEvalStep(e,t,n){if(this.hasEvalModel){const[r,i]=this.typeNarrowingForRunStep(this.evalInputNames,this.evalOutputNames,e,t,n),s=await this.handler.runEvalStep(e,r,i);return this.convertHandlerReturnTypeToMapOfTensors(s)}throw new Error("This TrainingSession has no EvalModel loaded.")}async getParametersSize(e=!0){return this.handler.getParametersSize(e)}async loadParametersBuffer(e,t=!0){const n=await this.getParametersSize(t);if(e.length!==4*n)throw new Error("Size of the buffer passed into loadParametersBuffer must match the number of parameters in the model. Please use getParametersSize method to check.");return this.handler.loadParametersBuffer(e,t)}async getContiguousParameters(e=!0){return this.handler.getContiguousParameters(e)}async release(){return this.handler.dispose()}}},"./node_modules/onnxruntime-common/dist/esm/training-session.js":
/*!**********************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/training-session.js ***!
  \**********************************************************************/(e,t,n)=>{n.r(t),n.d(t,{TrainingSession:()=>r});const r=n(/*! ./training-session-impl.js */"./node_modules/onnxruntime-common/dist/esm/training-session-impl.js").TrainingSession},"./node_modules/onnxruntime-common/dist/esm/version.js":
/*!*************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/esm/version.js ***!
  \*************************************************************/(e,t,n)=>{n.r(t),n.d(t,{version:()=>r});const r="1.17.0"},"./node_modules/onnxruntime-web/dist/ort.webgpu.min.mjs":
/*!**************************************************************!*\
  !*** ./node_modules/onnxruntime-web/dist/ort.webgpu.min.mjs ***!
  \**************************************************************/(e,t,n)=>{n.r(t),n.d(t,{InferenceSession:()=>I,TRACE:()=>C,TRACE_FUNC_BEGIN:()=>E,TRACE_FUNC_END:()=>A,Tensor:()=>S,TrainingSession:()=>B,default:()=>kd,env:()=>p,registerBackend:()=>o});
/*!
 * ONNX Runtime Web v1.18.0-esmtest.20240411-1abb64e894
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License.
 */
var r,i,s,o,a,l,d,u,c,p,h,f,m,g,_,w,y,b,v,x,M,T,k,$,S,C,P,E,A,F,I,z,B,O=Object.defineProperty,L=Object.getOwnPropertyDescriptor,D=Object.getOwnPropertyNames,R=Object.prototype.hasOwnProperty,N=(r=function(e){if(typeof require<"u")return require.apply(this,arguments);throw Error('Dynamic require of "'+e+'" is not supported')},typeof require<"u"?require:typeof Proxy<"u"?new Proxy(r,{get:(e,t)=>(typeof require<"u"?require:e)[t]}):r),V=(e,t)=>()=>(e&&(t=e(e=0)),t),j=(e,t)=>{for(var n in t)O(e,n,{get:t[n],enumerable:!0})},U=e=>((e,t,n,r)=>{if(t&&"object"==typeof t||"function"==typeof t)for(let i of D(t))!R.call(e,i)&&i!==n&&O(e,i,{get:()=>t[i],enumerable:!(r=L(t,i))||r.enumerable});return e})(O({},"__esModule",{value:!0}),e),G=V((()=>{i=new Map,s=[],o=(e,t,n)=>{if(!t||"function"!=typeof t.init||"function"!=typeof t.createInferenceSessionHandler)throw new TypeError("not a valid backend");{let r=i.get(e);if(void 0===r)i.set(e,{backend:t,priority:n});else{if(r.priority>n)return;if(r.priority===n&&r.backend!==t)throw new Error(`cannot register backend "${e}" using priority ${n}`)}if(n>=0){let t=s.indexOf(e);-1!==t&&s.splice(t,1);for(let t=0;t<s.length;t++)if(i.get(s[t]).priority<=n)return void s.splice(t,0,e);s.push(e)}}},a=async e=>{let t=i.get(e);if(!t)return"backend not found.";if(t.initialized)return t.backend;if(t.aborted)return t.error;{let n=!!t.initPromise;try{return n||(t.initPromise=t.backend.init(e)),await t.initPromise,t.initialized=!0,t.backend}catch(e){return n||(t.error=`${e}`,t.aborted=!0),t.error}finally{delete t.initPromise}}},l=async e=>{let t,n=e.executionProviders||[],r=n.map((e=>"string"==typeof e?e:e.name)),i=0===r.length?s:r,o=[],l=new Set;for(let e of i){let n=await a(e);"string"==typeof n?o.push({name:e,err:n}):(t||(t=n),t===n&&l.add(e))}if(!t)throw new Error(`no available backend found. ERR: ${o.map((e=>`[${e.name}] ${e.err}`)).join(", ")}`);for(let{name:e,err:t}of o)r.includes(e)&&console.warn(`removing requested execution provider "${e}" from session options because it is not available: ${t}`);let d=n.filter((e=>l.has("string"==typeof e?e:e.name)));return[t,new Proxy(e,{get:(e,t)=>"executionProviders"===t?d:Reflect.get(e,t)})]}})),q=V((()=>{G()})),W=V((()=>{d="1.18.0-esmtest.20240411-1abb64e894"})),H=V((()=>{W(),u="warning",c={wasm:{},webgl:{},webgpu:{},versions:{common:d},set logLevel(e){if(void 0!==e){if("string"!=typeof e||-1===["verbose","info","warning","error","fatal"].indexOf(e))throw new Error(`Unsupported logging level: ${e}`);u=e}},get logLevel(){return u}},Object.defineProperty(c,"logLevel",{enumerable:!0})})),X=V((()=>{H(),p=c})),Q=V((()=>{h=(e,t)=>{let n=typeof document<"u"?document.createElement("canvas"):new OffscreenCanvas(1,1);n.width=e.dims[3],n.height=e.dims[2];let r=n.getContext("2d");if(null!=r){let i,s;void 0!==t?.tensorLayout&&"NHWC"===t.tensorLayout?(i=e.dims[2],s=e.dims[3]):(i=e.dims[3],s=e.dims[2]);let o,a,l=void 0!==t?.format?t.format:"RGB",d=t?.norm;void 0===d||void 0===d.mean?o=[255,255,255,255]:"number"==typeof d.mean?o=[d.mean,d.mean,d.mean,d.mean]:(o=[d.mean[0],d.mean[1],d.mean[2],0],void 0!==d.mean[3]&&(o[3]=d.mean[3])),void 0===d||void 0===d.bias?a=[0,0,0,0]:"number"==typeof d.bias?a=[d.bias,d.bias,d.bias,d.bias]:(a=[d.bias[0],d.bias[1],d.bias[2],0],void 0!==d.bias[3]&&(a[3]=d.bias[3]));let u=s*i,c=0,p=u,h=2*u,f=-1;"RGBA"===l?(c=0,p=u,h=2*u,f=3*u):"RGB"===l?(c=0,p=u,h=2*u):"RBG"===l&&(c=0,h=u,p=2*u);for(let t=0;t<s;t++)for(let n=0;n<i;n++){let i=(e.data[c++]-a[0])*o[0],s=(e.data[p++]-a[1])*o[1],l=(e.data[h++]-a[2])*o[2],d=-1===f?255:(e.data[f++]-a[3])*o[3];r.fillStyle="rgba("+i+","+s+","+l+","+d+")",r.fillRect(n,t,1,1)}if("toDataURL"in n)return n.toDataURL();throw new Error("toDataURL is not supported")}throw new Error("Can not access image data")},f=(e,t)=>{let n,r=typeof document<"u"?document.createElement("canvas").getContext("2d"):new OffscreenCanvas(1,1).getContext("2d");if(null==r)throw new Error("Can not access image data");{let i,s,o;void 0!==t?.tensorLayout&&"NHWC"===t.tensorLayout?(i=e.dims[2],s=e.dims[1],o=e.dims[3]):(i=e.dims[3],s=e.dims[2],o=e.dims[1]);let a,l,d=void 0!==t&&void 0!==t.format?t.format:"RGB",u=t?.norm;void 0===u||void 0===u.mean?a=[255,255,255,255]:"number"==typeof u.mean?a=[u.mean,u.mean,u.mean,u.mean]:(a=[u.mean[0],u.mean[1],u.mean[2],255],void 0!==u.mean[3]&&(a[3]=u.mean[3])),void 0===u||void 0===u.bias?l=[0,0,0,0]:"number"==typeof u.bias?l=[u.bias,u.bias,u.bias,u.bias]:(l=[u.bias[0],u.bias[1],u.bias[2],0],void 0!==u.bias[3]&&(l[3]=u.bias[3]));let c=s*i;if(void 0!==t&&(void 0!==t.format&&4===o&&"RGBA"!==t.format||3===o&&"RGB"!==t.format&&"BGR"!==t.format))throw new Error("Tensor format doesn't match input tensor dims");let p=4,h=0,f=1,m=2,g=3,_=0,w=c,y=2*c,b=-1;"RGBA"===d?(_=0,w=c,y=2*c,b=3*c):"RGB"===d?(_=0,w=c,y=2*c):"RBG"===d&&(_=0,y=c,w=2*c),n=r.createImageData(i,s);for(let t=0;t<s*i;h+=p,f+=p,m+=p,g+=p,t++)n.data[h]=(e.data[_++]-l[0])*a[0],n.data[f]=(e.data[w++]-l[1])*a[1],n.data[m]=(e.data[y++]-l[2])*a[2],n.data[g]=-1===b?255:(e.data[b++]-l[3])*a[3]}return n}})),K=V((()=>{J(),m=(e,t)=>{if(void 0===e)throw new Error("Image buffer must be defined");if(void 0===t.height||void 0===t.width)throw new Error("Image height and width must be defined");if("NHWC"===t.tensorLayout)throw new Error("NHWC Tensor layout is not supported yet");let n,r,{height:i,width:s}=t,o=t.norm??{mean:255,bias:0};n="number"==typeof o.mean?[o.mean,o.mean,o.mean,o.mean]:[o.mean[0],o.mean[1],o.mean[2],o.mean[3]??255],r="number"==typeof o.bias?[o.bias,o.bias,o.bias,o.bias]:[o.bias[0],o.bias[1],o.bias[2],o.bias[3]??0];let a=void 0!==t.format?t.format:"RGBA",l=void 0!==t.tensorFormat&&void 0!==t.tensorFormat?t.tensorFormat:"RGB",d=i*s,u="RGBA"===l?new Float32Array(4*d):new Float32Array(3*d),c=4,p=0,h=1,f=2,m=3,g=0,_=d,w=2*d,y=-1;"RGB"===a&&(c=3,p=0,h=1,f=2,m=-1),"RGBA"===l?y=3*d:"RBG"===l?(g=0,w=d,_=2*d):"BGR"===l&&(w=0,_=d,g=2*d);for(let t=0;t<d;t++,p+=c,f+=c,h+=c,m+=c)u[g++]=(e[p]+r[0])/n[0],u[_++]=(e[h]+r[1])/n[1],u[w++]=(e[f]+r[2])/n[2],-1!==y&&-1!==m&&(u[y++]=(e[m]+r[3])/n[3]);return new $("float32",u,"RGBA"===l?[1,4,i,s]:[1,3,i,s])},g=async(e,t)=>{let n,r=typeof HTMLImageElement<"u"&&e instanceof HTMLImageElement,i=typeof ImageData<"u"&&e instanceof ImageData,s=typeof ImageBitmap<"u"&&e instanceof ImageBitmap,o="string"==typeof e,a=t??{},l=()=>{if(typeof document<"u")return document.createElement("canvas");if(typeof OffscreenCanvas<"u")return new OffscreenCanvas(1,1);throw new Error("Canvas is not supported")},d=e=>e instanceof HTMLCanvasElement||e instanceof OffscreenCanvas?e.getContext("2d"):null;if(r){let r=l();r.width=e.width,r.height=e.height;let i=d(r);if(null==i)throw new Error("Can not access image data");{let r=e.height,s=e.width;if(void 0!==t&&void 0!==t.resizedHeight&&void 0!==t.resizedWidth&&(r=t.resizedHeight,s=t.resizedWidth),void 0!==t){if(a=t,void 0!==t.tensorFormat)throw new Error("Image input config format must be RGBA for HTMLImageElement");a.tensorFormat="RGBA",a.height=r,a.width=s}else a.tensorFormat="RGBA",a.height=r,a.width=s;i.drawImage(e,0,0),n=i.getImageData(0,0,s,r).data}}else{if(!i){if(s){if(void 0===t)throw new Error("Please provide image config with format for Imagebitmap");let r=l();r.width=e.width,r.height=e.height;let i=d(r);if(null!=i){let t=e.height,r=e.width;return i.drawImage(e,0,0,r,t),n=i.getImageData(0,0,r,t).data,a.height=t,a.width=r,m(n,a)}throw new Error("Can not access image data")}if(o)return new Promise(((t,n)=>{let r=l(),i=d(r);if(!e||!i)return n();let s=new Image;s.crossOrigin="Anonymous",s.src=e,s.onload=()=>{r.width=s.width,r.height=s.height,i.drawImage(s,0,0,r.width,r.height);let e=i.getImageData(0,0,r.width,r.height);a.height=r.height,a.width=r.width,t(m(e.data,a))}}));throw new Error("Input data provided is not supported - aborted tensor creation")}{let r,i;if(void 0!==t&&void 0!==t.resizedWidth&&void 0!==t.resizedHeight?(r=t.resizedHeight,i=t.resizedWidth):(r=e.height,i=e.width),void 0!==t&&(a=t),a.format="RGBA",a.height=r,a.width=i,void 0!==t){let t=l();t.width=i,t.height=r;let s=d(t);if(null==s)throw new Error("Can not access image data");s.putImageData(e,0,0),n=s.getImageData(0,0,i,r).data}else n=e.data}}if(void 0!==n)return m(n,a);throw new Error("Input data provided is not supported - aborted tensor creation")},_=(e,t)=>{let{width:n,height:r,download:i,dispose:s}=t;return new $({location:"texture",type:"float32",texture:e,dims:[1,r,n,4],download:i,dispose:s})},w=(e,t)=>{let{dataType:n,dims:r,download:i,dispose:s}=t;return new $({location:"gpu-buffer",type:n??"float32",gpuBuffer:e,dims:r,download:i,dispose:s})},y=(e,t,n)=>new $({location:"cpu-pinned",type:e,data:t,dims:n??[t.length]})})),Y=V((()=>{b=new Map([["float32",Float32Array],["uint8",Uint8Array],["int8",Int8Array],["uint16",Uint16Array],["int16",Int16Array],["int32",Int32Array],["bool",Uint8Array],["float64",Float64Array],["uint32",Uint32Array]]),v=new Map([[Float32Array,"float32"],[Uint8Array,"uint8"],[Int8Array,"int8"],[Uint16Array,"uint16"],[Int16Array,"int16"],[Int32Array,"int32"],[Float64Array,"float64"],[Uint32Array,"uint32"]]),x=!1,M=()=>{if(!x){x=!0;let e=typeof BigInt64Array<"u"&&BigInt64Array.from,t=typeof BigUint64Array<"u"&&BigUint64Array.from,n=typeof Float16Array<"u"&&Float16Array.from;e&&(b.set("int64",BigInt64Array),v.set(BigInt64Array,"int64")),t&&(b.set("uint64",BigUint64Array),v.set(BigUint64Array,"uint64")),n?(b.set("float16",Float16Array),v.set(Float16Array,"float16")):b.set("float16",Uint16Array)}}})),Z=V((()=>{J(),T=e=>{let t=1;for(let n=0;n<e.length;n++){let r=e[n];if("number"!=typeof r||!Number.isSafeInteger(r))throw new TypeError(`dims[${n}] must be an integer, got: ${r}`);if(r<0)throw new RangeError(`dims[${n}] must be a non-negative integer, got: ${r}`);t*=r}return t},k=(e,t)=>{switch(e.location){case"cpu":return new $(e.type,e.data,t);case"cpu-pinned":return new $({location:"cpu-pinned",data:e.data,type:e.type,dims:t});case"texture":return new $({location:"texture",texture:e.texture,type:e.type,dims:t});case"gpu-buffer":return new $({location:"gpu-buffer",gpuBuffer:e.gpuBuffer,type:e.type,dims:t});default:throw new Error(`tensorReshape: tensor location ${e.location} is not supported`)}}})),J=V((()=>{Q(),K(),Y(),Z(),$=class{constructor(e,t,n){let r,i;if(M(),"object"==typeof e&&"location"in e)switch(this.dataLocation=e.location,r=e.type,i=e.dims,e.location){case"cpu-pinned":{let t=b.get(r);if(!t)throw new TypeError(`unsupported type "${r}" to create tensor from pinned buffer`);if(!(e.data instanceof t))throw new TypeError(`buffer should be of type ${t.name}`);this.cpuData=e.data;break}case"texture":if("float32"!==r)throw new TypeError(`unsupported type "${r}" to create tensor from texture`);this.gpuTextureData=e.texture,this.downloader=e.download,this.disposer=e.dispose;break;case"gpu-buffer":if("float32"!==r&&"float16"!==r&&"int32"!==r&&"int64"!==r&&"uint32"!==r&&"uint8"!==r&&"bool"!==r)throw new TypeError(`unsupported type "${r}" to create tensor from gpu buffer`);this.gpuBufferData=e.gpuBuffer,this.downloader=e.download,this.disposer=e.dispose;break;default:throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`)}else{let s,o;if("string"==typeof e)if(r=e,o=n,"string"===e){if(!Array.isArray(t))throw new TypeError("A string tensor's data must be a string array.");s=t}else{let n=b.get(e);if(void 0===n)throw new TypeError(`Unsupported tensor type: ${e}.`);if(Array.isArray(t)){if("float16"===e&&n===Uint16Array)throw new TypeError("Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.");s="uint64"===e||"int64"===e?n.from(t,BigInt):n.from(t)}else{if(!(t instanceof n))throw new TypeError(`A ${r} tensor's data must be type of ${n}`);s=t}}else if(o=t,Array.isArray(e)){if(0===e.length)throw new TypeError("Tensor type cannot be inferred from an empty array.");let t=typeof e[0];if("string"===t)r="string",s=e;else{if("boolean"!==t)throw new TypeError(`Invalid element type of data array: ${t}.`);r="bool",s=Uint8Array.from(e)}}else{let t=v.get(e.constructor);if(void 0===t)throw new TypeError(`Unsupported type for tensor data: ${e.constructor}.`);r=t,s=e}if(void 0===o)o=[s.length];else if(!Array.isArray(o))throw new TypeError("A tensor's dims must be a number array");i=o,this.cpuData=s,this.dataLocation="cpu"}let s=T(i);if(this.cpuData&&s!==this.cpuData.length)throw new Error(`Tensor's size(${s}) does not match data length(${this.cpuData.length}).`);this.type=r,this.dims=i,this.size=s}static async fromImage(e,t){return g(e,t)}static fromTexture(e,t){return _(e,t)}static fromGpuBuffer(e,t){return w(e,t)}static fromPinnedBuffer(e,t,n){return y(e,t,n)}toDataURL(e){return h(this,e)}toImageData(e){return f(this,e)}get data(){if(this.ensureValid(),!this.cpuData)throw new Error("The data is not on CPU. Use `getData()` to download GPU data to CPU, or use `texture` or `gpuBuffer` property to access the GPU data directly.");return this.cpuData}get location(){return this.dataLocation}get texture(){if(this.ensureValid(),!this.gpuTextureData)throw new Error("The data is not stored as a WebGL texture.");return this.gpuTextureData}get gpuBuffer(){if(this.ensureValid(),!this.gpuBufferData)throw new Error("The data is not stored as a WebGPU buffer.");return this.gpuBufferData}async getData(e){switch(this.ensureValid(),this.dataLocation){case"cpu":case"cpu-pinned":return this.data;case"texture":case"gpu-buffer":if(!this.downloader)throw new Error("The current tensor is not created with a specified data downloader.");if(this.isDownloading)throw new Error("The current tensor is being downloaded.");try{this.isDownloading=!0;let t=await this.downloader();return this.downloader=void 0,this.dataLocation="cpu",this.cpuData=t,e&&this.disposer&&(this.disposer(),this.disposer=void 0),t}finally{this.isDownloading=!1}default:throw new Error(`cannot get data from location: ${this.dataLocation}`)}}dispose(){if(this.isDownloading)throw new Error("The current tensor is being downloaded.");this.disposer&&(this.disposer(),this.disposer=void 0),this.cpuData=void 0,this.gpuTextureData=void 0,this.gpuBufferData=void 0,this.downloader=void 0,this.isDownloading=void 0,this.dataLocation="none"}ensureValid(){if("none"===this.dataLocation)throw new Error("The tensor is disposed.")}reshape(e){if(this.ensureValid(),this.downloader||this.disposer)throw new Error("Cannot reshape a tensor that owns GPU resource.");return k(this,e)}}})),ee=V((()=>{J(),S=$})),te=V((()=>{H(),C=(e,t)=>{(typeof c.trace>"u"?!c.wasm.trace:!c.trace)||console.timeStamp(`${e}::ORT::${t}`)},P=(e,t)=>{let n=(new Error).stack?.split(/\r\n|\r|\n/g)||[],r=!1;for(let i=0;i<n.length;i++){if(r&&!n[i].includes("TRACE_FUNC")){let r=`FUNC_${e}::${n[i].trim().split(" ")[1]}`;return t&&(r+=`::${t}`),void C("CPU",r)}n[i].includes("TRACE_FUNC")&&(r=!0)}},E=e=>{(typeof c.trace>"u"?!c.wasm.trace:!c.trace)||P("BEGIN",e)},A=e=>{(typeof c.trace>"u"?!c.wasm.trace:!c.trace)||P("END",e)}})),ne=V((()=>{G(),ee(),te(),F=class e{constructor(e){this.handler=e}async run(e,t,n){E();let r={},i={};if("object"!=typeof e||null===e||e instanceof S||Array.isArray(e))throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");let s=!0;if("object"==typeof t){if(null===t)throw new TypeError("Unexpected argument[1]: cannot be null.");if(t instanceof S)throw new TypeError("'fetches' cannot be a Tensor");if(Array.isArray(t)){if(0===t.length)throw new TypeError("'fetches' cannot be an empty array.");s=!1;for(let e of t){if("string"!=typeof e)throw new TypeError("'fetches' must be a string array or an object.");if(-1===this.outputNames.indexOf(e))throw new RangeError(`'fetches' contains invalid output name: ${e}.`);r[e]=null}if("object"==typeof n&&null!==n)i=n;else if(typeof n<"u")throw new TypeError("'options' must be an object.")}else{let e=!1,o=Object.getOwnPropertyNames(t);for(let n of this.outputNames)if(-1!==o.indexOf(n)){let i=t[n];(null===i||i instanceof S)&&(e=!0,s=!1,r[n]=i)}if(e){if("object"==typeof n&&null!==n)i=n;else if(typeof n<"u")throw new TypeError("'options' must be an object.")}else i=t}}else if(typeof t<"u")throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");for(let t of this.inputNames)if(typeof e[t]>"u")throw new Error(`input '${t}' is missing in 'feeds'.`);if(s)for(let e of this.outputNames)r[e]=null;let o=await this.handler.run(e,r,i),a={};for(let e in o)if(Object.hasOwnProperty.call(o,e)){let t=o[e];a[e]=t instanceof S?t:new S(t.type,t.data,t.dims)}return A(),a}async release(){return this.handler.dispose()}static async create(t,n,r,i){E();let s,o={};if("string"==typeof t){if(s=t,"object"==typeof n&&null!==n)o=n;else if(typeof n<"u")throw new TypeError("'options' must be an object.")}else if(t instanceof Uint8Array){if(s=t,"object"==typeof n&&null!==n)o=n;else if(typeof n<"u")throw new TypeError("'options' must be an object.")}else{if(!(t instanceof ArrayBuffer||typeof SharedArrayBuffer<"u"&&t instanceof SharedArrayBuffer))throw new TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");{let e=t,a=0,l=t.byteLength;if("object"==typeof n&&null!==n)o=n;else if("number"==typeof n){if(a=n,!Number.isSafeInteger(a))throw new RangeError("'byteOffset' must be an integer.");if(a<0||a>=e.byteLength)throw new RangeError(`'byteOffset' is out of range [0, ${e.byteLength}).`);if(l=t.byteLength-a,"number"==typeof r){if(l=r,!Number.isSafeInteger(l))throw new RangeError("'byteLength' must be an integer.");if(l<=0||a+l>e.byteLength)throw new RangeError(`'byteLength' is out of range (0, ${e.byteLength-a}].`);if("object"==typeof i&&null!==i)o=i;else if(typeof i<"u")throw new TypeError("'options' must be an object.")}else if(typeof r<"u")throw new TypeError("'byteLength' must be a number.")}else if(typeof n<"u")throw new TypeError("'options' must be an object.");s=new Uint8Array(e,a,l)}}let[a,d]=await l(o),u=await a.createInferenceSessionHandler(s,d);return A(),new e(u)}startProfiling(){this.handler.startProfiling()}endProfiling(){this.handler.endProfiling()}get inputNames(){return this.handler.inputNames}get outputNames(){return this.handler.outputNames}}})),re=V((()=>{ne(),I=F})),ie=V((()=>{})),se=V((()=>{})),oe=V((()=>{})),ae=V((()=>{})),le=V((()=>{G(),ee(),"Training backend could not be resolved. Make sure you're using the correct configuration & WebAssembly files.",z=class e{constructor(e,t,n){this.handler=e,this.hasOptimizerModel=t,this.hasEvalModel=n}get trainingInputNames(){return this.handler.inputNames}get trainingOutputNames(){return this.handler.outputNames}get evalInputNames(){if(this.hasEvalModel)return this.handler.evalInputNames;throw new Error("This training session has no evalModel loaded.")}get evalOutputNames(){if(this.hasEvalModel)return this.handler.evalOutputNames;throw new Error("This training session has no evalModel loaded.")}static async create(t,n){let r=t.evalModel||"",i=t.optimizerModel||"",s=n||{},[o,a]=await l(s);if(o.createTrainingSessionHandler){let n=await o.createTrainingSessionHandler(t.checkpointState,t.trainModel,r,i,a);return new e(n,!!t.optimizerModel,!!t.evalModel)}throw new Error("Training backend could not be resolved. Make sure you're using the correct configuration & WebAssembly files.")}typeNarrowingForRunStep(e,t,n,r,i){let s={},o={};if("object"!=typeof n||null===n||n instanceof S||Array.isArray(n))throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");let a=!0;if("object"==typeof r){if(null===r)throw new TypeError("Unexpected argument[1]: cannot be null.");if(r instanceof S)throw new TypeError("'fetches' cannot be a Tensor");if(Array.isArray(r)){if(0===r.length)throw new TypeError("'fetches' cannot be an empty array.");a=!1;for(let e of r){if("string"!=typeof e)throw new TypeError("'fetches' must be a string array or an object.");if(-1===t.indexOf(e))throw new RangeError(`'fetches' contains invalid output name: ${e}.`);s[e]=null}if("object"==typeof i&&null!==i)o=i;else if(typeof i<"u")throw new TypeError("'options' must be an object.")}else{let e=!1,n=Object.getOwnPropertyNames(r);for(let i of t)if(-1!==n.indexOf(i)){let t=r[i];(null===t||t instanceof S)&&(e=!0,a=!1,s[i]=t)}if(e){if("object"==typeof i&&null!==i)o=i;else if(typeof i<"u")throw new TypeError("'options' must be an object.")}else o=r}}else if(typeof r<"u")throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");for(let t of e)if(typeof n[t]>"u")throw new Error(`input '${t}' is missing in 'feeds'.`);if(a)for(let e of t)s[e]=null;return[s,o]}convertHandlerReturnTypeToMapOfTensors(e){let t={};for(let n in e)if(Object.hasOwnProperty.call(e,n)){let r=e[n];t[n]=r instanceof S?r:new S(r.type,r.data,r.dims)}return t}async lazyResetGrad(){await this.handler.lazyResetGrad()}async runTrainStep(e,t,n){let[r,i]=this.typeNarrowingForRunStep(this.trainingInputNames,this.trainingOutputNames,e,t,n),s=await this.handler.runTrainStep(e,r,i);return this.convertHandlerReturnTypeToMapOfTensors(s)}async runOptimizerStep(e){if(!this.hasOptimizerModel)throw new Error("This TrainingSession has no OptimizerModel loaded.");await this.handler.runOptimizerStep(e||{})}async runEvalStep(e,t,n){if(this.hasEvalModel){let[r,i]=this.typeNarrowingForRunStep(this.evalInputNames,this.evalOutputNames,e,t,n),s=await this.handler.runEvalStep(e,r,i);return this.convertHandlerReturnTypeToMapOfTensors(s)}throw new Error("This TrainingSession has no EvalModel loaded.")}async getParametersSize(e=!0){return this.handler.getParametersSize(e)}async loadParametersBuffer(e,t=!0){let n=await this.getParametersSize(t);if(e.length!==4*n)throw new Error("Size of the buffer passed into loadParametersBuffer must match the number of parameters in the model. Please use getParametersSize method to check.");return this.handler.loadParametersBuffer(e,t)}async getContiguousParameters(e=!0){return this.handler.getContiguousParameters(e)}async release(){return this.handler.dispose()}}})),de=V((()=>{le(),B=z})),ue={};j(ue,{InferenceSession:()=>I,TRACE:()=>C,TRACE_FUNC_BEGIN:()=>E,TRACE_FUNC_END:()=>A,Tensor:()=>S,TrainingSession:()=>B,env:()=>p,registerBackend:()=>o});var ce,pe,he,fe,me,ge,_e,we,ye,be,ve,xe,Me,Te,ke,$e,Se,Ce,Pe,Ee,Ae,Fe,Ie,ze,Be,Oe,Le,De,Re,Ne,Ve,je,Ue,Ge,qe,We,He,Xe,Qe,Ke,Ye,Ze,Je,et,tt,nt,rt,it,st,ot,at,lt,dt,ut,ct,pt,ht,ft,mt,gt,_t,wt,yt,bt,vt,xt,Mt,Tt,kt,$t,St,Ct,Pt,Et,At,Ft,It,zt,Bt,Ot,Lt,Dt,Rt,Nt,Vt,jt,Ut,Gt,qt,Wt,Ht,Xt,Qt,Kt,Yt,Zt,Jt,en,tn,nn,rn,sn,on,an,ln,dn,un,cn,pn,hn,fn,mn,gn,_n,wn,yn,bn,vn,xn,Mn,Tn,kn,$n,Sn,Cn,Pn,En,An,Fn,In,zn,Bn,On,Ln,Dn,Rn,Nn,Vn,jn,Un,Gn,qn,Wn,Hn,Xn,Qn,Kn,Yn,Zn,Jn,er,tr,nr,rr,ir,sr,or,ar,lr,dr,ur,cr,pr,hr,fr,mr,gr,_r,wr,yr,br,vr,xr,Mr,Tr,kr,$r,Sr,Cr,Pr,Er,Ar,Fr,Ir,zr,Br,Or,Lr,Dr,Rr,Nr,Vr,jr,Ur,Gr,qr,Wr,Hr,Xr,Qr,Kr,Yr,Zr,Jr,ei,ti,ni,ri,ii,si,oi,ai,li,di,ui,ci,pi,hi,fi,mi,gi,_i,wi,yi,bi,vi,xi,Mi,Ti,ki,$i,Si,Ci,Pi,Ei,Ai,Fi,Ii,zi,Bi,Oi,Li,Di,Ri,Ni,Vi,ji,Ui,Gi,qi,Wi,Hi,Xi,Qi,Ki,Yi,Zi,Ji,es,ts,ns,rs,is,ss,os,as,ls,ds,us,cs,ps,hs,fs,ms,gs,_s,ws,ys,bs,vs,xs,Ms,Ts,ks,$s,Ss,Cs,Ps,Es,As,Fs,Is,zs,Bs,Os,Ls,Ds,Rs,Ns,Vs,js,Us,Gs,qs,Ws,Hs,Xs,Qs,Ks,Ys,Zs,Js,eo,to,no,ro,io,so,oo,ao,lo,uo,co,po,ho,fo,mo,go,_o,wo,yo,bo,vo,xo,Mo,To,ko,$o,So,Co,Po,Eo,Ao,Fo,Io,zo,Bo,Oo,Lo,Do,Ro,No,Vo,jo,Uo,Go,qo,Wo,Ho,Xo,Qo,Ko,Yo,Zo,Jo,ea,ta,na,ra,ia,sa,oa,aa,la,da,ua,ca,pa,ha,fa,ma,ga,_a,wa,ya,ba,va,xa,Ma,Ta=V((()=>{q(),X(),re(),ee(),ie(),se(),te(),oe(),ae(),de()})),ka=V((()=>{ce=!!(typeof process<"u"&&process.versions&&process.versions.node)})),$a=V((()=>{ka(),pe=ce?void 0:"file:///home/belem/github/transformers.js/node_modules/onnxruntime-web/dist/ort.webgpu.min.mjs",he=ce||typeof location>"u"?void 0:location.origin,fe=async(e,t)=>(await import(`${t??"./"}${e}`)).default,me=async(e,t)=>{if(ce)return e;let n;try{n=t?new URL(e,t):new URL(e)}catch{return e}if(he&&n.origin!==he)try{let e=await(await fetch(n)).blob();return URL.createObjectURL(e)}catch(n){console.warn(`Failed to preload worker from FileName="${e}", Base="${t??""}": ${n}`)}return n.href}})),Sa=V((()=>{$a(),_e=!1,we=!1,ye=!1,be=e=>{if(1===e)return!1;if(typeof SharedArrayBuffer>"u")return typeof self<"u"&&!self.crossOriginIsolated&&console.warn("env.wasm.numThreads is set to "+e+", but this will not work unless you enable crossOriginIsolated mode. See https://web.dev/cross-origin-isolation-guide/ for more info."),!1;try{return typeof MessageChannel<"u"&&(new MessageChannel).port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11]))}catch{return!1}},ve=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch{return!1}},xe=(e,t)=>e?t?"ort-wasm-simd-threaded.jsep":"ort-wasm-simd.jsep":t?"ort-wasm-threaded":"ort-wasm",Me=async e=>{if(_e)return Promise.resolve();if(we)throw new Error("multiple calls to 'initializeWebAssembly()' detected.");if(ye)throw new Error("previous call to 'initializeWebAssembly()' failed.");we=!0;let t=e.initTimeout,n=e.numThreads,r=e.simd,i=be(n),s=r&&ve(),o=e.wasmPaths,a="string"==typeof o?o:void 0,l=xe(s,i),d="object"==typeof o?o[`${l}.wasm`]:void 0,u=await fe(`${l}.mjs`,a),c=i?`${l}.worker.js`:"",p=i?await me(`${l}.worker.js`,a??pe):"",h=!1,f=[];if(t>0&&f.push(new Promise((e=>{setTimeout((()=>{h=!0,e()}),t)}))),f.push(new Promise(((e,t)=>{let r={locateFile:(e,t)=>e.endsWith(".wasm")&&d?d:i&&e===c&&p!==c?p:(a??t)+e};i&&(r.numThreads=n,a&&(r.mainScriptUrlOrBlob=a+`${l}.mjs`)),u(r).then((t=>{we=!1,_e=!0,ge=t,e()}),(e=>{we=!1,ye=!0,t(e)}))}))),await Promise.race(f),h)throw new Error(`WebAssembly backend initializing failed due to timeout: ${t}ms`)},Te=()=>{if(_e&&ge)return ge;throw new Error("WebAssembly is not initialized yet.")}})),Ca=V((()=>{Sa(),ke=(e,t)=>{let n=Te(),r=n.lengthBytesUTF8(e)+1,i=n._malloc(r);return n.stringToUTF8(e,i,r),t.push(i),i},$e=(e,t,n,r)=>{if("object"==typeof e&&null!==e){if(n.has(e))throw new Error("Circular reference in options");n.add(e)}Object.entries(e).forEach((([e,i])=>{let s=t?t+e:e;if("object"==typeof i)$e(i,s+".",n,r);else if("string"==typeof i||"number"==typeof i)r(s,i.toString());else{if("boolean"!=typeof i)throw new Error("Can't handle extra config type: "+typeof i);r(s,i?"1":"0")}}))},Se=e=>{let t=Te(),n=t.stackSave();try{let n=t.stackAlloc(8);t._OrtGetLastError(n,n+4);let r=t.HEAP32[n/4],i=t.HEAPU32[n/4+1],s=i?t.UTF8ToString(i):"";throw new Error(`${e} ERROR_CODE: ${r}, ERROR_MESSAGE: ${s}`)}finally{t.stackRestore(n)}}})),Pa=V((()=>{Sa(),Ca(),Ce=e=>{let t=Te(),n=0,r=[],i=e||{};try{if(void 0===e?.logSeverityLevel)i.logSeverityLevel=2;else if("number"!=typeof e.logSeverityLevel||!Number.isInteger(e.logSeverityLevel)||e.logSeverityLevel<0||e.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${e.logSeverityLevel}`);if(void 0===e?.logVerbosityLevel)i.logVerbosityLevel=0;else if("number"!=typeof e.logVerbosityLevel||!Number.isInteger(e.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${e.logVerbosityLevel}`);void 0===e?.terminate&&(i.terminate=!1);let s=0;return void 0!==e?.tag&&(s=ke(e.tag,r)),n=t._OrtCreateRunOptions(i.logSeverityLevel,i.logVerbosityLevel,!!i.terminate,s),0===n&&Se("Can't create run options."),void 0!==e?.extra&&$e(e.extra,"",new WeakSet,((e,i)=>{let s=ke(e,r),o=ke(i,r);0!==t._OrtAddRunConfigEntry(n,s,o)&&Se(`Can't set a run config entry: ${e} - ${i}.`)})),[n,r]}catch(e){throw 0!==n&&t._OrtReleaseRunOptions(n),r.forEach((e=>t._free(e))),e}}})),Ea=V((()=>{Sa(),Ca(),Pe=e=>{switch(e){case"disabled":return 0;case"basic":return 1;case"extended":return 2;case"all":return 99;default:throw new Error(`unsupported graph optimization level: ${e}`)}},Ee=e=>{switch(e){case"sequential":return 0;case"parallel":return 1;default:throw new Error(`unsupported execution mode: ${e}`)}},Ae=e=>{e.extra||(e.extra={}),e.extra.session||(e.extra.session={});let t=e.extra.session;t.use_ort_model_bytes_directly||(t.use_ort_model_bytes_directly="1"),e.executionProviders&&e.executionProviders.some((e=>"webgpu"===("string"==typeof e?e:e.name)))&&(e.enableMemPattern=!1)},Fe=(e,t,n)=>{for(let r of t){let t="string"==typeof r?r:r.name;switch(t){case"webnn":if(t="WEBNN","string"!=typeof r){let t=r;if(t?.deviceType){let r=ke("deviceType",n),i=ke(t.deviceType,n);0!==Te()._OrtAddSessionConfigEntry(e,r,i)&&Se(`Can't set a session config entry: 'deviceType' - ${t.deviceType}.`)}if(t?.numThreads){let r=t.numThreads;("number"!=typeof r||!Number.isInteger(r)||r<0)&&(r=0);let i=ke("numThreads",n),s=ke(r.toString(),n);0!==Te()._OrtAddSessionConfigEntry(e,i,s)&&Se(`Can't set a session config entry: 'numThreads' - ${t.numThreads}.`)}if(t?.powerPreference){let r=ke("powerPreference",n),i=ke(t.powerPreference,n);0!==Te()._OrtAddSessionConfigEntry(e,r,i)&&Se(`Can't set a session config entry: 'powerPreference' - ${t.powerPreference}.`)}}break;case"webgpu":if(t="JS","string"!=typeof r){let t=r;if(t?.preferredLayout){if("NCHW"!==t.preferredLayout&&"NHWC"!==t.preferredLayout)throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${t.preferredLayout}`);let r=ke("preferredLayout",n),i=ke(t.preferredLayout,n);0!==Te()._OrtAddSessionConfigEntry(e,r,i)&&Se(`Can't set a session config entry: 'preferredLayout' - ${t.preferredLayout}.`)}}break;case"wasm":case"cpu":continue;default:throw new Error(`not supported execution provider: ${t}`)}let i=ke(t,n);0!==Te()._OrtAppendExecutionProvider(e,i)&&Se(`Can't append execution provider: ${t}.`)}},Ie=e=>{let t=Te(),n=0,r=[],i=e||{};Ae(i);try{let e=Pe(i.graphOptimizationLevel??"all"),s=Ee(i.executionMode??"sequential"),o="string"==typeof i.logId?ke(i.logId,r):0,a=i.logSeverityLevel??2;if(!Number.isInteger(a)||a<0||a>4)throw new Error(`log serverity level is not valid: ${a}`);let l=i.logVerbosityLevel??0;if(!Number.isInteger(l)||l<0||l>4)throw new Error(`log verbosity level is not valid: ${l}`);let d="string"==typeof i.optimizedModelFilePath?ke(i.optimizedModelFilePath,r):0;if(n=t._OrtCreateSessionOptions(e,!!i.enableCpuMemArena,!!i.enableMemPattern,s,!!i.enableProfiling,0,o,a,l,d),0===n&&Se("Can't create session options."),i.executionProviders&&Fe(n,i.executionProviders,r),void 0!==i.enableGraphCapture){if("boolean"!=typeof i.enableGraphCapture)throw new Error(`enableGraphCapture must be a boolean value: ${i.enableGraphCapture}`);let e=ke("enableGraphCapture",r),s=ke(i.enableGraphCapture.toString(),r);0!==t._OrtAddSessionConfigEntry(n,e,s)&&Se(`Can't set a session config entry: 'enableGraphCapture' - ${i.enableGraphCapture}.`)}if(i.freeDimensionOverrides)for(let[e,s]of Object.entries(i.freeDimensionOverrides)){if("string"!=typeof e)throw new Error(`free dimension override name must be a string: ${e}`);if("number"!=typeof s||!Number.isInteger(s)||s<0)throw new Error(`free dimension override value must be a non-negative integer: ${s}`);let i=ke(e,r);0!==t._OrtAddFreeDimensionOverride(n,i,s)&&Se(`Can't set a free dimension override: ${e} - ${s}.`)}return void 0!==i.extra&&$e(i.extra,"",new WeakSet,((e,i)=>{let s=ke(e,r),o=ke(i,r);0!==t._OrtAddSessionConfigEntry(n,s,o)&&Se(`Can't set a session config entry: ${e} - ${i}.`)})),[n,r]}catch(e){throw 0!==n&&t._OrtReleaseSessionOptions(n),r.forEach((e=>t._free(e))),e}}})),Aa=V((()=>{ze=e=>{switch(e){case"int8":return 3;case"uint8":return 2;case"bool":return 9;case"int16":return 5;case"uint16":return 4;case"int32":return 6;case"uint32":return 12;case"float16":return 10;case"float32":return 1;case"float64":return 11;case"string":return 8;case"int64":return 7;case"uint64":return 13;default:throw new Error(`unsupported data type: ${e}`)}},Be=e=>{switch(e){case 3:return"int8";case 2:return"uint8";case 9:return"bool";case 5:return"int16";case 4:return"uint16";case 6:return"int32";case 12:return"uint32";case 10:return"float16";case 1:return"float32";case 11:return"float64";case 8:return"string";case 7:return"int64";case 13:return"uint64";default:throw new Error(`unsupported data type: ${e}`)}},Oe=e=>[void 0,4,1,1,2,2,4,8,void 0,1,2,8,4,8,void 0,void 0,void 0][e],Le=e=>{switch(e){case"float16":return typeof Float16Array<"u"&&Float16Array.from?Float16Array:Uint16Array;case"float32":return Float32Array;case"uint8":case"bool":return Uint8Array;case"int8":return Int8Array;case"uint16":return Uint16Array;case"int16":return Int16Array;case"int32":return Int32Array;case"float64":return Float64Array;case"uint32":return Uint32Array;case"int64":return BigInt64Array;case"uint64":return BigUint64Array;default:throw new Error(`unsupported type: ${e}`)}},De=e=>{switch(e){case"verbose":return 0;case"info":return 1;case"warning":return 2;case"error":return 3;case"fatal":return 4;default:throw new Error(`unsupported logging level: ${e}`)}},Re=e=>"float32"===e||"float16"===e||"int32"===e||"int64"===e||"uint32"===e||"uint8"===e||"bool"===e,Ne=e=>{switch(e){case"none":return 0;case"cpu":return 1;case"cpu-pinned":return 2;case"texture":return 3;case"gpu-buffer":return 4;default:throw new Error(`unsupported data location: ${e}`)}}})),Fa=V((()=>{ka(),Ve=async e=>{if("string"!=typeof e)return e instanceof Blob?new Uint8Array(await e.arrayBuffer()):e instanceof Uint8Array?e:new Uint8Array(e);if(!ce){let t=await fetch(e);if(!t.ok)throw new Error(`failed to load external data file: ${e}`);let n=t.headers.get("Content-Length"),r=n?parseInt(n,10):0;if(r<1073741824)return new Uint8Array(await t.arrayBuffer());{if(!t.body)throw new Error(`failed to load external data file: ${e}, no response body.`);let n,i=t.body.getReader();try{n=new ArrayBuffer(r)}catch(e){if(!(e instanceof RangeError))throw e;{let e=Math.ceil(r/65536);n=new WebAssembly.Memory({initial:e,maximum:e}).buffer}}let s=0;for(;;){let{done:e,value:t}=await i.read();if(e)break;let r=t.byteLength;new Uint8Array(n,s,r).set(t),s+=r}return new Uint8Array(n,0,r)}}try{let{readFile:t}=N("node:fs/promises");return new Uint8Array(await t(e))}catch(t){if("ERR_FS_FILE_TOO_LARGE"===t.code){let{createReadStream:t}=N("node:fs"),n=t(e),r=[];for await(let e of n)r.push(e);return new Uint8Array(Buffer.concat(r))}throw t}}})),Ia=V((()=>{Aa(),je=["V","I","W","E","F"],Ue=(e,t)=>{console.log(`[${je[e]},${(new Date).toISOString()}]${t}`)},We=(e,t)=>{Ge=e,qe=t},He=(e,t)=>{let n=De(e);n>=De(Ge)&&Ue(n,"function"==typeof t?t():t)},Xe=(...e)=>{qe&&He(...e)}})),za=V((()=>{Aa(),Qe=(e,t)=>new(Le(t))(e)})),Ba=V((()=>{})),Oa=V((()=>{Ia(),Ba(),Ke=e=>16*Math.ceil(e/16),Ye=1,Ze=()=>Ye++,Je=async(e,t,n,r)=>{let i=Ke(n),s=e.device.createBuffer({size:i,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ});try{let o=e.getCommandEncoder();e.endComputePass(),o.copyBufferToBuffer(t,0,s,0,i),e.flush(),await s.mapAsync(GPUMapMode.READ);let a=s.getMappedRange();if(r){let e=r();return e.set(new Uint8Array(a,0,n)),e}return new Uint8Array(a.slice(0,n))}finally{s.destroy()}},et=class{constructor(e){this.backend=e,this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.buffersForUploadingPending=[],this.buffersPending=[],this.externalBuffers=new Map,this.capturedPendingBuffers=new Map}upload(e,t){let n=t.buffer,r=t.byteOffset,i=t.byteLength,s=Ke(i),o=this.storageCache.get(e);if(!o)throw new Error("gpu data for uploading does not exist");if(o.originalSize!==i)throw new Error(`inconsistent data size. gpu data size=${o.originalSize}, data size=${i}`);let a=this.backend.device.createBuffer({mappedAtCreation:!0,size:s,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC}),l=a.getMappedRange();new Uint8Array(l).set(new Uint8Array(n,r,i)),a.unmap();let d=this.backend.getCommandEncoder();this.backend.endComputePass(),d.copyBufferToBuffer(a,0,o.gpuData.buffer,0,s),Xe("verbose",(()=>`[WebGPU] GpuDataManager.upload(id=${e})`)),this.buffersForUploadingPending.push(a)}memcpy(e,t){let n=this.storageCache.get(e);if(!n)throw new Error("source gpu data for memcpy does not exist");let r=this.storageCache.get(t);if(!r)throw new Error("destination gpu data for memcpy does not exist");if(n.originalSize!==r.originalSize)throw new Error("inconsistent source and destination gpu data size");let i=Ke(n.originalSize),s=this.backend.getCommandEncoder();this.backend.endComputePass(),s.copyBufferToBuffer(n.gpuData.buffer,0,r.gpuData.buffer,0,i)}registerExternalBuffer(e,t,n){let r;if(n){if(r=this.externalBuffers.get(n),void 0===r)throw new Error("previous buffer is not registered");if(e===n)return Xe("verbose",(()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${t}) => id=${r}, buffer is the same, skip.`)),r;if(this.backend.capturedCommandList.has(this.backend.currentSessionId))throw new Error("Registering a different external buffer under graph capture mode is not supported yet.\n             Please use the previous external buffer!");this.externalBuffers.delete(n)}else r=Ze();return this.storageCache.set(r,{gpuData:{id:r,type:0,buffer:e},originalSize:t}),this.externalBuffers.set(e,r),Xe("verbose",(()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${t}) => id=${r}, registered.`)),r}unregisterExternalBuffer(e){let t=this.externalBuffers.get(e);void 0!==t&&(this.storageCache.delete(t),this.externalBuffers.delete(e),Xe("verbose",(()=>`[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${t}`)))}create(e,t=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){let n,r=Ke(e),i=(t&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE,s=(t&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM;if(i||s){let e=i?this.freeBuffers:this.freeUniformBuffers,s=e.get(r);s||(s=[],e.set(r,s)),n=s.length>0?s.pop():this.backend.device.createBuffer({size:r,usage:t})}else n=this.backend.device.createBuffer({size:r,usage:t});let o={id:Ze(),type:0,buffer:n};return this.storageCache.set(o.id,{gpuData:o,originalSize:e}),Xe("verbose",(()=>`[WebGPU] GpuDataManager.create(size=${e}) => id=${o.id}`)),o}get(e){return this.storageCache.get(e)?.gpuData}release(e){let t=this.storageCache.get(e);if(!t)throw new Error("releasing data does not exist");return Xe("verbose",(()=>`[WebGPU] GpuDataManager.release(id=${e}), gpuDataId=${t.gpuData.id}`)),this.storageCache.delete(e),this.buffersPending.push(t.gpuData.buffer),t.originalSize}async download(e,t){let n=this.storageCache.get(e);if(!n)throw new Error("data does not exist");await Je(this.backend,n.gpuData.buffer,n.originalSize,t)}refreshPendingBuffers(){for(let e of this.buffersForUploadingPending)e.destroy();if(this.buffersForUploadingPending=[],0!==this.buffersPending.length)if("default"===this.backend.sessionStatus){for(let e of this.buffersPending)(e.usage&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE?this.freeBuffers.get(e.size).push(e):(e.usage&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM?this.freeUniformBuffers.get(e.size).push(e):e.destroy();this.buffersPending=[]}else{let e=this.capturedPendingBuffers.get(this.backend.currentSessionId);e||(e=[],this.capturedPendingBuffers.set(this.backend.currentSessionId,e));for(let t of this.buffersPending)e.push(t);this.buffersPending=[]}}dispose(){this.freeBuffers.forEach((e=>{e.forEach((e=>{e.destroy()}))})),this.freeUniformBuffers.forEach((e=>{e.forEach((e=>{e.destroy()}))})),this.storageCache.forEach((e=>{e.gpuData.buffer.destroy()})),this.capturedPendingBuffers.forEach((e=>{e.forEach((e=>{e.destroy()}))})),this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.capturedPendingBuffers=new Map}onReleaseSession(e){let t=this.capturedPendingBuffers.get(e);t&&(t.forEach((e=>{e.destroy()})),this.capturedPendingBuffers.delete(e))}},tt=(...e)=>new et(...e)})),La=V((()=>{nt=class{constructor(e){Object.assign(this,e)}get cacheKey(){return this.key||(this.key=Object.getOwnPropertyNames(this).sort().map((e=>`${this[e]}`)).join(";")),this.key}},rt=e=>new nt(e)})),Da=V((()=>{it=class{static calcMatMulShape(e,t){return e[1]!==t[0]?void 0:[e[0],t[1]]}},st=class{static calcShape(e,t,n=!1){let r=e.length,i=t.length;if(0===r)return t;if(0===i)return e;let s=Math.max(e.length,t.length),o=new Array(s);if(n){if(r<2||i<2)return;let n=it.calcMatMulShape([e[r-2],e[r-1]],[t[i-2],t[i-1]]);if(void 0===n)return;[o[s-2],o[s-1]]=n}for(let a=n?3:1;a<=s;a++){let n=r-a<0?1:e[r-a],l=i-a<0?1:t[i-a];if(n!==l&&n>1&&l>1)return;let d=Math.max(n,l);if(n&&l)o[s-a]=Math.max(n,l);else{if(d>1)return;o[s-a]=0}}return o}static isValidBroadcast(e,t){let n=e.length,r=t.length;if(n>r)return!1;for(let i=1;i<=n;i++)if(1!==e[n-i]&&e[n-i]!==t[r-i])return!1;return!0}},ot=class e{static size(t){return e.getSizeFromDimensionRange(t,0,t.length)}static convertShape(e,t=4){let n=e.length;if(0===n)return[];let r=new Array(n),i=n-1;for(;i>=0;){if(e[i]%t==0){r[i]=e[i]/t;break}if(t%e[i]!=0)throw new Error("cannot convert shape");r[i]=1,t/=e[i],i--}for(i--;i>=0;i--)r[i]=e[i];return r}static sizeFromDimension(t,n){if(n<0||n>t.length)throw new Error(`invalid dimension of ${n} for sizeFromDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,n,t.length)}static sizeToDimension(t,n){if(n<0||n>t.length)throw new Error(`invalid dimension of ${n} for sizeToDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,0,n)}static getSizeFromDimensionRange(e,t,n){let r=1;for(let i=t;i<n;i++){if(e[i]<0)throw new Error("cannot get valid size from specified dimension range. Most likely the range contains negative values in them.");r*=e[i]}return r}static computeStrides(e){let t=e.length;if(0===t)return[];if(1===t)return[1];let n=new Array(t);n[t-1]=1,n[t-2]=e[t-1];for(let r=t-3;r>=0;--r)n[r]=n[r+1]*e[r+1];return n}static normalizeAxis(e,t){if(e<-t&&e>=t)throw new Error("unsupported axis for this operation.");return e<0?e+t:e}static normalizeAxes(e,t){return e.map((n=>this.normalizeAxis(n,t??e.length)))}static sortBasedOnPerm(e,t){return t?t.map((t=>e[t])):e.slice().reverse()}static padShape(e,t){let n=e.length;return e.map(((e,r)=>e+t[r]+t[r+n]))}static areEqual(e,t){return e.length===t.length&&e.every(((e,n)=>e===t[n]))}},at=class e{static adjustPoolAttributes(e,t,n,r,i,s){if(!e&&n.length!==t.length-2)throw new Error("length of specified kernel shapes should be 2 less than length of input dimensions");if(e)for(let e=0;e<t.length-2;e++)e>=n.length?n.push(t[e+2]):n[e]=t[e+2];for(let e=0;e<n.length;e++)if(e<r.length){if(r[e]<0)throw new Error("strides should be greater than or equal to 1")}else r.push(1);for(let e=0;e<n.length;e++)if(e<i.length){if(i[e]<0)throw new Error("dilations should be greater than or equal to 1")}else i.push(1);for(let e=0;e<2*n.length;e++)if(e<s.length){if(s[e]<0)throw new Error("pad should be greater than or equal to 1")}else s.push(0);for(let e=0;e<n.length;e++){if(n[e]<=0)throw new Error("kernel shapes need to be greater than 0");if(s[e]>=n[e]||s[e+n.length]>=n[e])throw new Error("pads should be smaller than kernel")}}static adjustPadsBasedOnAutoPad(t,n,r,i,s,o,a){if(a){if(s.length!==2*(t.length-2))throw new Error("length of pads should be twice the length of data dimensions");if(n.length!==t.length-2)throw new Error("length of strides should be the length of data dimensions");if(i.length!==t.length-2)throw new Error("length of kernel shapes should be the length of data dimensions");for(let l=0;l<t.length-2;l++)e.adjustPadAndReturnShape(t[l+(o?1:2)],n[l],r[l],i[l],s,l,l+t.length-2,a)}}static computePoolOutputShape(t,n,r,i,s,o,a){if(n.length<=0)throw new Error("input shape must be of size greater than 0");let l=[n[0],n[1]];return e.computeShapeHelper(t,n,l,r,i,s,o,a),l}static computeConvOutputShape(t,n,r,i,s,o,a){if(t.length<=0||n.length<=0)throw new Error("invalid input tensor dims or invalid filter tensor dims");let l=[t[0],n[0]];return e.computeShapeHelper(!1,t,l,r,i,s,o,a),l}static computeShapeHelper(t,n,r,i,s,o,a,l){if(t)for(let e=0;e<n.length-2;e++)r.push(1);else for(let t=0;t<n.length-2;t++)r.push(e.adjustPadAndReturnShape(n[t+2],i[t],s[t],o[t],a,t,t+n.length-2,l))}static adjustPadAndReturnShape(e,t,n,r,i,s,o,a){let l=n*(r-1)+1;if(!a||"NOTSET"===a)return Math.floor((e+i[s]+i[o]-l)/t+1);switch(a){case"VALID":return i[s]=0,i[o]=0,Math.floor((e-l)/t+1);case"SAME_LOWER":case"SAME_UPPER":if(1!==n)throw new Error("Dilation not supported for SAME_UPPER or SAME_LOWER");{let n=((e+t-1)/t-1)*t+r-e;return i[s]=Math.floor("SAME_LOWER"===a?(n+1)/2:n/2),i[o]=n-i[s],Math.floor((e+n-r)/t+1)}default:throw new Error("Unsupported AutoPad type")}}},lt=class{static getShapeOfGemmResult(e,t,n,r,i){if(2!==e.length||2!==n.length)throw new Error("shape need to be of size 2");let s,o,a;t?(s=e[1],o=e[0]):(s=e[0],o=e[1]);let l=-1;if(r?(a=n[0],l=1):(a=n[1],l=0),n[l]!==o)throw new Error("dimension mismatch");if(s<=0||a<=0||o<=0)throw new Error("invalid shape specified");if(i&&!st.isValidBroadcast(i,[s,a]))throw new Error("gemm: invalid bias shape for broadcast");return[s,a,o]}},dt=-34028234663852886e22,ut=34028234663852886e22})),Ra=V((()=>{Aa(),Da(),ct=64,pt=(e,t)=>{if(3===t)throw new Error("vec3 has same alignment as vec4, use vec4 instead");switch(e){case 10:return t>1?`vec${t}<f16>`:"f16";case 1:return t>1?`vec${t}<f32>`:"f32";case 6:return t>1?`vec${t}<i32>`:"i32";case 12:return t>1?`vec${t}<u32>`:"u32";case 7:if(t>1)throw new Error("currently not supported vecX of uint64 yet");return["vec2<u32>","i32"];case 13:if(t>1)throw new Error("currently not supported vecX of uint64 yet");return["vec2<u32>","u32"];case 9:if(4!==t)throw new Error("bool must be vec4");return["u32","vec4<bool>"];default:throw new Error(`Unknown data type: ${e}`)}},ht=(e,t=1)=>{let n=pt(e,t);return"string"==typeof n?n:n[0]},ft=(e,t=1)=>{let n=pt(e,t);return"string"==typeof n?n:n[1]},mt=(...e)=>{let t=[];return e.forEach((e=>{0!==e.length&&t.push({type:12,data:e},{type:12,data:ot.computeStrides(e)})})),t},gt=e=>e%4==0?4:e%2==0?2:1,_t=(e="f32",t,n="0")=>t&&1!==t?`vec${t}<${e}>(${n})`:`${e}(${n})`,wt=(e,t,n)=>"f32"===e?n:1===t?`f32(${n})`:`vec${t}f(${n})`,yt=(e,t)=>4===t?`(${e}.x + ${e}.y + ${e}.z + ${e}.w)`:2===t?`(${e}.x + ${e}.y)`:3===t?`(${e}.x + ${e}.y + ${e}.z)`:e,bt=(e,t,n,r)=>e.startsWith("uniforms.")&&n>4?"string"==typeof t?"f16"===r?`${e}[(${t}) / 8][(${t}) % 8 / 4][(${t}) % 8 % 4]`:`${e}[(${t}) / 4][(${t}) % 4]`:"f16"===r?`${e}[${Math.floor(t/8)}][${Math.floor(t%8/4)}][${t%8%4}]`:`${e}[${Math.floor(t/4)}][${t%4}]`:n>1?`${e}[${t}]`:e,vt=(e,t,n,r,i)=>{let s="number"==typeof n,o=s?n:n.length,a=[...new Array(o).keys()],l=o<2?"u32":o<=4?`vec${o}<u32>`:`array<u32, ${o}>`,d=pt(t,i),u="string"==typeof d?d:d[1],c="string"==typeof d?d:d[0],p={indices:l,value:u,storage:c,tensor:t},h=e=>"string"==typeof e?e:`${e}u`,f={offsetToIndices:!1,indicesToOffset:!1,broadcastedIndicesToOffset:!1,set:!1,setByIndices:!1,get:!1,getByIndices:!1},m=s?"uniforms.":"",g=`${m}${e}_shape`,_=`${m}${e}_strides`,w="";for(let e=0;e<o-1;e++)w+=`\n    let dim${e} = current / ${bt(_,e,o)};\n    let rest${e} = current % ${bt(_,e,o)};\n    indices[${e}] = dim${e};\n    current = rest${e};\n    `;w+=`indices[${o-1}] = current;`;let y=o<2?"":`\n  fn o2i_${e}(offset: u32) -> ${p.indices} {\n    var indices: ${p.indices};\n    var current = offset;\n    ${w}\n    return indices;\n  }`,b=[];if(o>=2)for(let e=o-1;e>=0;e--)b.push(`${bt(_,e,o)} * (indices[${e}])`);let v=o<2?"":`\n  fn i2o_${e}(indices: ${p.indices}) -> u32 {\n    return ${b.join("+")};\n  }`,x=(...e)=>0===o?"0u":`${p.indices}(${e.map(h).join(",")})`,M=(e,t)=>o<2?`${e}`:`${bt(e,t,o)}`,T={},k=(t,n)=>(()=>{if(p.storage===p.value)return`${e}[${t}]=${n};`;if("vec2<u32>"===p.storage&&"i32"===p.value)return`${e}[${t}]=vec2<u32>(u32(${n}), select(0u, 0xFFFFFFFFu, ${n} < 0));`;if("vec2<u32>"===p.storage&&"u32"===p.value)return`${e}[${t}]=vec2<u32>(u32(${n}), 0u);`;if("u32"===p.storage&&"vec4<bool>"===p.value)return`${e}[${t}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${n}));`;throw new Error(`not supported combination of storage type ${p.storage} and value type ${p.value} yet`)})(),$=t=>(()=>{if(p.storage===p.value)return`${e}[${t}]`;if("vec2<u32>"===p.storage&&"i32"===p.value)return`i32(${e}[${t}].x)`;if("vec2<u32>"===p.storage&&"u32"===p.value)return`u32(${e}[${t}].x)`;if("u32"===p.storage&&"vec4<bool>"===p.value)return`vec4<bool>(bool(${e}[${t}] & 0xFFu), bool(${e}[${t}] & 0xFF00u), bool(${e}[${t}] & 0xFF0000u), bool(${e}[${t}] & 0xFF000000u))`;throw new Error(`not supported combination of storage type ${p.storage} and value type ${p.value} yet`)})(),S=o<2?"":`\n  fn get_${e}ByIndices(indices: ${p.indices}) -> ${u} {\n    return ${$(`i2o_${e}(indices)`)};\n  }`,C=o<2?"":(()=>{let t=a.map((e=>`d${e}: u32`)).join(", "),n=a.map((e=>`d${e}`)).join(", ");return`\n  fn get_${e}(${t}) -> ${u} {\n    return get_${e}ByIndices(${x(n)});\n  }`})(),P=o<2?"":`\n  fn set_${e}ByIndices(indices: ${p.indices}, value: ${u}) {\n    ${k(`i2o_${e}(indices)`,"value")}\n  }`,E=o<2?"":(()=>{let t=a.map((e=>`d${e}: u32`)).join(", "),n=a.map((e=>`d${e}`)).join(", ");return`\n  fn set_${e}(${t}, value: ${u}) {\n    set_${e}ByIndices(${x(n)}, value);\n  }`})();return{impl:()=>{let e=[],t=!1;return f.offsetToIndices&&(e.push(y),t=!0),f.indicesToOffset&&(e.push(v),t=!0),f.broadcastedIndicesToOffset&&(Object.values(T).forEach((t=>e.push(t))),t=!0),f.set&&(e.push(E),t=!0),f.setByIndices&&(e.push(P),t=!0),f.get&&(e.push(C),t=!0),f.getByIndices&&(e.push(S),t=!0),!s&&t&&e.unshift(`const ${g} = ${p.indices}(${n.join(",")});`,`const ${_} = ${p.indices}(${ot.computeStrides(n).join(",")});`),e.join("\n")},type:p,offsetToIndices:t=>(f.offsetToIndices=!0,o<2?t:`o2i_${e}(${t})`),indicesToOffset:t=>(f.indicesToOffset=!0,o<2?t:`i2o_${e}(${t})`),broadcastedIndicesToOffset:(t,n)=>{f.broadcastedIndicesToOffset=!0;let r=`${n.name}broadcastedIndicesTo${e}Offset`;if(r in T)return`${r}(${t})`;let i=[];for(let e=o-1;e>=0;e--){let t=n.indicesGet("outputIndices",e+n.rank-o);i.push(`${M(_,e)} * (${t} % ${M(g,e)})`)}return T[r]=`fn ${r}(outputIndices: ${n.type.indices}) -> u32 {\n             return ${i.length>0?i.join("+"):"0u"};\n           }`,`${r}(${t})`},indices:x,indicesGet:M,indicesSet:(e,t,n)=>o<2?`${e}=${n};`:`${bt(e,t,o)}=${n};`,set:(...t)=>{if(t.length!==o+1)throw new Error(`indices length must be ${o}`);let n=t[o];if("string"!=typeof n)throw new Error("value must be string");let r=t.slice(0,o).map(h).join(",");return 0===o?k("0u",n):1===o?k(r[0],n):(f.set=!0,f.setByIndices=!0,f.indicesToOffset=!0,`set_${e}(${r}, ${n})`)},setByOffset:k,setByIndices:(t,n)=>o<2?k(t,n):(f.setByIndices=!0,f.indicesToOffset=!0,`set_${e}ByIndices(${t}, ${n});`),get:(...t)=>{if(t.length!==o)throw new Error(`indices length must be ${o}`);let n=t.map(h).join(",");return 0===o?$("0u"):1===o?$(n[0]):(f.get=!0,f.getByIndices=!0,f.indicesToOffset=!0,`get_${e}(${n})`)},getByOffset:$,getByIndices:t=>o<2?$(t):(f.getByIndices=!0,f.indicesToOffset=!0,`get_${e}ByIndices(${t})`),usage:r,name:e,strides:_,shape:g,rank:o}},xt=(e,t,n,r=1)=>vt(e,t,n,"input",r),Mt=(e,t,n,r=1)=>vt(e,t,n,"output",r),Tt=(e,t,n,r=1)=>vt(e,t,n,"internal",r),kt=class{constructor(e,t){this.normalizedDispatchGroup=e,this.limits=t,this.internalVariables=[],this.variables=[],this.uniforms=[],this.variableIndex=0}guardAgainstOutOfBoundsWorkgroupSizes(e){return`if (global_idx >= ${"number"==typeof e?`${e}u`:e}) { return; }`}mainStart(e=ct){let t="number"==typeof e?e:e[0],n="number"==typeof e?1:e[1],r="number"==typeof e?1:e[2];if(t>this.limits.maxComputeWorkgroupSizeX||n>this.limits.maxComputeWorkgroupSizeY||r>this.limits.maxComputeWorkgroupSizeZ)throw new Error(`workgroup size [${t}, ${n}, ${r}] exceeds the maximum workgroup size [${this.limits.maxComputeWorkgroupSizeX}, ${this.limits.maxComputeWorkgroupSizeY}, ${this.limits.maxComputeWorkgroupSizeZ}].`);if(t*n*r>this.limits.maxComputeInvocationsPerWorkgroup)throw new Error(`workgroup size [${t}, ${n}, ${r}] exceeds the maximum workgroup invocations ${this.limits.maxComputeInvocationsPerWorkgroup}.`);let i=1===this.normalizedDispatchGroup[1]&&1===this.normalizedDispatchGroup[2];return`@compute @workgroup_size(${t}, ${n}, ${r})\n  fn main(${i?"@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>":"@builtin(global_invocation_id) global_id : vec3<u32>,\n                                             @builtin(local_invocation_id) local_id : vec3<u32>,\n    @builtin(local_invocation_index) local_idx : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>"}) {\n    ${i?"let global_idx = global_id.x; let local_idx = local_id.x;":`let global_idx = (workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n          workgroup_id.y * num_workgroups[0] + workgroup_id.x) * ${t*n*r}u + local_idx;`}\n  `}appendVariableUniforms(e){0!==e.rank&&(e.shape.startsWith("uniforms.")&&this.uniforms.push({name:e.shape.replace("uniforms.",""),type:"u32",length:e.rank}),e.strides.startsWith("uniforms.")&&this.uniforms.push({name:e.strides.replace("uniforms.",""),type:"u32",length:e.rank}))}declareVariable(e,t){if("internal"===e.usage)throw new Error("cannot use internal variable with declareVariable(). use registerInternalVariables() instead.");this.variables.push(e),this.appendVariableUniforms(e);let n="input"===e.usage?"read":"read_write",r=e.type.storage;return`@group(0) @binding(${t}) var<storage, ${n}> ${e.name}: array<${r}>;`}declareVariables(...e){return e.map((e=>this.declareVariable(e,this.variableIndex++))).join("\n")}registerInternalVariable(e){if("internal"!==e.usage)throw new Error("cannot use input or output variable with registerInternalVariable(). use declareVariables() instead.");this.internalVariables.push(e),this.appendVariableUniforms(e)}registerInternalVariables(...e){return e.forEach((e=>this.registerInternalVariable(e))),this}registerUniform(e,t,n=1){return this.uniforms.push({name:e,type:t,length:n}),this}registerUniforms(e){return this.uniforms=this.uniforms.concat(e),this}uniformDeclaration(){if(0===this.uniforms.length)return"";let e=[];for(let{name:t,type:n,length:r}of this.uniforms)if(r&&r>4)"f16"===n?e.push(`@align(16) ${t}:array<mat2x4<${n}>, ${Math.ceil(r/8)}>`):e.push(`${t}:array<vec4<${n}>, ${Math.ceil(r/4)}>`);else{let i=null==r||1===r?n:`vec${r}<${n}>`;e.push(`${t}:${i}`)}return`\n      struct Uniforms { ${e.join(", ")} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`}get additionalImplementations(){return this.uniformDeclaration()+this.variables.map((e=>e.impl())).join("\n")+this.internalVariables.map((e=>e.impl())).join("\n")}get variablesInfo(){if(0===this.uniforms.length)return;let e=e=>[12,10,1,6][["u32","f16","f32","i32"].indexOf(e)];return this.uniforms.map((t=>[e(t.type),t.length??1]))}},$t=(e,t)=>new kt(e,t),St=(e,t)=>{let n=e.length,r=[];for(let i=0;i<n;i++){let s=n-1-i,o=e[s]||1;(t[t.length-1-i]||1)>1&&1===o&&r.unshift(s)}return r}})),Na=V((()=>{Aa(),Da(),La(),Ra(),Ct=e=>{if(!e||1!==e.length)throw new Error("Transpose requires 1 input.")},Pt=(e,t)=>t&&t.length!==e?[...new Array(e).keys()].reverse():t,Et=(e,t)=>ot.sortBasedOnPerm(e,Pt(e.length,t)),At=(e,t,n,r)=>{let i=[];i.push(`fn perm(i: ${r.type.indices}) -> ${n.type.indices} {\n    var a: ${n.type.indices};`);for(let r=0;r<t;++r)i.push(n.indicesSet("a",e[r],`i[${r}]`));return i.push("return a;}"),i.join("\n")},Ft=(e,t)=>{let n=e.dataType,r=e.dims.length,i=Pt(r,t),s=Et(e.dims,i),o=Mt("output",n,s.length),a=xt("a",n,r);return{name:"Transpose",shaderCache:{hint:`${t}`,inputDependencies:["rank"]},getRunData:e=>{let t=ot.size(s);return{outputs:[{dims:s,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(t/64)},programUniforms:[{type:12,data:t},...mt(e[0].dims,s)]}},getShaderSource:e=>`\n  ${e.registerUniform("output_size","u32").declareVariables(a,o)}\n\n  ${At(i,r,a,o)}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n\n    let indices = ${o.offsetToIndices("global_idx")};\n    let aIndices = perm(indices);\n\n    ${o.setByOffset("global_idx",a.getByIndices("aIndices"))}\n  }`}},It=(e,t)=>{Ct(e.inputs),e.compute(Ft(e.inputs[0],t.perm))},zt=e=>rt({perm:e.perm})})),Va=V((()=>{Aa(),Da(),Ra(),ja(),Na(),Bt={max:"select(bestValue, candidate, candidate > bestValue)",min:"select(bestValue, candidate, candidate < bestValue)",mean:"bestValue + candidate",sum:"bestValue + candidate",prod:"bestValue * candidate",sumSquare:"bestValue + candidate * candidate",logSumExp:"bestValue + exp(candidate)",l1:"bestValue + abs(candidate)",l2:"bestValue + candidate * candidate",logSum:"bestValue + candidate"},Ot={max:"select(bestValue, candidate, candidate > bestValue)",min:"select(bestValue, candidate, candidate < bestValue)",mean:"bestValue + candidate",sum:"bestValue + candidate",prod:"bestValue * candidate",sumSquare:"bestValue + candidate",logSumExp:"bestValue + candidate",l1:"bestValue + candidate",l2:"bestValue + candidate",logSum:"bestValue + candidate"},Lt={max:"_A[offset]",min:"_A[offset]",mean:"0",sum:"0",prod:"1",sumSquare:"0",logSumExp:"0",l1:"0",l2:"0",logSum:"0"},Dt={max:"bestValue",min:"bestValue",sum:"bestValue",prod:"bestValue",sumSquare:"bestValue",logSumExp:"log(bestValue)",l1:"bestValue",l2:"sqrt(bestValue)",logSum:"log(bestValue)"},Rt=(e,t)=>{let n=[];for(let r=t-e;r<t;++r)n.push(r);return n},Nt=(e,t)=>{let n=[],r=e.length;for(let i=0;i<r;i++)-1===t.indexOf(i)&&n.push(e[i]);return[n,t.map((t=>e[t]))]},Vt=(e,t)=>{let n=e.length+t.length,r=[],i=0;for(let s=0;s<n;s++)-1===t.indexOf(s)?r.push(e[i++]):r.push(1);return r},jt=(e,t)=>{for(let n=0;n<e.length;++n)if(e[e.length-n-1]!==t-1-n)return!1;return!0},Ut=(e,t)=>{let n=[];if(!jt(e,t)){for(let r=0;r<t;++r)-1===e.indexOf(r)&&n.push(r);e.forEach((e=>n.push(e)))}return n},Gt=(e,t,n,r,i,s,o)=>{let a=n[0].dims,l=ot.size(s),d=ot.size(o),u=xt("_A",n[0].dataType,a),c=Mt("output",i,s);return{name:e,shaderCache:t,getShaderSource:e=>`\n        ${e.registerUniform("reduceSize","u32").declareVariables(u,c)}\n        \n          var<workgroup> aBestValues : array<f32, 32>;\n       \n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${e.mainStart(32)}\n\n          let outputIndex = global_idx / 32;\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = f32(${Lt[r]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + 32) {\n           let candidate = f32(${u.getByOffset("offset + k")});\n           bestValue = ${Bt[r]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, 32u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${Ot[r]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${c.setByOffset("outputIndex",""+("mean"===r?`${c.type.storage}(bestValue / f32(uniforms.reduceSize))`:`${c.type.storage}(${Dt[r]})`))};\n         }\n        }`,getRunData:()=>({outputs:[{dims:s,dataType:i}],dispatchGroup:{x:l},programUniforms:[{type:12,data:d}]})}},qt=(e,t,n,r)=>{let i=1===e.inputs.length?n:on(e.inputs,n),s=i.axes;0===s.length&&!i.noopWithEmptyAxes&&(s=e.inputs[0].dims.map(((e,t)=>t)));let o=ot.normalizeAxes(s,e.inputs[0].dims.length),a=o,l=e.inputs[0],d=Ut(a,e.inputs[0].dims.length);d.length>0&&(l=e.compute(Ft(e.inputs[0],d),{inputs:[0],outputs:[-1]})[0],a=Rt(a.length,l.dims.length));let[u,c]=Nt(l.dims,a),p=u;i.keepDims&&(p=Vt(u,o)),e.compute(Gt(t,{hint:i.cacheKey,inputDependencies:["type"]},[l],r,e.inputs[0].dataType,p,c),{inputs:[l]})},Wt=(e,t)=>{qt(e,"ReduceMeanShared",t,"mean")},Ht=(e,t)=>{qt(e,"ReduceL1Shared",t,"l1")},Xt=(e,t)=>{qt(e,"ReduceL2Shared",t,"l2")},Qt=(e,t)=>{qt(e,"ReduceLogSumExpShared",t,"logSumExp")},Kt=(e,t)=>{qt(e,"ReduceMaxShared",t,"max")},Yt=(e,t)=>{qt(e,"ReduceMinShared",t,"min")},Zt=(e,t)=>{qt(e,"ReduceProdShared",t,"prod")},Jt=(e,t)=>{qt(e,"ReduceSumShared",t,"sum")},en=(e,t)=>{qt(e,"ReduceSumSquareShared",t,"sumSquare")},tn=(e,t)=>{qt(e,"ReduceLogSumShared",t,"logSum")}})),ja=V((()=>{Aa(),Da(),La(),Ra(),Va(),nn=e=>{if(!e||0===e.length||e.length>2)throw new Error("Reduce op requires 1 or 2 inputs.");if(2===e.length&&1!==e[1].dims.length)throw new Error("Invalid axes input dims.")},rn=e=>["","",`var value = ${e.getByIndices("input_indices")};`,""],sn=(e,t,n,r,i,s,o=!1,a=!1)=>{let l=[],d=n[0].dims,u=d.length,c=ot.normalizeAxes(i,u),p=!a&&0===c.length;d.forEach(((e,t)=>{p||c.indexOf(t)>=0?o&&l.push(1):l.push(e)}));let h=l.length,f=ot.size(l);return{name:e,shaderCache:t,getShaderSource:e=>{let t=[],i=xt("_A",n[0].dataType,u),a=Mt("output",s,h),l=r(i,a,c),f=l[2];for(let e=0,n=0;e<u;e++)p||c.indexOf(e)>=0?(o&&n++,f=`for(var j${e}: u32 = 0; j${e} < ${d[e]}; j${e}++) {\n                  ${l[2].includes("last_index")?`let last_index = j${e};`:""}\n                  ${i.indicesSet("input_indices",e,`j${e}`)}\n                  ${f}\n                }`):(t.push(`${i.indicesSet("input_indices",e,a.indicesGet("output_indices",n))};`),n++);return`\n\n        ${e.registerUniform("output_size","u32").declareVariables(i,a)}\n\n        ${e.mainStart()}\n          ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n          var input_indices: ${i.type.indices};\n          let output_indices = ${a.offsetToIndices("global_idx")};\n\n          ${t.join("\n")}\n          ${l[0]}       // init ops for reduce max/min\n          ${l[1]}\n          ${f}\n          ${l[3]}\n          ${4===l.length?a.setByOffset("global_idx","value"):l.slice(4).join("\n")}\n        }`},getRunData:()=>({outputs:[{dims:l,dataType:s}],dispatchGroup:{x:Math.ceil(f/64)},programUniforms:[{type:12,data:f},...mt(d,l)]})}},on=(e,t)=>{let n=[];return e[1].dims[0]>0&&e[1].getBigInt64Array().forEach((e=>n.push(Number(e)))),rt({axes:n,keepDims:t.keepDims,noopWithEmptyAxes:t.noopWithEmptyAxes})},an=(e,t,n,r)=>{let i=e.inputs,s=1===i.length?n:on(i,n);e.compute(sn(t,{hint:s.cacheKey,inputDependencies:["rank"]},[i[0]],s.noopWithEmptyAxes&&0===s.axes.length?rn:r,s.axes,i[0].dataType,s.keepDims,s.noopWithEmptyAxes),{inputs:[0]})},ln=(e,t)=>{nn(e.inputs),an(e,"ReduceLogSum",t,((e,t)=>[`var value = ${t.type.storage}(0);`,"",`value += ${e.getByIndices("input_indices")};`,"value = log(value);"]))},dn=(e,t)=>{nn(e.inputs),an(e,"ReduceL1",t,((e,t)=>[`var value = ${t.type.storage}(0);`,"",`value += abs(${e.getByIndices("input_indices")});`,""]))},un=(e,t)=>{nn(e.inputs),an(e,"ReduceL2",t,((e,t)=>[`var t = ${t.type.value}(0); var value = ${t.type.value}(0);`,"",`t = ${e.getByIndices("input_indices")}; value += (t * t);`,"value = sqrt(value);"]))},cn=(e,t)=>{nn(e.inputs),an(e,"ReduceLogSumExp",t,((e,t)=>[`var value = ${t.type.storage}(0);`,"",`value += exp(${e.getByIndices("input_indices")});`,"value = log(value);"]))},pn=(e,t)=>{nn(e.inputs),an(e,"ReduceMax",t,((e,t,n)=>{let r=[];for(let t=0;t<e.rank;t++)(n.indexOf(t)>=0||0===n.length)&&r.push(e.indicesSet("input_indices",t,0));return[`${r.join("\n")}`,`var value = ${e.getByIndices("input_indices")};`,`value = max(value, ${e.getByIndices("input_indices")});`,""]}))},hn=(e,t)=>{nn(e.inputs),an(e,"ReduceMean",t,((t,n,r)=>{let i=1;for(let n=0;n<t.rank;n++)(r.indexOf(n)>=0||0===r.length)&&(i*=e.inputs[0].dims[n]);return["var sum = f32(0);","",`sum += f32(${t.getByIndices("input_indices")});`,`let value = ${n.type.value}(sum / ${i});`]}))},fn=(e,t)=>{nn(e.inputs),an(e,"ReduceMin",t,((e,t,n)=>{let r=[];for(let t=0;t<e.rank;t++)(n.indexOf(t)>=0||0===n.length)&&r.push(`input_indices[${t}] = 0;`);return[`${r.join("\n")}`,`var value = ${e.getByIndices("input_indices")};`,`value = min(value, ${e.getByIndices("input_indices")});`,""]}))},mn=(e,t)=>{nn(e.inputs),an(e,"ReduceProd",t,((e,t)=>[`var value = ${t.type.storage}(1);`,"",`value *= ${e.getByIndices("input_indices")};`,""]))},gn=(e,t)=>{nn(e.inputs),an(e,"ReduceSum",t,((e,t)=>[`var value = ${t.type.storage}(0);`,"",`value += ${e.getByIndices("input_indices")};`,""]))},_n=(e,t)=>{nn(e.inputs),an(e,"ReduceSumSquare",t,((e,t)=>[`var t = ${t.type.value}(0); var value = ${t.type.value}(0);`,"",`t = ${e.getByIndices("input_indices")}; value += t * t;`,""]))},wn=(e,t,n)=>{if(0===t.length)return n;let r=1,i=1;for(let n=0;n<t.length;n++)-1===t.indexOf(n)?r*=e[n]:i*=e[n];return i<32&&r>1024},yn=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?hn(e,t):Wt(e,t)},bn=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?dn(e,t):Ht(e,t)},vn=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?un(e,t):Xt(e,t)},xn=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?cn(e,t):Qt(e,t)},Mn=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?pn(e,t):Kt(e,t)},Tn=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?fn(e,t):Yt(e,t)},kn=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?mn(e,t):Zt(e,t)},$n=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?gn(e,t):Jt(e,t)},Sn=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?_n(e,t):en(e,t)},Cn=(e,t)=>{wn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?ln(e,t):tn(e,t)}})),Ua=V((()=>{Aa(),La(),ja(),Pn=e=>{if(!e||0===e.length||e.length>2)throw new Error("ArgMinMaxOp op requires 1 or 2 inputs.");if(1!==e[0].dataType)throw new Error("Invalid input type.")},En=(e,t)=>{Pn(e.inputs);e.compute(sn("ArgMin",{hint:t.cacheKey,inputDependencies:["rank"]},[e.inputs[0]],((e,n,r)=>{let i=[];for(let t=0;t<e.rank;t++)(r.indexOf(t)>=0||0===r.length)&&i.push(`input_indices[${t}] = 0;`);return[`${i.join("\n")}`,`var value = ${e.getByIndices("input_indices")};\nvar best_index : i32 = 0;`,`if (${e.getByIndices("input_indices")} ${t.selectLastIndex>0?"<=":"<"} value) {\n         value = ${e.getByIndices("input_indices")};\n         best_index = i32(last_index);\n       }`,"",n.setByOffset("global_idx","best_index")]}),[t.axis],7,t.keepDims),{inputs:[0]})},An=(e,t)=>{Pn(e.inputs);e.compute(sn("argMax",{hint:t.cacheKey,inputDependencies:["rank"]},[e.inputs[0]],((e,n,r)=>{let i=[];for(let t=0;t<e.rank;t++)(r.indexOf(t)>=0||0===r.length)&&i.push(`input_indices[${t}] = 0;`);return[`${i.join("\n")}`,`var value = ${e.getByIndices("input_indices")};\nvar best_index : i32 = 0;`,`if (${e.getByIndices("input_indices")} ${t.selectLastIndex>0?">=":">"} value) {\n         value = ${e.getByIndices("input_indices")};\n         best_index = i32(last_index);\n       }`,"",n.setByOffset("global_idx","best_index")]}),[t.axis],7,t.keepDims),{inputs:[0]})},Fn=e=>rt(e)})),Ga=V((()=>{Aa(),Ba(),Ra(),In=(e,t)=>{let n=e[0],r=e[1],i=e[2],s=e[3],o=e[4],a=e[5];if(o&&a)throw new Error("Attention cannot have both past and relative_position_bias");if(3!==n.dims.length)throw new Error('Input "input" must have 3 dimensions');let l=n.dims[0],d=n.dims[1],u=n.dims[2];if(1!==i.dims.length)throw new Error('Input "bias" is expected to have 1 dimensions');if(2!==r.dims.length)throw new Error('Input "weights" is expected to have 2 dimensions');if(r.dims[0]!==u)throw new Error("Input 1 dimension 0 should have same length as dimension 2 of input 0");if(i.dims[0]!==r.dims[1])throw new Error('Input "bias" dimension 0 should have same length as dimension 1 of input "weights"');let c=i.dims[0]/3,p=c,h=p;if(t.qkvHiddenSizes.length>0){if(3!==t.qkvHiddenSizes.length)throw new Error("qkv_hidden_sizes attribute should have 3 elements");for(let e of t.qkvHiddenSizes)if(e%t.numHeads!=0)throw new Error("qkv_hidden_sizes should be divisible by num_heads");c=t.qkvHiddenSizes[0],p=t.qkvHiddenSizes[1],h=t.qkvHiddenSizes[2]}let f=d;if(c!==p)throw new Error("qkv_hidden_sizes first element should be same as the second");if(i.dims[0]!==c+p+h)throw new Error('Input "bias" dimension 0 should have same length as sum of Q/K/V hidden sizes');let m=0;if(o){if(p!==h)throw new Error('Input "past" expect k_hidden_size == v_hidden_size');if(5!==o.dims.length)throw new Error('Input "past" must have 5 dimensions');if(2!==o.dims[0])throw new Error('Input "past" first dimension must be 2');if(o.dims[1]!==l)throw new Error('Input "past" second dimension must be batch_size');if(o.dims[2]!==t.numHeads)throw new Error('Input "past" third dimension must be num_heads');if(o.dims[4]!==p/t.numHeads)throw new Error('Input "past" fifth dimension must be k_hidden_size / num_heads');t.pastPresentShareBuffer||(m=o.dims[3])}let g=f+m;if(s)throw new Error("Mask not supported");if(o)throw new Error("past is not supported");if(a)throw new Error("relativePositionBias is not supported");return{batchSize:l,sequenceLength:d,pastSequenceLength:m,kvSequenceLength:f,totalSequenceLength:g,maxSequenceLength:-1,inputHiddenSize:u,hiddenSize:c,vHiddenSize:h,headSize:Math.floor(c/t.numHeads),vHeadSize:Math.floor(h/t.numHeads),numHeads:t.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:t.maskFilterValue,maskType:0,scale:t.scale,broadcastResPosBias:!1,passPastInKv:!1,qkvFormat:1}},zn=(e,t,n,r)=>{let i=gt(r),s=64,o=r/i;o<s?s=1:o/8<64&&(s=Math.ceil(o/8));let a=Math.ceil(r/i/s),l=[{type:t.dataType,data:1/r},{type:12,data:o},{type:12,data:a}],d=ht(t.dataType,i);e.compute({name:"AttentionProbsSoftmax",shaderCache:{hint:`${s};${d};${i}`},getShaderSource:e=>{let n=Mt("x",t.dataType,t.dims,i),r="thread_max_vector";2===i?r="max(thread_max_vector.x, thread_max_vector.y)":4===i&&(r="max(max(thread_max_vector.x, thread_max_vector.y), max(thread_max_vector.z, thread_max_vector.w))");let o=ft(t.dataType),a=[{name:"d_inv",type:o},{name:"d_comp",type:"u32"},{name:"elements_per_wg",type:"u32"}];return`\n  var<workgroup> wgMax: array<f32, ${s}>;\n  var<workgroup> wgSum: array<f32, ${s}>;\n  ${e.registerUniforms(a).declareVariables(n)}\n  ${e.mainStart([s,1,1])}\n    let localOffset = local_idx * uniforms.elements_per_wg;\n    let offset: u32 = workgroup_id.x * uniforms.d_comp + localOffset;\n\n    var thread_max_vector = ${_t("f32",i,"-3.402823e+38f")};\n    for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n      thread_max_vector = max(${wt(o,i,"x[offset + i]")}, thread_max_vector);\n    }\n    wgMax[local_idx] = ${r};\n    workgroupBarrier();\n\n    var maxValue = -3.402823e+38f;\n    for (var i = 0u; i < ${s}; i++) {\n      maxValue = max(wgMax[i], maxValue);\n    }\n\n    var sumVector = ${_t("f32",i,"0")};\n    for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n      sumVector += exp(${wt(o,i,"x[offset + i]")} - maxValue);\n    }\n    wgSum[local_idx] = ${yt("sumVector",i)};\n    workgroupBarrier();\n\n    var sum: f32 = 0;\n    for (var i = 0u; i < ${s}; i++) {\n      sum += wgSum[i];\n    }\n\n    if (sum == 0) {\n      for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n        x[offset + i] = ${_t(o,i,"uniforms.d_inv")};\n      }\n    } else {\n      for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n        let f32input = ${wt(o,i,"x[offset + i]")};\n        x[offset + i] = ${n.type.value}(exp(f32input - maxValue) / sum);\n      }\n    }\n  }`},getRunData:()=>({outputs:[],dispatchGroup:{x:n},programUniforms:l})},{inputs:[t],outputs:[]})},Bn=(e,t,n,r,i,s)=>{let o=[i.batchSize,i.numHeads,i.sequenceLength,i.kvSequenceLength+i.pastSequenceLength],a=0===s.scale?1/Math.sqrt(i.headSize):s.scale,l=gt(i.headSize),d=i.headSize/l,u=12,c={x:Math.ceil(i.totalSequenceLength/u),y:Math.ceil(i.sequenceLength/u),z:i.batchSize*i.numHeads},p=[{type:12,data:i.sequenceLength},{type:12,data:d},{type:12,data:i.totalSequenceLength},{type:12,data:i.kvSequenceLength},{type:t.dataType,data:a}],h=[t,n],f=e.compute({name:"AttentionProbs",shaderCache:{hint:`${l}`,inputDependencies:["type","type"]},getRunData:()=>({outputs:[{dims:o,dataType:t.dataType,gpuDataType:0}],dispatchGroup:c,programUniforms:p}),getShaderSource:e=>{let r=xt("q",t.dataType,t.dims,l),i=xt("key",n.dataType,n.dims,l),s=Mt("output",t.dataType,o),a=ht(t.dataType),d=[{name:"M",type:"u32"},{name:"K",type:"u32"},{name:"N",type:"u32"},{name:"kv_sequence_length",type:"u32"},{name:"alpha",type:a}];return`\n  const beta: ${a} = 1.0;\n  const TILE_SIZE = 12u;\n\n  var<workgroup> tileQ: array<${r.type.storage}, 144>;\n  var<workgroup> tileK: array<${r.type.storage}, 144>;\n  ${e.registerUniforms(d).declareVariables(r,i,s)}\n  ${e.mainStart([u,u,1])}\n    // x holds the N and y holds the M\n    let headIdx = workgroup_id.z;\n    let m = workgroup_id.y * TILE_SIZE;\n    let n = workgroup_id.x * TILE_SIZE;\n    let qOffset = uniforms.M * uniforms.K * headIdx + m * uniforms.K;\n    let kOffset = uniforms.kv_sequence_length * uniforms.K * headIdx + n * uniforms.K;\n\n    var value = ${_t(a,l)};\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (global_id.y < uniforms.M && w + local_id.x < uniforms.K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * uniforms.K + w + local_id.x];\n      }\n      if (n + local_id.y < uniforms.N && w + local_id.x < uniforms.K) {\n        tileK[TILE_SIZE * local_id.y + local_id.x] = key[kOffset + local_id.y * uniforms.K + w + local_id.x];\n      }\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n        value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = headIdx * uniforms.M * uniforms.N;\n    if (global_id.y < uniforms.M && global_id.x < uniforms.N) {\n      let outputIdx = headOffset + global_id.y * uniforms.N + global_id.x;\n      output[outputIdx] = ${yt("value",l)} * uniforms.alpha;\n    }\n  }`}},{inputs:h,outputs:[-1]})[0];return zn(e,f,i.batchSize*i.numHeads*i.sequenceLength,i.totalSequenceLength),f},On=(e,t,n,r)=>{let i=[r.batchSize,r.sequenceLength,r.vHiddenSize],s=12,o={x:Math.ceil(r.vHeadSize/s),y:Math.ceil(r.sequenceLength/s),z:r.batchSize*r.numHeads},a=[{type:12,data:r.sequenceLength},{type:12,data:r.totalSequenceLength},{type:12,data:r.vHeadSize},{type:12,data:r.numHeads},{type:12,data:r.vHiddenSize}];return e.compute({name:"AttentionScore",shaderCache:{inputDependencies:["type","type"]},getRunData:()=>({outputs:[{dims:i,dataType:t.dataType,gpuDataType:0}],dispatchGroup:o,programUniforms:a}),getShaderSource:e=>{let r=xt("probs",t.dataType,t.dims),o=xt("v",n.dataType,n.dims),a=Mt("output",t.dataType,i);return`\n  const TILE_SIZE = 12u;\n  var<workgroup> tileQ: array<${r.type.value}, 144>;\n  var<workgroup> tileK: array<${r.type.value}, 144>;\n  ${e.registerUniforms([{name:"M",type:"u32"},{name:"K",type:"u32"},{name:"N",type:"u32"},{name:"num_heads",type:"u32"},{name:"v_hidden_size",type:"u32"}]).declareVariables(r,o,a)}\n  ${e.mainStart([s,s,1])}\n   let headIdx = workgroup_id.z;\n   let m = global_id.y;\n   let n = global_id.x;\n\n   let offsetA = headIdx * (uniforms.M * uniforms.K) + m * uniforms.K;\n   let offsetB = headIdx * (uniforms.N * uniforms.K) + n;\n\n   var value = ${r.type.storage}(0);\n   for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n     if (m < uniforms.M && w + local_id.x < uniforms.K) {\n       tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];\n     }\n     if (n < uniforms.N && w + local_id.y < uniforms.K) {\n       tileK[TILE_SIZE * local_id.y + local_id.x] = v[offsetB + (w + local_id.y) * uniforms.N];\n     }\n     workgroupBarrier();\n     for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n       value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * k + local_id.x];\n     }\n     workgroupBarrier();\n   }\n\n   // we need to transpose output from BNSH_v to BSND_v\n   let batchIdx = workgroup_id.z / uniforms.num_heads;\n   let currentBatchHeadNumber = workgroup_id.z % uniforms.num_heads;\n   let headOffset = (batchIdx * uniforms.M * uniforms.num_heads + currentBatchHeadNumber) * uniforms.N;\n   if (m < uniforms.M && n < uniforms.N) {\n     let outputIdx = batchIdx * uniforms.M *uniforms.v_hidden_size + m * uniforms.v_hidden_size\n       + currentBatchHeadNumber * uniforms.N + n;\n     output[outputIdx] = value;\n   }\n  }`}},{inputs:[t,n],outputs:[0]})[0]},Ln=(e,t,n,r,i,s,o,a,l,d,u)=>{let c=Bn(e,t,n,0,d,u);On(e,c,r,d)},Dn=(e,t)=>{let n=[t.batchSize,t.numHeads,t.sequenceLength,t.headSize],r=t.sequenceLength,i=t.inputHiddenSize,s=t.headSize,o=12,a={x:Math.ceil(t.headSize/o),y:Math.ceil(t.sequenceLength/o),z:t.batchSize*t.numHeads},l=[e.inputs[0],e.inputs[1],e.inputs[2]],d=[{type:12,data:r},{type:12,data:i},{type:12,data:s},{type:12,data:t.numHeads},{type:12,data:t.headSize},{type:12,data:t.hiddenSize},{type:12,data:t.hiddenSize+t.hiddenSize+t.vHiddenSize}];return e.compute({name:"AttentionPrepare",shaderCache:{inputDependencies:["type","type","type"]},getRunData:()=>({outputs:[{dims:n,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:n,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:n,dataType:e.inputs[0].dataType,gpuDataType:0}],dispatchGroup:a,programUniforms:d}),getShaderSource:e=>{let t=Mt("output_q",l[0].dataType,n),r=Mt("output_k",l[0].dataType,n),i=Mt("output_v",l[0].dataType,n),s=xt("input",l[0].dataType,l[0].dims),a=xt("weight",l[1].dataType,l[1].dims),d=xt("bias",l[2].dataType,l[2].dims),u=s.type.storage;return`\n  const TILE_SIZE = 12u;\n  var<workgroup> tileInput: array<${u}, 144>;\n  var<workgroup> tileWeightQ: array<${u}, 144>;\n  var<workgroup> tileWeightK: array<${u}, 144>;\n  var<workgroup> tileWeightV: array<${u}, 144>;\n  ${e.registerUniforms([{name:"M",type:"u32"},{name:"K",type:"u32"},{name:"N",type:"u32"},{name:"num_heads",type:"u32"},{name:"head_size",type:"u32"},{name:"hidden_size",type:"u32"},{name:"ldb",type:"u32"}]).declareVariables(s,a,d,t,r,i)}\n  ${e.mainStart([o,o,1])}\n    let batchIndex = workgroup_id.z / uniforms.num_heads;\n    let headNumber = workgroup_id.z % uniforms.num_heads;\n    let m = global_id.y;\n    let n = global_id.x;\n\n    let inputOffset = batchIndex * (uniforms.M * uniforms.K) + m * uniforms.K;\n    let biasOffsetQ = headNumber * uniforms.head_size;\n    let biasOffsetK = uniforms.hidden_size + biasOffsetQ;\n    let biasOffsetV = uniforms.hidden_size + biasOffsetK;\n\n    var valueQ = ${u}(0);\n    var valueK = ${u}(0);\n    var valueV = ${u}(0);\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (m < uniforms.M && w + local_id.x < uniforms.K) {\n        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];\n      }\n      if (n < uniforms.N && w + local_id.y < uniforms.K) {\n        let offset = n + (w + local_id.y) * uniforms.ldb;\n        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];\n        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];\n        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];\n      }\n      workgroupBarrier();\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n        let inputTileOffset = TILE_SIZE * local_id.y + k;\n        let weightTileOffset = TILE_SIZE * k + local_id.x;\n        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];\n        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];\n        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = (m * uniforms.N + n) % uniforms.head_size;\n    valueQ += bias[headOffset + biasOffsetQ];\n    valueK += bias[headOffset + biasOffsetK];\n    valueV += bias[headOffset + biasOffsetV];\n\n    let offset = workgroup_id.z * uniforms.M * uniforms.N;\n    if (m < uniforms.M && n < uniforms.N) {\n      let outputIdx = offset + m * uniforms.N + n;\n      output_q[outputIdx] = valueQ;\n      output_k[outputIdx] = valueK;\n      output_v[outputIdx] = valueV;\n    }\n  }`}},{inputs:l,outputs:[-1,-1,-1]})},Rn=(e,t)=>{let n=In(e.inputs,t),[r,i,s]=Dn(e,n);return Ln(e,r,i,s,e.inputs[4],void 0,void 0,void 0,e.inputs[5],n,t)}})),qa=V((()=>{Ta(),Aa(),Da(),La(),Ra(),Nn=(e,t)=>{if(!e||5!==e.length)throw new Error("BatchNormalization requires 5 inputs");let n=(e,t,n)=>{let r=t.length;if(r!==e.length)throw new Error(`${n}: num dimensions != ${r}`);t.forEach(((t,r)=>{if(t!==e[r])throw new Error(`${n}: dim[${r}] do not match`)}))};if(e[0].dims.length>1){let r="NHWC"===t.format?t.spatial?e[0].dims.slice(-1):e[0].dims.slice(-1).concat(e[0].dims.slice(1,e[0].dims.length-1)):e[0].dims.slice(1,t.spatial?2:void 0);n(e[1].dims,r,"Invalid input scale"),n(e[2].dims,r,"Invalid input B"),n(e[3].dims,r,"Invalid input mean"),n(e[4].dims,r,"Invalid input var")}else n(e[1].dims,[1],"Invalid input scale"),n(e[2].dims,[1],"Invalid input B"),n(e[3].dims,[1],"Invalid input mean"),n(e[4].dims,[1],"Invalid input var")},Vn=(e,t)=>{let{epsilon:n,spatial:r,format:i}=t,s=e[0].dims,o=r?gt(s[s.length-1]):1,a="NHWC"===i&&s.length>1?o:1,l=ot.size(s)/o,d=r,u=d?s.length:s,c=xt("x",e[0].dataType,e[0].dims,o),p=xt("scale",e[1].dataType,e[1].dims,a),h=xt("bias",e[2].dataType,e[2].dims,a),f=xt("inputMean",e[3].dataType,e[3].dims,a),m=xt("inputVar",e[4].dataType,e[4].dims,a),g=Mt("y",e[0].dataType,u,o);return{name:"BatchNormalization",shaderCache:{hint:`${t.epsilon}_${t.format}_${r}_${o}`,inputDependencies:d?["rank","type","type","type","type"]:void 0},getShaderSource:e=>`\n  const epsilon = ${n};\n  ${e.registerUniform("outputSize","u32").declareVariables(c,p,h,f,m,g)}\n  ${e.mainStart()}\n  ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n    var outputIndices = ${g.offsetToIndices(`global_idx * ${o}`)};\n    ${(()=>{let e="";if(r)e=`let cOffset = ${1===s.length?"0u":"NHWC"===i?`outputIndices[${s.length-1}] / ${o}`:"outputIndices[1]"};`;else if("NCHW"===i)e=`\n            ${g.indicesSet("outputIndices","0","0")}\n            let cOffset = ${g.indicesToOffset("outputIndices")};`;else{e=`var cIndices = ${p.type.indices}(0);\n                       cIndices[0] = outputIndices[${s.length-1}];`;for(let t=1;t<p.rank;t++)e+=`cIndices[${t}] = outputIndices[${t}];`;e+=`let cOffset = ${p.indicesToOffset("cIndices")};`}return e})()}\n    let scale = ${p.getByOffset("cOffset")};\n    let bias = ${h.getByOffset("cOffset")};\n    let inputMean = ${f.getByOffset("cOffset")};\n    let inputVar = ${m.getByOffset("cOffset")};\n    let x = ${c.getByOffset("global_idx")};\n    let value = (x - inputMean) * inverseSqrt(inputVar + epsilon) * scale + bias;\n    ${g.setByOffset("global_idx","value")}\n  }`,getRunData:()=>({outputs:[{dims:e[0].dims,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(l/64)},programUniforms:d?[{type:12,data:l},...mt(s)]:[{type:12,data:l}]})}},jn=e=>rt(e),Un=(e,t)=>{let{inputs:n,outputCount:r}=e,i=jn({...t,outputCount:r});if(p.webgpu.validateInputContent&&Nn(n,i),t.trainingMode)throw new Error("BatchNormalization trainingMode is not supported yet.");e.compute(Vn(n,i))}})),Wa=V((()=>{Da(),Ra(),Gn=e=>{if(3!==e[0].dims.length)throw new Error("input should have 3 dimensions");if(![320,640,1280].includes(e[0].dims[2]))throw new Error("number of channels should be 320, 640 or 1280");if(1!==e[1].dims.length)throw new Error("bias is expected to have 1 dimensions");if(e[0].dims[2]!==e[1].dims[0])throw new Error("last dimension of input and bias are not the same")},qn=e=>{let t=e[0].dims,n=e[0].dims[2],r=ot.size(t)/4,i=e[0].dataType,s=xt("input",i,t,4),o=xt("bias",i,[n],4),a=xt("residual",i,t,4),l=Mt("output",i,t,4);return{name:"BiasAdd",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(r/64)}}),getShaderSource:e=>`\n  const channels = ${n}u / 4;\n  ${e.declareVariables(s,o,a,l)}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(r)}\n    let value = ${s.getByOffset("global_idx")}\n      + ${o.getByOffset("global_idx % channels")} + ${a.getByOffset("global_idx")};\n    ${l.setByOffset("global_idx","value")}\n  }`}},Wn=e=>{Gn(e.inputs),e.compute(qn(e.inputs))}})),Ha=V((()=>{Aa(),Da(),La(),Ra(),Hn=(e,t,n,r,i,s)=>{let o=Math.ceil(t/4),a="";a="string"==typeof i?`${i}(a)`:i("a");let l=xt("inputData",n,[o],4),d=Mt("outputData",r,[o],4);return`\n      ${e.registerUniform("vec_size","u32").declareVariables(l,d)}\n\n  ${s??""}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}\n\n    let a = ${l.getByOffset("global_idx")};\n    ${d.setByOffset("global_idx",a)}\n  }`},Xn=(e,t,n,r,i,s=e.dataType)=>({name:t,shaderCache:{hint:i,inputDependencies:["type"]},getShaderSource:t=>Hn(t,ot.size(e.dims),e.dataType,s,n,r),getRunData:t=>({outputs:[{dims:e.dims,dataType:s}],dispatchGroup:{x:Math.ceil(ot.size(t[0].dims)/64/4)},programUniforms:[{type:12,data:Math.ceil(ot.size(e.dims)/4)}]})}),Qn=e=>{e.compute(Xn(e.inputs[0],"Abs","abs"))},Kn=e=>{e.compute(Xn(e.inputs[0],"Acos","acos"))},Yn=e=>{e.compute(Xn(e.inputs[0],"Acosh","acosh"))},Zn=e=>{e.compute(Xn(e.inputs[0],"Asin","asin"))},Jn=e=>{e.compute(Xn(e.inputs[0],"Asinh","asinh"))},er=e=>{e.compute(Xn(e.inputs[0],"Atan","atan"))},tr=e=>{e.compute(Xn(e.inputs[0],"Atanh","atanh"))},nr=e=>rt(e),rr=(e,t)=>{let n;switch(t.to){case 10:n="vec4<f16>";break;case 1:n="vec4<f32>";break;case 12:n="vec4<u32>";break;case 6:n="vec4<i32>";break;case 9:n="vec4<bool>";break;default:throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${t.to}`)}e.compute(Xn(e.inputs[0],"Cast",n,void 0,t.cacheKey,t.to))},ir=e=>{let t=e.length>=2&&0!==e[1].data?e[1].getFloat32Array()[0]:dt,n=e.length>=3&&0!==e[2].data?e[2].getFloat32Array()[0]:ut;return rt({min:t,max:n})},sr=(e,t)=>{let n=1===e.inputs.length?t:ir(e.inputs),r=ft(e.inputs[0].dataType);e.compute(Xn(e.inputs[0],"Clip",(e=>`clamp(${e}, clip_min_, clip_max_)`),`\n    const clip_min_: vec4<${r}> = vec4(${r}(${n.min}));\n    const clip_max_: vec4<${r}> = vec4(${r}(${n.max}));\n`,n.cacheKey),{inputs:[0]})},or=e=>{e.compute(Xn(e.inputs[0],"Ceil","ceil"))},ar=e=>{e.compute(Xn(e.inputs[0],"Cos","cos"))},lr=e=>{e.compute(Xn(e.inputs[0],"Cosh","cosh"))},dr=e=>rt(e),ur=(e,t)=>{let n=ft(e.inputs[0].dataType);e.compute(Xn(e.inputs[0],"Elu",(e=>`elu_vf32(${e})`),`\n  const elu_alpha_ = ${n}(${t.alpha});\n\n  fn elu_f32(a: ${n}) -> ${n} {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<${n}>) -> vec4<${n}> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,t.cacheKey))},cr=(e="f32")=>`\nconst r0: ${e} = 0.3275911;\nconst r1: ${e} = 0.254829592;\nconst r2: ${e} = -0.284496736;\nconst r3: ${e} = 1.421413741;\nconst r4: ${e} = -1.453152027;\nconst r5: ${e} = 1.061405429;\n\nfn erf_vf32(v: vec4<${e}>) -> vec4<${e}> {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`,pr=e=>{let t=ft(e.inputs[0].dataType);e.compute(Xn(e.inputs[0],"Erf",(e=>`erf_vf32(${e})`),cr(t)))},hr=e=>{e.compute(Xn(e.inputs[0],"Exp","exp"))},fr=e=>{e.compute(Xn(e.inputs[0],"Floor","floor"))},mr=e=>{let t=ft(e.inputs[0].dataType);e.compute(Xn(e.inputs[0],"Gelu",(e=>`0.5 * ${e} * (1.0 + erf_vf32(${e} * 0.7071067811865475))`),cr(t)))},gr=(e,t)=>{let n=ft(e.inputs[0].dataType);e.compute(Xn(e.inputs[0],"LeakyRelu",(e=>`select(leaky_relu_alpha_ * ${e}, ${e}, ${e} >= vec4<${n}>(0.0))`),`const leaky_relu_alpha_ = ${n}(${t.alpha});`,t.cacheKey))},_r=e=>{e.compute(Xn(e.inputs[0],"Not",(e=>`!${e}`)))},wr=e=>{e.compute(Xn(e.inputs[0],"Neg",(e=>`-${e}`)))},yr=e=>{e.compute(Xn(e.inputs[0],"Reciprocal",(e=>`1.0/${e}`)))},br=e=>{let t=ft(e.inputs[0].dataType);e.compute(Xn(e.inputs[0],"Relu",(e=>`select(vec4<${t}>(0.0), ${e}, ${e} > vec4<${t}>(0.0))`)))},vr=e=>{e.compute(Xn(e.inputs[0],"Sigmoid",(e=>`(1.0 / (1.0 + exp(-${e})))`)))},xr=e=>rt(e),Mr=(e,t)=>{let n=ft(e.inputs[0].dataType);e.compute(Xn(e.inputs[0],"HardSigmoid",(e=>`max(vec4<${n}>(0.0), min(vec4<${n}>(1.0), ${t.alpha} * ${e} + vec4<${n}>(${t.beta})))`),void 0,t.cacheKey))},Tr=e=>{e.compute(Xn(e.inputs[0],"Sin","sin"))},kr=e=>{e.compute(Xn(e.inputs[0],"Sinh","sinh"))},$r=e=>{e.compute(Xn(e.inputs[0],"Sqrt","sqrt"))},Sr=e=>{e.compute(Xn(e.inputs[0],"Tan","tan"))},Cr=e=>`sign(${e}) * (1 - exp(-2 * abs(${e}))) / (1 + exp(-2 * abs(${e})))`,Pr=e=>{e.compute(Xn(e.inputs[0],"Tanh",Cr))},Er=(e="f32")=>`\nconst fast_gelu_a: ${e} = 0.5;\nconst fast_gelu_b: ${e} = 0.7978845608028654;\nconst fast_gelu_c: ${e} = 0.035677408136300125;\n\nfn tanh_v(v: vec4<${e}>) -> vec4<${e}> {\n  return ${Cr("v")};\n}\n`,Ar=e=>`(fast_gelu_a + fast_gelu_a * tanh_v(${e} * (fast_gelu_c * ${e} * ${e} + fast_gelu_b))) * ${e}`,Fr=e=>{let t=ft(e.inputs[0].dataType);e.compute(Xn(e.inputs[0],"FastGelu",Ar,Er(t),void 0,e.inputs[0].dataType))},Ir=(e,t)=>{let n=ft(e.inputs[0].dataType);return e.compute(Xn(e.inputs[0],"ThresholdedRelu",(e=>`select(vec4<${n}>(0.0), ${e}, ${e} > thresholded_relu_alpha_)`),`const thresholded_relu_alpha_ = vec4<${n}>(${t.alpha});`,t.cacheKey)),0},zr=e=>{e.compute(Xn(e.inputs[0],"Log","log"))}})),Xa=V((()=>{Da(),Ra(),Ha(),Br=e=>{if(3!==e[0].dims.length)throw new Error("input should have 3 dimensions");if(![2560,5120,10240].includes(e[0].dims[2]))throw new Error("hidden state should be 2560, 5120 or 10240");if(1!==e[1].dims.length)throw new Error("bias is expected to have 1 dimensions");if(e[0].dims[2]!==e[1].dims[0])throw new Error("last dimension of input and bias are not the same")},Or=e=>{let t=e[0].dims.slice();t[2]=t[2]/2;let n=xt("input",e[0].dataType,e[0].dims,4),r=xt("bias",e[0].dataType,[e[0].dims[2]],4),i=Mt("output",e[0].dataType,t,4),s=ot.size(t)/4,o=ht(e[0].dataType);return{name:"BiasSplitGelu",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:t=>`\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${e[0].dims[2]/4/2}u;\n\n  ${t.declareVariables(n,r,i)}\n\n  ${cr(o)}\n\n  ${t.mainStart()}\n    ${t.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${i.setByOffset("global_idx","valueLeft * geluRight")}\n  }`}},Lr=e=>{Br(e.inputs),e.compute(Or(e.inputs))}})),Qa=V((()=>{Aa(),Da(),Ra(),Dr=(e,t,n,r,i,s,o,a,l,d,u,c)=>{let p,h;"string"==typeof a?p=h=(e,t)=>`${a}((${e}),(${t}))`:"function"==typeof a?p=h=a:(p=a.scalar,h=a.vector);let f,m=Mt("outputData",u,r.length,4),g=xt("aData",l,t.length,4),_=xt("bData",d,n.length,4);if(i)if(s){let e=1===ot.size(t),r=1===ot.size(n),i=t.length>0&&t[t.length-1]%4==0,s=n.length>0&&n[n.length-1]%4==0;f=e||r?m.setByOffset("global_idx",h(e?`${g.type.value}(${g.getByOffset("0")}.x)`:g.getByOffset("global_idx"),r?`${_.type.value}(${_.getByOffset("0")}.x)`:_.getByOffset("global_idx"))):`\n            let outputIndices = ${m.offsetToIndices("global_idx * 4u")};\n            let offsetA = ${g.broadcastedIndicesToOffset("outputIndices",m)};\n            let offsetB = ${_.broadcastedIndicesToOffset("outputIndices",m)};\n            ${m.setByOffset("global_idx",h(o||i?g.getByOffset("offsetA / 4u"):`${g.type.value}(${g.getByOffset("offsetA / 4u")}[offsetA % 4u])`,o||s?_.getByOffset("offsetB / 4u"):`${_.type.value}(${_.getByOffset("offsetB / 4u")}[offsetB % 4u])`))}\n          `}else f=m.setByOffset("global_idx",h(g.getByOffset("global_idx"),_.getByOffset("global_idx")));else{if(!s)throw new Error("no necessary to use scalar implementation for element-wise binary op implementation.");let e=(e,t,n="")=>{let r=`aData[indexA${t}][componentA${t}]`,i=`bData[indexB${t}][componentB${t}]`;return`\n            let outputIndices${t} = ${m.offsetToIndices(`global_idx * 4u + ${t}u`)};\n            let offsetA${t} = ${g.broadcastedIndicesToOffset(`outputIndices${t}`,m)};\n            let offsetB${t} = ${_.broadcastedIndicesToOffset(`outputIndices${t}`,m)};\n            let indexA${t} = offsetA${t} / 4u;\n            let indexB${t} = offsetB${t} / 4u;\n            let componentA${t} = offsetA${t} % 4u;\n            let componentB${t} = offsetB${t} % 4u;\n            ${e}[${t}] = ${n}(${p(r,i)});\n          `};f=9===u?`\n            var data = vec4<u32>(0);\n            ${e("data",0,"u32")}\n            ${e("data",1,"u32")}\n            ${e("data",2,"u32")}\n            ${e("data",3,"u32")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:`\n            ${e("outputData[global_idx]",0)}\n            ${e("outputData[global_idx]",1)}\n            ${e("outputData[global_idx]",2)}\n            ${e("outputData[global_idx]",3)}\n          `}return`\n        ${e.registerUniform("vec_size","u32").declareVariables(g,_,m)}\n\n        ${c??""}\n\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}\n        ${f}\n      }`},Rr=(e,t,n,r,i,s,o=n.dataType)=>{let a=!ot.areEqual(n.dims,r.dims),l=n.dims,d=ot.size(n.dims),u=!1,c=!1,p=[a];if(a){let e=st.calcShape(n.dims,r.dims,!1);if(!e)throw new Error("Can't perform binary op on the given tensors");l=e,d=ot.size(l);let t=1===ot.size(n.dims),i=1===ot.size(r.dims),s=n.dims.length>0&&n.dims[n.dims.length-1]%4==0,o=r.dims.length>0&&r.dims[r.dims.length-1]%4==0;p.push(t),p.push(i),p.push(s),p.push(o);let a=1;for(let e=1;e<l.length;e++){let t=n.dims[n.dims.length-e]??1;if(t!==(r.dims[r.dims.length-e]??1))break;a*=t}a%4==0?(c=!0,u=!0):(t||i||s||o)&&(u=!0)}else u=!0;return p.push(u),{name:e,shaderCache:{hint:t+p.map((e=>e.toString())).join("_"),inputDependencies:["rank","rank"]},getShaderSource:e=>Dr(e,n.dims,r.dims,l,u,a,c,i,n.dataType,r.dataType,o,s),getRunData:()=>({outputs:[{dims:l,dataType:o}],dispatchGroup:{x:Math.ceil(d/64/4)},programUniforms:[{type:12,data:Math.ceil(ot.size(l)/4)},...mt(n.dims,r.dims,l)]})}},Nr=(e,t,n,r,i,s)=>{e.compute(Rr(t,i??"",e.inputs[0],e.inputs[1],n,r,s))},Vr=e=>{Nr(e,"Add",((e,t)=>`${e}+${t}`))},jr=e=>{Nr(e,"Div",((e,t)=>`${e}/${t}`))},Ur=e=>{Nr(e,"Equal",{scalar:(e,t)=>`u32(${e}==${t})`,vector:(e,t)=>`vec4<u32>(${e}==${t})`},void 0,void 0,9)},Gr=e=>{Nr(e,"Mul",((e,t)=>`${e}*${t}`))},qr=e=>{let t=xt("input",e.inputs[0].dataType,e.inputs[0].dims).type.value;Nr(e,"Pow",{scalar:(e,t)=>`pow_custom(${e},${t})`,vector:(e,t)=>`pow_vector_custom(${e},${t})`},`\n    fn pow_custom(a : ${t}, b : ${t}) -> ${t} {\n      if (b == ${t}(0.0)) {\n        return ${t}(1.0);\n      } else if (a < ${t}(0.0) && f32(b) != floor(f32(b))) {\n        return ${t}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${t}(1.0), round(f32(abs(b) % ${t}(2.0))) != 1.0) * ${t}(${"i32"===t?"round":""}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${t}>, b : vec4<${t}>) -> vec4<${t}> {\n      // TODO: implement vectorized pow\n      return vec4<${t}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `)},Wr=e=>{Nr(e,"Sub",((e,t)=>`${e}-${t}`))},Hr=e=>{Nr(e,"Greater",{scalar:(e,t)=>`u32(${e}>${t})`,vector:(e,t)=>`vec4<u32>(${e}>${t})`},void 0,void 0,9)},Xr=e=>{Nr(e,"Less",{scalar:(e,t)=>`u32(${e}<${t})`,vector:(e,t)=>`vec4<u32>(${e}<${t})`},void 0,void 0,9)},Qr=e=>{Nr(e,"GreaterOrEqual",{scalar:(e,t)=>`u32(${e}>=${t})`,vector:(e,t)=>`vec4<u32>(${e}>=${t})`},void 0,void 0,9)},Kr=e=>{Nr(e,"LessOrEqual",{scalar:(e,t)=>`u32(${e}<=${t})`,vector:(e,t)=>`vec4<u32>(${e}<=${t})`},void 0,void 0,9)}})),Ka=V((()=>{Aa(),Da(),La(),Ra(),Yr=(e,t)=>{if(!e||e.length<1)throw new Error("too few inputs");let n=e[0],r=n.dataType,i=n.dims.length;e.forEach(((e,s)=>{if(0!==s){if(e.dataType!==r)throw new Error("input tensors should be one type");if(e.dims.length!==i)throw new Error("input tensors should have the same shape");e.dims.forEach(((e,r)=>{if(r!==t&&e!==n.dims[r])throw new Error("non concat dimensions must match")}))}}))},Zr=(e,t)=>`\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${e}u>(${t});\n    for (var i: u32 = 0u; i < ${e}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${e}u;\n  }`,Jr=(e,t)=>{let n=e.length,r=[];for(let i=0;i<n;++i){let s=t.setByOffset("global_idx",e[i].getByIndices("indices"));1===n?r.push(s):0===i?r.push(`if (inputIndex == ${i}u) { ${s} }`):i===n-1?r.push(`else { ${s} }`):r.push(`else if (inputIndex == ${i}) { ${s} }`)}return r.join("\n")},ei=(e,t,n,r)=>{let i=ot.size(n),s=new Array(e.length),o=new Array(e.length),a=0,l=[],d=[],u=[{type:12,data:i}];for(let n=0;n<e.length;++n)a+=e[n].dims[t],s[n]=a,d.push(e[n].dims.length),o[n]=xt(`input${n}`,r,d[n]),l.push("rank"),u.push({type:12,data:s[n]});for(let t=0;t<e.length;++t)u.push(...mt(e[t].dims));u.push(...mt(n));let c=Mt("output",r,n.length),p=c.indicesGet("indices",t),h=Array.from(Array(s.length).keys()).map((e=>`uniforms.sizeInConcatAxis${e}`)).join(",");return{name:"Concat",shaderCache:{hint:`${t}`,inputDependencies:l},getRunData:()=>({outputs:[{dims:n,dataType:r}],dispatchGroup:{x:Math.ceil(i/64)},programUniforms:u}),getShaderSource:t=>`\n\n  ${(()=>{t.registerUniform("outputSize","u32");for(let n=0;n<e.length;n++)t.registerUniform(`sizeInConcatAxis${n}`,"u32");return t.declareVariables(...o,c)})()}\n\n  ${Zr(s.length,h)}\n\n  ${t.mainStart()}\n    ${t.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n\n    var indices = ${c.offsetToIndices("global_idx")};\n\n    let inputIndex = calculateInputIndex(${p});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${s.length}u>(${h});\n      ${p} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${Jr(o,c)}\n  }`}},ti=(e,t)=>{let n=e.inputs,r=n[0].dims,i=ot.normalizeAxis(t.axis,r.length);Yr(n,i);let s=r.slice();s[i]=n.reduce(((e,t)=>e+(t.dims.length>i?t.dims[i]:0)),0);let o=n.filter((e=>ot.size(e.dims)>0));e.compute(ei(o,i,s,n[0].dataType),{inputs:o})},ni=e=>rt({axis:e.axis})})),Ya=V((()=>{Aa(),Da(),ri=(e,t,n="f32")=>{switch(e.activation){case"Relu":return`value = max(value, ${t}(0.0));`;case"Sigmoid":return`value = (${t}(1.0) / (${t}(1.0) + exp(-value)));`;case"Clip":return`value = clamp(value, ${t}(${n}(uniforms.clip_min)), ${t}(${n}(uniforms.clip_max)));`;case"HardSigmoid":return`value = max(${t}(0.0), min(${t}(1.0), ${n}(uniforms.alpha) * value + ${n}(uniforms.beta)));`;case"LeakyRelu":return`value = select(${n}(uniforms.alpha) * value, value, value >= ${t}(0.0));`;case"":return"";default:throw new Error(`Unsupported activation ${e.activation}`)}},ii=(e,t)=>{"Clip"===e.activation?t.push({type:1,data:e.clipMax},{type:1,data:e.clipMin}):"HardSigmoid"===e.activation?t.push({type:1,data:e.alpha},{type:1,data:e.beta}):"LeakyRelu"===e.activation&&t.push({type:1,data:e.alpha})},si=(e,t)=>{"Clip"===e.activation?t.push({name:"clip_max",type:"f32"},{name:"clip_min",type:"f32"}):"HardSigmoid"===e.activation?t.push({name:"alpha",type:"f32"},{name:"beta",type:"f32"}):"LeakyRelu"===e.activation&&t.push({name:"alpha",type:"f32"})},oi=e=>{let t=e?.activation||"";if("HardSigmoid"===t){let[n,r]=e?.activation_params||[.2,.5];return{activation:t,alpha:n,beta:r}}if("Clip"===t){let[n,r]=e?.activation_params||[dt,ut];return{activation:t,clipMax:r,clipMin:n}}if("LeakyRelu"===t){let[n]=e?.activation_params||[.01];return{activation:t,alpha:n}}return{activation:t}}})),Za=V((()=>{ai=(e,t)=>{switch(e){case 1:return t;case 2:return`vec2<${t}>`;case 3:return`vec3<${t}>`;case 4:return`vec4<${t}>`;default:throw new Error(`${e}-component is not supported.`)}},li=e=>`\n      ${e?"value = value + getBiasByOutputCoords(coords);":""}\n      `})),Ja=V((()=>{di=e=>`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    i32(${e}.x), i32(${e}.y), i32(${e}.z), 1));\n}\n`})),el=V((()=>{Aa(),Da(),Ra(),Ya(),Za(),ui=(e,t)=>e?`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${t?", batchIndices":""});\n        `:`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${t?", batchIndices":""});\n        `,ci=(e,t)=>e?`\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${3===t?"":"let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];"}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${3===t?"":"acc[i] = BCached3 * ACached3[i] + acc[i];"}\n        }`:`\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${3===t?"":"acc[i] = BCached3 * ACached.w + acc[i];"}\n        }`,pi=(e,t,n="f32",r,i=!1,s=32,o=!1,a=32)=>{let l=t[1]*e[1],d=t[0]*e[0],u=i?l:s,c=i?s:l,p=u/t[0],h=s/t[1];if((!i||4!==p||4!==e[1])&&(i||3!==p&&4!==p)||u%t[0]!=0||s%t[1]!=0||4!==e[0])throw new Error(`If transposeA ${i} is true, innerElementSize ${p} and workPerThread[1] ${e[1]} must be 4.\n      Otherwise, innerElementSize ${p} must be 3 or 4.\n  tileAWidth ${u} must be divisible by workgroupSize[0]${t[0]}. tileInner ${s} must be divisible by workgroupSize[1] ${t[1]}. colPerThread ${e[0]} must be 4.`);return`\nvar<workgroup> mm_Asub: array<array<vec${p}<${n}>, ${u/p}>, ${c}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${n}>, ${d/e[0]}>, ${s}>;\n\nconst rowPerThread = ${e[1]};\nconst colPerThread = ${e[0]};\nconst innerElementSize = ${p};\nconst tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${o?"0":"i32(globalId.z)"};\n  ${r?`let batchIndices = ${r.offsetToIndices("u32(batch)")};`:""}\n  let globalRowStart = i32(workgroupId.y) * ${l};\n\n  let num_tiles = ${o?`${Math.ceil(a/s)}`:"(uniforms.dim_inner - 1) / tileInner + 1"};\n  var kStart = ${o?`i32(globalId.z) * ${a}`:"0"};\n\n  var acc: array<vec4<${n}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${h};\n  for (var t = 0; t < num_tiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${ui(i,r)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${h}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${r?", batchIndices":""});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${3===p?"":"let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];"}\n\n          ${ci(i,p)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`},hi=(e,t)=>e?`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${t?", batchIndices":""});\n            `:`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${t?", batchIndices":""});\n            `,fi=e=>e?"let ACached = mm_Asub[k][tileRow + innerRow];":"let ACached = mm_Asub[tileRow + innerRow][k];",mi=(e,t,n="f32",r,i=!1,s=32,o=!1,a=32,l=!1)=>{let d=e[1]*t[1],u=e[0]*t[0],c=i?d:s,p=i?s:d;if(p%t[1]!=0||c%t[0]!=0||s%t[1]!=0)throw new Error(`tileAHight ${p} must be divisible by workgroupSize[1]${t[1]}, tileAWidth ${c} must be divisible by workgroupSize[0]${t[0]}, tileInner ${s} must be divisible by workgroupSize[1]${t[1]}`);let h=p/t[1],f=c/t[0],m=s/t[1],g=l?`\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${d};\n    let globalColStart = i32(workgroupId.x) * ${u};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < num_tiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${p}; inputRow = inputRow + ${t[1]}) {\n        for (var inputCol = localCol; inputCol < ${c}; inputCol = inputCol + ${t[0]}) {\n          ${hi(i,r)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${s}; inputRow = inputRow + ${t[1]}) {\n            for (var inputCol = localCol; inputCol < ${u}; inputCol = inputCol + ${t[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${r?", batchIndices":""});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${n}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${t[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${i?`mm_Asub[k][localRow + innerRow * ${t[1]}];`:`mm_Asub[localRow + innerRow * ${t[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${t[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${t[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    `:`\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${d};\n\nlet tileRowA = i32(localId.y) * ${h};\nlet tileColA = i32(localId.x) * ${f};\nlet tileRowB = i32(localId.y) * ${m};\n// Loop over shared dimension.\nfor (var t = 0; t < num_tiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${h}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${f}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${hi(i,r)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${m}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${r?", batchIndices":""});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${n}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${fi(i)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;return`\n  var<workgroup> mm_Asub : array<array<${n}, ${c}>, ${p}>;\n  var<workgroup> mm_Bsub : array<array<${n}, ${u}>, ${s}>;\n  const rowPerThread = ${e[1]};\n  const colPerThread = ${e[0]};\n  const tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${o?"0":"i32(globalId.z)"};\n    ${r?`let batchIndices = ${r.offsetToIndices("u32(batch)")};`:""}\n    let num_tiles = ${o?`${Math.ceil(a/s)}`:"(uniforms.dim_inner - 1) / tileInner + 1"};\n    var kStart = ${o?`i32(globalId.z) * ${a}`:"0"};\n\n    var acc : array<array<${n}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${g}\n  }\n`},gi=(e,t,n,r,i,s=!1)=>{let[o,a,l]=i,[d,u,c,p]=r,h=St(o,l),f=St(a,l),m=ht(r[0].type.tensor);return`\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${d.type.indices}) -> ${ai(e,m)} {\n      var value = ${ai(e,m)}(0.0);\n      let col = colIn * ${e};\n      if(row < uniforms.dim_a_outer && col < uniforms.dim_inner)\n      {\n        ${(()=>{let e=u.rank,t=d.rank,n=`var aIndices: ${u.type.indices};`;for(let r=e-2-1,i=t-1;r>=0;r--,i--)n+=`\naIndices[${r}] = ${t>1?`batchIndices[${i}]`:"batchIndices"};`;return h.forEach((e=>{n+=`\naIndices[${e}] = 0;`})),n+=`\naIndices[${e-2}] = u32(row);\n                   aIndices[${e-1}] = u32(colIn);`,n})()}\n        value = ${u.getByIndices("aIndices")};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${d.type.indices}) -> ${ai(e,m)} {\n      var value = ${ai(e,m)}(0.0);\n      let col = colIn * ${e};\n      if(row < uniforms.dim_inner && col < uniforms.dim_b_outer)\n      {\n        ${(()=>{let e=c.rank,t=d.rank,n=`var bIndices: ${c.type.indices};`;for(let r=e-2-1,i=t-1;r>=0;r--,i--)n+=`\nbIndices[${r}] = ${t>1?`batchIndices[${i}]`:"batchIndices"};`;return f.forEach((e=>{n+=`\nbIndices[${e}] = 0;`})),n+=`\nbIndices[${e-2}] = u32(row);\n                   bIndices[${e-1}] = u32(colIn);`,n})()}\n        value = ${c.getByIndices("bIndices")};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${ai(e,m)}) {\n      let col = colIn * ${e};\n      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${t?`value = value + ${s?"bias[colIn]":`${ai(e,m)}(bias[row])`};`:""}\n        ${n}\n        ${p.setByIndices("vec3<u32>(coords)","value")}\n      }\n    }\n    `},_i=(e,t,n,r,i=!1)=>{let s=e[0].dims,o=e[1].dims,a=s.slice(0,-2),l=o.slice(0,-2),d=r?r.slice(0,-2):n.slice(0,-2),u=ot.size(d),c=s[s.length-2],p=s[s.length-1],h=o[o.length-1],f=p%4==0&&h%4==0,m=c<=8?[4,1,1]:[4,4,1],g=[8,8,1],_=[Math.ceil(h/g[0]/m[0]),Math.ceil(c/g[1]/m[1]),Math.ceil(u/g[2]/m[2])],w=f?4:1,y=[...a,c,p/w],b=y.length,v=[...l,p,h/w],x=v.length,M=[u,c,h/w],T=[{type:6,data:c},{type:6,data:h},{type:6,data:p}];ii(t,T),T.push(...mt(d,y,v));let k=["rank","rank"],$=e.length>2;$&&(T.push(...mt(e[2].dims)),k.push("rank")),T.push(...mt(M));return{name:"MatMul",shaderCache:{hint:`${m};${t.activation};${f};${i}`,inputDependencies:k},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:_[0],y:_[1],z:_[2]},programUniforms:T}),getShaderSource:n=>{let r=d.length,s=Tt("batchDims",e[0].dataType,r,1),o=ht(e[0].dataType),u=xt("a",e[0].dataType,b,w),c=xt("b",e[1].dataType,x,w),p=Mt("result",e[0].dataType,M.length,w),h=[u,c];if($){let t=i?w:1;h.push(xt("bias",e[2].dataType,e[2].dims.length,t))}let _=[{name:"dim_a_outer",type:"i32"},{name:"dim_b_outer",type:"i32"},{name:"dim_inner",type:"i32"}];si(t,_);let y=ht(p.type.tensor),v=ri(t,p.type.value,y),T=gi(w,$,v,[s,u,c,p],[a,l,d],i);return`\n  ${n.registerUniforms(_).registerInternalVariables(s).declareVariables(...h,p)}\n  ${T}\n  ${f?pi(m,g,o,s):mi(m,g,o,s)}\n                   `}}}})),tl=V((()=>{Aa(),Ia(),Ra(),Ya(),Za(),Ja(),el(),wi=(e,t,n,r,i=!1,s,o=4,a=4,l=4,d="f32")=>{let u=e?"\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    ":"\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    ",c=e?"\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ":"\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    ",p=e?"i32(uniforms.x_shape[1])":"i32(uniforms.x_shape[2])",h=e?"i32(uniforms.x_shape[2])":"i32(uniforms.x_shape[3])",f=e?"row":"col",m=e?"col":"row",g=`\n    let inChannels = i32(uniforms.w_shape[2]);\n    let outWidth = ${e?"i32(uniforms.result_shape[2])":"i32(uniforms.result_shape[3])"};\n    let outRow = ${f} / outWidth;\n    let outCol = ${f} % outWidth;\n\n    let WRow = ${m} / (i32(uniforms.w_shape[1]) * inChannels);\n    let WCol = ${m} / inChannels % i32(uniforms.w_shape[1]);\n    let xRow = outRow * uniforms.stride[0] + uniforms.dilation[0] * WRow - uniforms.pad[0];\n    let xCol = outCol * uniforms.stride[1] + uniforms.dilation[1] * WCol - uniforms.pad[1];\n    let xCh = ${m} % inChannels;\n    var resData = ${ai(o,d)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${p} && xCol >= 0 && xCol < ${h}) {\n      ${u}\n      let xIndex = getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape));\n      ${(e=>{switch(e){case 1:return"resData = x[xIndex];";case 3:return`resData = vec3<${d}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;case 4:return"resData = x[xIndex / 4];";default:throw new Error(`innerElementSize ${e} is not supported.`)}})(o)}\n    }\n    return resData;`,_=e?t&&r?`\n    let col = colIn * ${o};\n    ${g}`:`\n    let col = colIn * ${o};\n    if (row < uniforms.dim_a_outer && col < uniforms.dim_inner) {\n      ${g}\n    }\n    return ${ai(o,d)}(0.0);`:r&&n?`\n    let col = colIn * ${o};\n    ${g}`:`\n    let col = colIn * ${o};\n    if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {\n      ${g}\n    }\n    return ${ai(o,d)}(0.0);`,w=`${(e=>{switch(e){case 1:return"return w[row * i32(uniforms.w_shape[3]) + colIn];";case 4:return"return w[row * i32(uniforms.w_shape[3]) / 4 + colIn];";default:throw new Error(`innerElementSize ${e} is not supported.`)}})(a)}`,y=ai(l,d),b=ai(e?o:a,d),v=ai(e?a:o,d),x=ri(s,y,d);return`\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${b} {\n      ${e?_:w}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${v} {\n      ${e?w:_}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${y}) {\n      let col = colIn * ${l};\n      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer)\n      {\n      var value = valueIn;\n      let outWidth = ${e?"i32(uniforms.result_shape[2])":"i32(uniforms.result_shape[3])"};\n      ${c}\n      ${li(i)}\n      ${x}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`},yi=(e,t,n,r,i,s,o,a)=>{let l="NHWC"===t.format,d=l?e[0].dims[3]:e[0].dims[1],u=n[0],c=l?n[2]:n[3],p=l?n[1]:n[2],h=l?n[3]:n[1],f=l&&(d%4==0||d%3==0)&&h%4==0,m=l?h:c*p,g=l?c*p:h,_=[8,8,1],w=r<=8?[4,1,1]:[4,4,1],y=[Math.ceil(m/_[0]/w[0]),Math.ceil(g/_[1]/w[1]),Math.ceil(u/_[2]/w[2])];Xe("verbose",(()=>`[conv2d_mm_webgpu] dispatch = ${y}`));let b=f?l&&d%4!=0?3:4:1,v=_[1]*w[1],x=_[0]*w[0],M=Math.max(_[0]*b,_[1]),T=r%v==0,k=i%x==0,$=s%M==0,S=f?[b,4,4]:[1,1,1],C=[{type:6,data:r},{type:6,data:i},{type:6,data:s},{type:6,data:[t.pads[0],t.pads[1]]},{type:6,data:t.strides},{type:6,data:t.dilations}];ii(t,C),C.push(...mt(e[0].dims,e[1].dims));let P=["rank","rank"];o&&(C.push(...mt(e[2].dims)),P.push("rank")),C.push(...mt(n));return{name:"Conv2DMatMul",shaderCache:{hint:`${t.cacheKey};${b};${f};${T};${k};${$};${v};${x};${M}`,inputDependencies:P},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:y[0],y:y[1],z:y[2]},programUniforms:C}),getShaderSource:r=>{let i=[{name:"dim_a_outer",type:"i32"},{name:"dim_b_outer",type:"i32"},{name:"dim_inner",type:"i32"},{name:"pad",type:"i32",length:2},{name:"stride",type:"i32",length:2},{name:"dilation",type:"i32",length:2}];si(t,i);let s=f?4:1,d=ht(e[0].dataType),u=`\n      fn setOutputAtIndex(flatIndex : i32, value : ${f?`vec4<${d}>`:d}) {\n        result[flatIndex] = ${f?`vec4<${d}>`:d}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${f?`vec4<${d}>`:d}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${f?"/ 4":""}, value);\n      }`,c=[xt("x",e[0].dataType,e[0].dims.length,3===b?1:b),xt("w",e[1].dataType,e[1].dims.length,s)],p=Mt("result",e[0].dataType,n.length,s);if(o){let t=xt("bias",e[2].dataType,e[2].dims.length,s);c.push(t),u+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${f?`vec4<${d}>`:d} {\n          return bias[coords.${l?"w":"y"}${f?"/ 4":""}];\n        }`}return`\n        ${di("uniforms.result_strides")}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${r.registerUniforms(i).declareVariables(...c,p)}\n        ${u}\n        ${wi(l,T,k,$,o,t,S[0],S[1],S[2],d)}\n        ${f?pi(w,_,d,void 0,!l,M):mi(w,_,d,void 0,!l,M,!1,void 0,a)}`}}}})),nl=V((()=>{Aa(),Da(),Ra(),il(),Ya(),bi=(e,t,n)=>{let r=e.length>2,i=r?"value += b[output_channel];":"",s=e[0].dims,o=e[1].dims,a=o[0]/t.group,l="NHWC"===t.format,d=ki(s,o,t.dilations,t.pads,t.strides,l),u=ot.size(d),c=[{type:12,data:u},{type:12,data:t.dilations},{type:12,data:[t.strides[0],t.strides[1]]},{type:12,data:[t.pads[0],t.pads[1]]},{type:12,data:a}];ii(t,c),c.push(...mt(s,o));let p=["rank","rank"];r&&(c.push(...mt(e[2].dims)),p.push("rank")),c.push(...mt(d));return{name:"GroupedConv",shaderCache:{hint:t.cacheKey,inputDependencies:p},getRunData:()=>({outputs:[{dims:n?n(d):d,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:c}),getShaderSource:n=>{let a=Mt("output",e[0].dataType,d.length),u=ht(a.type.tensor),c=ri(t,a.type.value,u),p=xt("x",e[0].dataType,s.length),h=xt("w",e[1].dataType,o.length),f=[p,h];r&&f.push(xt("b",e[2].dataType,e[2].dims.length));let m=[{name:"output_size",type:"u32"},{name:"dilations",type:"u32",length:t.dilations.length},{name:"strides",type:"u32",length:2},{name:"pads",type:"u32",length:2},{name:"output_channels_per_group",type:"u32"}];return si(t,m),`\n  ${n.registerUniforms(m).declareVariables(...f,a)}\n\n  ${n.mainStart()}\n    ${n.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n\n    let outputIndices = ${a.offsetToIndices("global_idx")};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${l?3:1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${l?1:2}], outputIndices[${l?2:3}]) * uniforms.strides - uniforms.pads;\n    let group_id: u32 = output_channel / uniforms.output_channels_per_group;\n\n    var value: ${a.type.value} = ${a.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < uniforms.w_shape[1]; wInChannel++) {\n      let input_channel = group_id * uniforms.w_shape[1] + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < uniforms.w_shape[2]; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * uniforms.dilations[0];\n\n        if (xHeight < 0u || xHeight >= uniforms.x_shape[${l?1:2}]) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < uniforms.w_shape[3]; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * uniforms.dilations[1];\n          if (xWidth < 0u || xWidth >= uniforms.x_shape[${l?2:3}]) {\n            continue;\n          }\n\n          let xVal = ${l?p.get("batch","xHeight","xWidth","input_channel"):p.get("batch","input_channel","xHeight","xWidth")};\n          let wVal = ${h.get("output_channel","wInChannel","wHeight","wWidth")};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${i}\n    ${c}\n    ${a.setByOffset("global_idx","value")}\n  }`}}},vi=(e,t,n)=>{let r=e.length>2,i=gt(n[3]),s=gt(n[2]),o=ot.size(n)/i/s,a=[e[0].dims[0],e[0].dims[1],e[0].dims[2],e[0].dims[3]/i],l=[e[1].dims[0],e[1].dims[1],e[1].dims[2],e[1].dims[3]/i],d=[n[0],n[1],n[2],n[3]/i],u=[{type:12,data:o},{type:6,data:[t.strides[0],t.strides[1]]},{type:6,data:[t.pads[0],t.pads[1]]}];ii(t,u),u.push(...mt(a,l,d));let c=(s-1)*t.strides[1]+l[1];return{name:"GroupedConv-Vectorize",shaderCache:{hint:`${t.cacheKey};${i};${s};${c};${l[0]};${l[1]}`,inputDependencies:r?["rank","rank","type"]:["rank","rank"]},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(o/64)},programUniforms:u}),getShaderSource:n=>{let o=Mt("output",e[0].dataType,d.length,i),u=ht(o.type.tensor),p=ri(t,o.type.value,u),h=xt("x",e[0].dataType,a.length,i),f=xt("w",e[1].dataType,l.length,i),m=[h,f];r&&m.push(xt("b",e[2].dataType,e[2].dims,i));let g=r?"value += b[output_channel];":"",_=[{name:"output_size",type:"u32"},{name:"strides",type:"i32",length:2},{name:"pads",type:"i32",length:2}];return si(t,_),`\n  ${n.registerUniforms(_).declareVariables(...m,o)}\n  ${n.mainStart()}\n    ${n.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n    let width0 = uniforms.output_shape[3];\n    let output_channel = global_idx % width0;\n    var index1 = global_idx / width0;\n    let width1 = uniforms.output_shape[2] / ${s}u;\n    let col = (index1 % width1) * ${s}u;\n    index1 = index1 / width1;\n    let row = index1 % uniforms.output_shape[1];\n    let batch = index1 / uniforms.output_shape[1];\n\n    let x_corner = vec2<i32>(i32(row), i32(col)) * uniforms.strides - uniforms.pads;\n\n    var x_vals: array<${h.type.value}, ${c}>;\n    var values: array<${o.type.value}, ${s}>;\n    let input_channel = output_channel;\n    // Use constant instead of uniform can give better performance for w's height/width.\n    for (var w_height: u32 = 0u; w_height < ${l[0]}; w_height++) {\n      let x_height = x_corner.x + i32(w_height);\n      if (x_height >= 0 && u32(x_height) < uniforms.x_shape[1]) {\n        for (var i = 0; i < ${c}; i++) {\n          let x_width = x_corner.y + i;\n          if (x_width >= 0 && u32(x_width) < uniforms.x_shape[2]) {\n            x_vals[i] = ${h.get("batch","u32(x_height)","u32(x_width)","input_channel")};\n          } else {\n            x_vals[i] = ${h.type.value}(0);\n          }\n        }\n        for (var w_width: u32 = 0u; w_width < ${l[1]}; w_width++) {\n          let w_val = ${f.get("w_height","w_width","0","output_channel")};\n          for (var i = 0u; i < ${s}u; i++) {\n            values[i] = fma(x_vals[i * u32(uniforms.strides[1]) + w_width], w_val, values[i]);\n          }\n        }\n      }\n    }\n\n    for (var i = 0u; i < ${s}u; i++) {\n      var value = values[i];\n      ${g}\n      ${p}\n      ${o.set("batch","row","col + i","output_channel","value")};\n    }\n  }`}}}})),rl=V((()=>{Aa(),Da(),el(),Ra(),Ya(),xi=(e,t,n,r,i=!1)=>{let s=e[0].dims,o=e[1].dims,a=s[s.length-2],l=o[o.length-1],d=s[s.length-1],u=gt(l),c=gt(d),p=gt(a),h=ot.size(n)/u/p,f=e.length>2,m=r?r.slice(0,-2):n.slice(0,-2),g=[ot.size(m),a,l],_=[{type:12,data:h},{type:12,data:a},{type:12,data:l},{type:12,data:d}];ii(t,_),_.push(...mt(m,s,o)),f&&_.push(...mt(e[2].dims)),_.push(...mt(g));return{name:"MatMulNaive",shaderCache:{hint:`${t.activation};${u};${c};${p};${i}`,inputDependencies:f?["rank","rank","rank"]:["rank","rank"]},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(h/64)},programUniforms:_}),getShaderSource:r=>{let a=Tt("batch_dims",e[0].dataType,m.length),l=xt("a",e[0].dataType,s.length,c),d=xt("b",e[1].dataType,o.length,u),h=Mt("output",e[0].dataType,g.length,u),_=ht(h.type.tensor),w=ri(t,h.type.value,_),y=[l,d],b="";if(f){let t=i?u:1;y.push(xt("bias",e[2].dataType,e[2].dims.length,t)),b=""+(i?`value += bias[col / ${t}];`:`value += ${h.type.value}(bias[row + i]);`)}let v=s.slice(0,-2),x=o.slice(0,-2),M=St(v,m),T=St(x,m),k=[{name:"output_size",type:"u32"},{name:"M",type:"u32"},{name:"N",type:"u32"},{name:"K",type:"u32"}];si(t,k);let $=(e,t)=>{let n=e.rank,r=e.name;if(2===n)return`var ${r}_indices = ${e.type.indices}(0u, 0u);`;let i=a.rank,s=`var ${r}_indices: ${e.type.indices};`;for(let e=n-2-1,t=i-1;e>=0;e--,t--)s+=`\n${r}_indices[${e}] = ${i>1?`batch_indices[${t}]`:"batch_indices"};`;return t.forEach((e=>{s+=`\n${r}_indices[${e}] = 0;`})),s+=`${r}_indices[${n-2}] = 0u;\n                     ${r}_indices[${n-1}] = 0u;`,s};return`\n  ${r.registerUniforms(k).registerInternalVariables(a).declareVariables(...y,h)}\n  ${r.mainStart()}\n    ${r.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n    let col = (global_idx % (uniforms.N / ${u})) * ${u};\n    var index1 = global_idx / (uniforms.N / ${u});\n    let stride1 = uniforms.M / ${p};\n    let row = (index1 % stride1) * ${p};\n    let batch = index1 / stride1;\n\n    ${2===n.length?"":`let batch_indices = ${a.offsetToIndices("batch")};`}\n    ${$(l,M)}\n    let a_offset = ${l.indicesToOffset("a_indices")};\n    ${$(d,T)}\n    let b_offset = ${d.indicesToOffset("b_indices")};\n    var values: array<${h.type.value}, ${p}>;\n    for (var k: u32 = 0u; k < uniforms.K; k = k + ${c}) {\n      ${(()=>{let e=`var a_data: ${l.type.value};`;for(let t=0;t<c;t++)e+=`\n              let b_data${t} = b[(b_offset + (k + ${t}) * uniforms.N + col) / ${u}];`;for(let t=0;t<p;t++){e+=`a_data = a[(a_offset + (row + ${t}) * uniforms.K + k) / ${c}];`;for(let n=0;n<c;n++)e+=`\n            values[${t}] = fma(${d.type.value}(a_data${1===c?"":`[${n}]`}), b_data${n}, values[${t}]);\n`}return e})()}\n    }\n    for (var i = 0u; i < ${p}u; i++) {\n      var value = values[i];\n      ${b}\n      ${w}\n      let cur_indices = ${h.type.indices}(batch, row + i, col);\n      let offset = ${h.indicesToOffset("cur_indices")};\n      ${h.setByOffset(`offset / ${u}`,"value")};\n    }\n  }\n  `}}},Mi=e=>{if(!e||2!==e.length)throw new Error("MatMul requires 2 inputs.");if(e[0].dims[e[0].dims.length-1]!==e[1].dims[e[1].dims.length-2])throw new Error("shared dimension does not match.")},Ti=e=>{Mi(e.inputs);let t=st.calcShape(e.inputs[0].dims,e.inputs[1].dims,!0);if(!t)throw new Error("Can't use matmul on the given tensors");let n=t[t.length-1],r=e.inputs[0].dims[e.inputs[0].dims.length-1];n<8&&r<8?e.compute(xi(e.inputs,{activation:""},t)):e.compute(_i(e.inputs,{activation:""},t))}})),il=V((()=>{Da(),tl(),el(),nl(),Ya(),rl(),Na(),ki=(e,t,n,r,i,s)=>{let o=e[0],a=e.slice(s?1:2,s?3:4),l=a.length,d=t[0],u=t.slice(2).map(((e,t)=>e+(e-1)*(n[t]-1))),c=a.map(((e,t)=>e+r[t]+r[t+l])).map(((e,t)=>Math.floor((e-u[t]+i[t])/i[t])));return c.splice(0,0,o),c.splice(s?3:1,0,d),c},$i=[2,3,1,0],Si=(e,t)=>{if(!e||2!==e.length&&3!==e.length)throw new Error("Conv requires 2 or 3 inputs");if(4!==e[0].dims.length&&3!==e[0].dims.length)throw new Error("currently only support conv 1D and 2D");if(e[0].dims.length!==e[1].dims.length)throw new Error("filter does not have same dimension as input");if(e[0].dims["NHWC"===t.format?e[0].dims.length-1:1]!==e[1].dims[1]*t.group)throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");if(3===e.length&&(1!==e[2].dims.length||e[1].dims[0]!==e[2].dims[0]))throw new Error("invalid bias");let n=e[0].dims.length-2;if(t.dilations.length!==n)throw new Error(`dilations should be ${n}D`);if(t.strides.length!==n)throw new Error(`strides should be ${n}D`);if(t.pads.length!==2*n)throw new Error(`pads should be ${2*n}D`);if(0!==t.kernelShape.length&&t.kernelShape.length!==e[1].dims.length-2)throw new Error("invalid kernel shape")},Ci=(e,t)=>{let n=e.kernelShape.slice();for(let e=2;e<t[1].dims.length;++e)0===n[e-2]&&(n[e-2]=t[1].dims[e]);let r=e.pads.slice();at.adjustPadsBasedOnAutoPad(t[0].dims,e.strides,e.dilations,n,r,"NHWC"===e.format,e.autoPad);let i=Object.assign({},e);return Object.assign(i,{kernelShape:n,pads:r}),i},Pi=e=>{let t=oi(e),n=e.format;return{autoPad:["NOTSET","VALID","SAME_UPPER","SAME_LOWER"][e.auto_pad],format:n,dilations:e.dilations,group:e.group,kernelShape:e.kernel_shape,pads:e.pads,strides:e.strides,wIsConst:e.w_is_const(),...t,cacheKey:`${e.format};${t.activation};`}},Ei=(e,t,n)=>{let r=Ci(n,t),i="NHWC"===n.format;if(1!==n.group){if(!e.adapterInfo.isArchitecture("ampere")&&i&&t[1].dims[0]===n.group&&1===t[1].dims[1]&&1===n.dilations[0]&&1===n.dilations[1]){let s=ki(t[0].dims,t[1].dims,n.dilations,r.pads,n.strides,i),o=e.kernelCustomData.wT??e.compute(Ft(t[1],$i),{inputs:[1],outputs:[n.wIsConst?-2:-1]})[0];n.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=o);let a=[t[0],o];3===t.length&&a.push(t[2]),e.compute(vi(a,r,s),{inputs:a})}else e.compute(bi(t,r));return}let s=3===t.length,o=t[0].dims[i?1:2],a=t[0].dims[i?2:3],l=t[0].dims[i?3:1],d=t[1].dims[2],u=t[1].dims[3],c=ki(t[0].dims,t[1].dims,n.dilations,r.pads,n.strides,i),p=c[i?1:2],h=c[i?2:3],f=c[i?3:1],m=i&&d===o&&u===a&&0===n.pads[0]&&0===n.pads[1];if(m||1===d&&1===u&&1===n.dilations[0]&&1===n.dilations[1]&&1===n.strides[0]&&1===n.strides[1]&&0===n.pads[0]&&0===n.pads[1]){let d,u,g,_=c[0],w=[];if(i){let r=e.kernelCustomData.wT??e.compute(Ft(t[1],$i),{inputs:[1],outputs:[n.wIsConst?-2:-1]})[0];if(n.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=r),m){let e=o*a*l;d=t[0].reshape([1,_,e]),u=r.reshape([1,e,f]),g=[1,_,f]}else d=t[0].reshape([_,o*a,l]),u=r.reshape([1,l,f]),g=[_,p*h,f];w.push(d),w.push(u)}else d=t[0].reshape([_,l,o*a]),u=t[1].reshape([1,f,l]),g=[_,f,p*h],w.push(u),w.push(d);s&&w.push(t[2]);let y=g[2],b=w[0].dims[w[0].dims.length-1];return void(y<8&&b<8?e.compute(xi(w,r,c,g,i),{inputs:w}):e.compute(_i(w,r,c,g,i),{inputs:w}))}let g=e.kernelCustomData.wT??e.compute(Ft(t[1],$i),{inputs:[1],outputs:[n.wIsConst?-2:-1]})[0];n.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=g);let _=[t[0],g];s&&_.push(t[2]);let w=i?p*h:f,y=i?f:p*h,b=d*u*l;e.compute(yi(_,r,c,w,y,b,s,!0),{inputs:_})},Ai=(e,t)=>{let n="NHWC"===t.format,r=[e.inputs[0].reshape(n?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];3===e.inputs.length&&r.push(e.inputs[2]);let i=[0,t.pads[0],0,t.pads[1]],s=[1].concat(t.strides),o=[1].concat(t.dilations),a=[1].concat(t.kernelShape),l=Ci({...t,pads:i,strides:s,dilations:o,kernelShape:a},r);e.compute(bi(r,l,(e=>n?[e[0],e[2],e[3]]:[])))},Fi=(e,t)=>{Si(e.inputs,t),3===e.inputs[0].dims.length?Ai(e,t):Ei(e,e.inputs,t)}})),sl=V((()=>{Aa(),Ia(),Ra(),Ya(),Za(),Ja(),el(),Ii=(e,t=!1,n,r,i=4)=>{let s=e?"\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ":"\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    ",o=e?"row":"col",a=e?"col":"row",l=`\n      let inChannels = ${e?"i32(uniforms.x_shape[3])":"i32(uniforms.x_shape[1])"};\n      let outWidth = ${e?"i32(uniforms.result_shape[2])":"i32(uniforms.result_shape[3])"};\n      let outRow = ${o} / outWidth;\n      let outCol = ${o} % outWidth;\n\n      let WRow = ${a} / (uniforms.filter_dims[1] * inChannels);\n      let WCol = ${a} / inChannels % uniforms.filter_dims[1];\n      let xR = f32(outRow - uniforms.pads[0] + uniforms.dilations[0] * WRow) / f32(uniforms.strides[0]);\n      let xC = f32(outCol - uniforms.pads[1] + uniforms.dilations[1] * WCol) / f32(uniforms.strides[1]);\n      if (xR < 0.0 || xR >= f32(${e?"i32(uniforms.x_shape[1])":"i32(uniforms.x_shape[2])"}) || fract(xR) > 0.0) {\n        return ${r}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${e?"i32(uniforms.x_shape[2])":"i32(uniforms.x_shape[3])"}) || fract(xC) > 0.0) {\n        return ${r}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${a} % inChannels;\n      ${e?"\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      ":"\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      "}\n      return x[getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape))/${i}];`,d=e?`\n      let col = colIn * ${i};\n      if (row < uniforms.dim_a_outer && col < uniforms.dim_inner) {\n        ${l}\n      }\n      return ${r}(0.0);`:`\n      let col = colIn * ${i};\n      if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {\n        ${l}\n      }\n      return ${r}(0.0);`,u=`\n      let col = colIn * ${i};\n      let inChannels = ${e?"i32(uniforms.x_shape[3])":"i32(uniforms.x_shape[1])"};\n      let coordX = uniforms.filter_dims[0] - 1 - row / (uniforms.filter_dims[1] * inChannels);\n      let coordY = uniforms.filter_dims[1] - 1 - (row / inChannels) % uniforms.filter_dims[1];\n      if (${e?"row < uniforms.dim_inner && col < uniforms.dim_b_outer":"row < uniforms.dim_inner && col < uniforms.dim_a_outer"}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${(e=>{switch(e){case 1:return"return w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];";case 4:return`\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];\n            let v1 = w[getIndexFromCoords4D(coord1, vec4<i32>(uniforms.w_shape))];\n            let v2 = w[getIndexFromCoords4D(coord2, vec4<i32>(uniforms.w_shape))];\n            let v3 = w[getIndexFromCoords4D(coord3, vec4<i32>(uniforms.w_shape))];\n            return ${r}(v0, v1, v2, v3);\n            `;default:throw new Error(`innerElementSize ${e} is not supported.`)}})(i)}\n      }\n      return ${r}(0.0);\n      `,c=ri(n,r);return`\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${r} {\n    ${e?d:u}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${r} {\n    ${e?u:d}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${r}) {\n    let col = colIn * ${i};\n    if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer) {\n      var value = valueInput;\n      let outWidth = ${e?"i32(uniforms.result_shape[2])":"i32(uniforms.result_shape[3])"};\n      ${s}\n      ${li(t)}\n      ${c}\n      result[getIndexFromCoords4D(coords, vec4<i32>(uniforms.result_shape))/${i}] = value;\n    }\n  }`},zi=(e,t,n,r,i,s,o,a)=>{let l="NHWC"===t.format,d=l?e[0].dims[3]:e[0].dims[1],u=n[0],c=l?n[2]:n[3],p=l?n[1]:n[2],h=l?n[3]:n[1],f=l&&d%4==0&&d%3&&h%4==0,m=l?h:c*p,g=l?c*p:h,_=[8,8,1],w=r<=8?[4,1,1]:[4,4,1],y=[Math.ceil(m/_[0]/w[0]),Math.ceil(g/_[1]/w[1]),Math.ceil(u/_[2]/w[2])];Xe("verbose",(()=>`[conv_backprop_mm_webgpu] dispatch = ${y}`));let b=f?4:1,v=Math.max(_[0]*b,_[1]),x=f?4:1,M=[t.kernelShape[l?1:2],t.kernelShape[l?2:3]],T=[M[0]+(t.dilations[0]<=1?0:(M[0]-1)*(t.dilations[0]-1)),M[1]+(t.dilations[1]<=1?0:(M[1]-1)*(t.dilations[1]-1))],k=[T[0]-1-Math.floor((t.pads[0]+t.pads[2])/2),T[1]-1-Math.floor((t.pads[1]+t.pads[3])/2)],$=[{type:6,data:r},{type:6,data:i},{type:6,data:s},{type:6,data:t.strides},{type:6,data:t.dilations},{type:6,data:M},{type:6,data:k}];ii(t,$),$.push(...mt(e[0].dims,e[1].dims));let S=["rank","rank"];o&&($.push(...mt(e[2].dims)),S.push("rank")),$.push(...mt(n));return{name:"Conv2DTransposeMatMul",shaderCache:{hint:`${t.cacheKey};${w};${_};${f}`,inputDependencies:S},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:y[0],y:y[1],z:y[2]},programUniforms:$}),getShaderSource:r=>{let i=xt("x",e[0].dataType,e[0].dims.length,x),s=xt("w",e[1].dataType,e[1].dims.length,1),d=Mt("result",e[0].dataType,n.length,x),u=[i,s],c="";if(o){let t=xt("bias",e[2].dataType,e[2].dims.length,x);u.push(t),c+=`\n          fn getBiasByOutputCoords(coords : vec4<i32>) -> ${t.type.value} {\n            return bias[coords.${l?"w":"y"}${f?"/ 4":""}];\n          }`}let p=[{name:"dim_a_outer",type:"i32"},{name:"dim_b_outer",type:"i32"},{name:"dim_inner",type:"i32"},{name:"strides",type:"i32",length:2},{name:"dilations",type:"i32",length:2},{name:"filter_dims",type:"i32",length:M.length},{name:"pads",type:"i32",length:k.length}];si(t,p);let h=ht(e[0].dataType,1);if("f16"!==h&&"f32"!==h)throw new Error(`elemType ${h} is not supported.`);return`\n        ${di("uniforms.result_strides")}\n        ${r.registerUniforms(p).declareVariables(...u,d)};\n        ${c}\n        ${Ii(l,o,t,i.type.value,b)}\n        ${f?pi(w,_,h,void 0,!l,v):mi(w,_,h,void 0,!l,v,!1,void 0,a)}`}}}})),ol=V((()=>{Aa(),Ia(),Da(),Ra(),Bi=(e,t,n,r,i,s=!1,o,a,l=!1)=>{let d=l?1:2,u=l?2:3,c=l?3:1,p=s?2:1,h=`\n  fn setOutputAtIndex(flatIndex : u32, value : ${s?`vec4<${o}>`:o}) {\n    result[flatIndex] = ${s?`vec4<${o}>`:o}(value);\n  }`;r&&(h+=`\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${s?`vec4<${o}>`:o} {\n      return bias[coords.${l?"w":"y"}${s?"/ 4":""}];\n    }`);let f=s?4:1,m=xt("W",t[1].dataType,t[1].dims.length,f),g=xt("Dy",t[0].dataType,t[0].dims.length,f),_=[g,m];r&&_.push(xt("bias",t[2].dataType,[n[c]].length,f));let w=Mt("result",t[0].dataType,n.length,f),y=`{\n        let batch: u32 = ${i?"global_id.z":"workgroup_id.z"} / uniforms.result_shape[1];\n        let r = ${i?"global_id.z":"workgroup_id.z"} % uniforms.result_shape[1];\n        let c = ${i?"global_id.y":"workgroup_id.y"} * ${p};\n        let d1: u32 = ${i?"global_id.x":"workgroup_id.x"} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(uniforms.pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${o}>, ${p}>;\n        for (var i = 0; i < ${p}; i++) {\n          dotProd[i] = vec4<${o}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < uniforms.filter_dims[0]; wR = wR + 1) {\n          var dyR = (${o}(dyCorner.x) + ${o}(wR)) / ${o}(uniforms.strides.x);\n          let wRPerm = uniforms.filter_dims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${o}(uniforms.Dy_shape[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < uniforms.filter_dims[1]; wC = wC + 1) {\n            let dyC = (${o}(dyCorner.y) + ${o}(wC)) / ${o}(uniforms.strides.y);\n            let dyC2 = (${o}(dyCorner.y) + 1.0 + ${o}(wC)) / ${o}(uniforms.strides.y);\n            let wCPerm = uniforms.filter_dims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${o}(uniforms.Dy_shape[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${o}(uniforms.Dy_shape[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = uniforms.Dy_shape[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1","d2")};\n                let wValue1 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1 + 1","d2")};\n                let wValue2 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1 + 2","d2")};\n                let wValue3 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1 + 3","d2")};\n\n                var xValue = ${g.get("batch","idyR","idyC","d2")};\n                let tmpval = vec4<${o}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${g.get("batch","idyR","idyC2","d2")};\n\n                dotProd[1] = dotProd[1] + vec4<${o}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = uniforms.Dy_shape[${c}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1","d2")};\n                let wValue1 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1 + 1","d2")};\n                let wValue2 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1 + 2","d2")};\n                let wValue3 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1 + 3","d2")};\n\n                var xValue = ${g.get("batch","idyR","idyC","d2")};\n                let tmpval = vec4<${o}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = uniforms.Dy_shape[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1","d2")};\n                let wValue1 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1 + 1","d2")};\n                let wValue2 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1 + 2","d2")};\n                let wValue3 = ${m.get("u32(wRPerm)","u32(wCPerm)","d1 + 3","d2")};\n\n                var xValue = ${g.get("batch","idyR","idyC2","d2")};\n                let tmpval = vec4<${o}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${p}; i = i + 1) {\n          let value = dotProd[i] + ${r?"bias[c+i]":`vec4<${o}>(0.0)`};\n          ${w.set("batch","r","c + i","d1","value")};\n        }\n      }`,b=`\n          let outputIndices = ${w.offsetToIndices("global_idx")};\n          let batch = ${w.indicesGet("outputIndices",0)};\n          let d1 = ${w.indicesGet("outputIndices",c)};\n          let r = ${w.indicesGet("outputIndices",d)};\n          let c = ${w.indicesGet("outputIndices",u)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - uniforms.pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / uniforms.output_channels_per_group;\n          let wOutChannel = d1 - groupId * uniforms.output_channels_per_group;\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = ${o}(0.0);\n          for (var wR: u32 = 0; wR < uniforms.effective_filter_dims.x; wR = wR + 1) {\n            if (wR % uniforms.dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${o}(dyRCorner) + ${o}(wR)) / ${o}(uniforms.strides[0]);\n            let wRPerm = uniforms.filter_dims.x - 1 - wR / uniforms.dilations.x;\n            if (dyR < 0.0 || dyR >= ${o}(uniforms.Dy_shape[${d}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < uniforms.effective_filter_dims.y; wC = wC + 1) {\n              if (wC % uniforms.dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${o}(dyCCorner) + ${o}(wC)) / ${o}(uniforms.strides.y);\n              let wCPerm = uniforms.filter_dims.y - 1 - wC / uniforms.dilations.y;\n              if (dyC < 0.0 || dyC >= ${o}(uniforms.Dy_shape[${u}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * uniforms.input_channels_per_group;\n              for (var d2: u32 = 0; d2 < uniforms.input_channels_per_group; d2 = d2 + 1) {\n                let xValue = ${l?g.get("batch","idyR","idyC","inputChannel"):g.get("batch","inputChannel","idyR","idyC")};\n                let wValue = ${m.get("inputChannel","wOutChannel","u32(wRPerm)","u32(wCPerm)")};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${r?"bias[d1]":`${o}(0.0)`};\n          ${w.setByOffset("global_idx","value")};\n        `;return`\n  ${e.registerUniforms(a).declareVariables(..._,w)}\n  ${h}\n\n    ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")};\n  ${s?y:b}}`},Oi=(e,t,n)=>{let r=e.length>2,i=t.outputShape,s=ot.size(i),o=[Math.ceil(s/64),1,1];Xe("verbose",(()=>`[conv2d_backprop_webgpu] dispatch = ${o}`));let a="NHWC"===t.format,l=["rank","rank"],d=[t.strides[0],t.strides[1]],u=[t.kernelShape[a?1:2],t.kernelShape[a?2:3]],c=[t.dilations[0],t.dilations[1]],p=[u[0]+(t.dilations[0]<=1?0:(t.kernelShape[a?1:2]-1)*(t.dilations[0]-1)),u[1]+(t.dilations[1]<=1?0:(t.kernelShape[a?2:3]-1)*(t.dilations[1]-1))],h=[p[0]-1-Math.floor((t.pads[0]+t.pads[2])/2),p[1]-1-Math.floor(t.pads[1]+t.pads[3])/2],f=t.group,m=e[1].dims,g=m[0]/f,_=m[1],w=[{type:12,data:s},{type:12,data:d},{type:12,data:u},{type:12,data:c},{type:12,data:p},{type:6,data:h},{type:12,data:g},{type:12,data:_},...mt(e[0].dims,e[1].dims)];r&&(w.push(...mt(e[2].dims)),l.push("rank")),w.push(...mt(i));let y=1===o[1]&&1===o[2];return{name:"ConvTranspose2D",shaderCache:{hint:`${t.cacheKey};`,inputDependencies:l},getRunData:()=>({dispatchGroup:{x:o[0],y:o[1],z:o[2]},outputs:[{dims:n?n(i):i,dataType:e[0].dataType}],programUniforms:w}),getShaderSource:t=>{let n=[{name:"output_size",type:"u32"},{name:"strides",type:"u32",length:d.length},{name:"filter_dims",type:"u32",length:u.length},{name:"dilations",type:"u32",length:u.length},{name:"effective_filter_dims",type:"u32",length:p.length},{name:"pads",type:"i32",length:h.length},{name:"input_channels_per_group",type:"u32"},{name:"output_channels_per_group",type:"u32"}],s=ht(e[0].dataType);return`${Bi(t,e,i,r,y,false,s,n,a)}`}}}})),al=V((()=>{sl(),ol(),Ya(),Na(),Li=(e,t,n,r,i,s)=>(e-1)*t+n+(r-1)*i+1-s,Di=(e,t,n,r,i)=>{let s=Math.floor(e/2);"SAME_UPPER"===t?(n[r]=s,n[i]=e-s):"SAME_LOWER"===t&&(n[r]=e-s,n[i]=s)},Ri=(e,t,n,r,i,s,o,a,l,d)=>{let u=e.length-2,c=0===d.length;if(0===l.length)for(let e=0;e<u;++e)l.push(0);let p=e[0],h=t[a?3:1]*i;for(let i=0,p=e.length-u-(a?1:0);i<u;++i,++p){let a=e[p],h=c?a*o[i]:d[i],f=Li(a,o[i],s[i],t[p],n[i],h);Di(f,r,s,i,i+u),c&&d.push(o[i]*(a-1)+l[i]+(t[p]-1)*n[i]+1-s[i]-s[i+u])}d.splice(0,0,p),d.splice(a?3:1,0,h)},Ni=(e,t)=>{let n=e.kernelShape.slice();if(0===e.kernelShape.length||0===e.kernelShape.reduce(((e,t)=>e*t),1)){n.length=0;for(let e=2;e<t[1].dims.length;++e)n.push(t[1].dims[e])}let r="NHWC"===e.format;n.splice(0,0,t[1].dims[0]),n.splice(r?3:1,0,t[1].dims[1]);let i=e.pads.slice(),s=e.outputShape.slice(),o=e.outputPadding.slice(),a=t[0].dims,l=e.dilations.slice();if(0===l.reduce(((e,t)=>e+t),0)){let e=t[0].dims.length-2;l=new Array(e).fill(1)}let d=e.strides.slice();if(0===d.reduce(((e,t)=>e+t),0)){let e=t[0].dims.length-2;d=new Array(e).fill(1)}Ri(a,n,l,e.autoPad,e.group,i,d,r,o,s);let u=Object.assign({},e);return Object.assign(u,{kernelShape:n,pads:i,outputPadding:o,outputShape:s,dilations:l,strides:d}),u},Vi=e=>{let t=oi(e),n=e.format,r=["NOTSET","VALID","SAME_UPPER","SAME_LOWER"][typeof e.autoPad>"u"?0:e.autoPad],i=e.dilations,s=e.group,o=e.kernelShape,a=e.pads,l=e.strides,d=e.wIsConst();return{autoPad:r,format:n,dilations:i,group:s,kernelShape:o,outputPadding:e.outputPadding,outputShape:e.outputShape,pads:a,strides:l,wIsConst:d,...t,cacheKey:`${e.format};${t.activation};`}},ji=(e,t)=>{if(!e||2!==e.length&&3!==e.length)throw new Error("Conv requires 2 or 3 inputs");if(4!==e[0].dims.length&&3!==e[0].dims.length)throw new Error("currently only support 2-dimensional conv");if(e[0].dims.length!==e[1].dims.length)throw new Error("filter does not have same dimension as input");if(e[0].dims["NHWC"===t.format?e[0].dims.length-1:1]!==e[1].dims[0])throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");let n=e[1].dims[1]*t.group;if(3===e.length&&(1!==e[2].dims.length||e[2].dims[0]!==n))throw new Error("invalid bias");let r=e[0].dims.length-2;if(t.dilations.reduce(((e,t)=>e+t),0)>0&&t.dilations.length!==r)throw new Error(`dilations should be ${r}D`);if(t.strides.reduce(((e,t)=>e+t),0)>0&&t.strides.length!==r)throw new Error(`strides should be ${r}D`);if(t.pads.reduce(((e,t)=>e+t),0)>0&&t.pads.length!==2*r)throw new Error(`pads should be ${2*r}D`);if(t.outputPadding.length!==r&&0!==t.outputPadding.length)throw new Error(`output_padding should be ${r}D`);if(t.kernelShape.reduce(((e,t)=>e+t),0)>0&&0!==t.kernelShape.length&&t.kernelShape.length!==e[1].dims.length-2)throw new Error("invalid kernel shape");if(0!==t.outputShape.length&&t.outputShape.length!==e[0].dims.length-2)throw new Error("invalid output shape")},Ui=[2,3,1,0],Gi=(e,t,n)=>{let r=Ni(n,t),i="NHWC"===n.format,s=r.outputShape,o=s[i?3:1],a=t[0].dims[i?3:1];if(1!==r.group||1===o&&1===a)return void e.compute(Oi(t,r));let l=s[i?1:2],d=s[i?2:3],u=i?l*d:o,c=i?o:l*d,p=t[1].dims[2]*t[1].dims[3]*a,h=e.kernelCustomData.wT??e.compute(Ft(t[1],Ui),{inputs:[1],outputs:[n.wIsConst?-2:-1]})[0];n.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=h);let f=[t[0],h],m=3===t.length;m&&(i||1!==t[2].dims.length?f.push(t[2]):f.push(t[2].reshape([t[2].dims[0],1,1]))),e.compute(zi(f,r,s,u,c,p,m,!0),{inputs:f})},qi=(e,t)=>{let n="NHWC"===t.format,r=[e.inputs[0].reshape(n?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];3===e.inputs.length&&r.push(e.inputs[2]);let i=t.kernelShape;(0===i.length||0===i[0])&&(i=[e.inputs[1].dims[2]]);let s=t.dilations;(0===s.length||0===s[0])&&(s=[1]);let o=t.strides;(0===o.length||0===o[0])&&(o=[1]);let a=t.pads;0===a.length&&(a=[0,0]),a=[0,a[0],0,a[1]],o=[1].concat(o),s=[1].concat(s),i=[1].concat(i);let l=Ni({...t,pads:a,strides:o,dilations:s,kernelShape:i},r);e.compute(Oi(r,l,(e=>n?[e[0],e[2],e[3]]:[e[0],e[1],e[3]])))},Wi=(e,t)=>{ji(e.inputs,t),3===e.inputs[0].dims.length?qi(e,t):Gi(e,e.inputs,t)}})),ll=V((()=>{Aa(),Da(),La(),Ra(),Hi=(e,t,n,r)=>{let i=ot.size(t),s=t.length,o=xt("input",e,s),a=Mt("output",e,s),l=6===n.dataType?n.getInt32Array()[0]:Number(n.getBigInt64Array()[0]),d=ot.normalizeAxis(l,s);return{name:"CumSum",shaderCache:{hint:r.cacheKey,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:t,dataType:e}],dispatchGroup:{x:Math.ceil(i/64)},programUniforms:[{type:12,data:i},{type:6,data:d},...mt(t,t)]}),getShaderSource:e=>{let t=` i32(${o.indicesGet("inputIndices","uniforms.axis")}) `,n=bt("uniforms.input_shape","uniforms.axis",s),i=r.reverse?t+(r.exclusive?" + 1":""):"0",l=r.reverse?n:t+(r.exclusive?"":" + 1");return`\n                ${e.registerUniform("outputSize","u32").registerUniform("axis","u32").declareVariables(o,a)}\n                ${e.mainStart()}\n                  ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n                  var inputIndices = ${a.offsetToIndices("global_idx")};\n                  var sum = ${a.type.value}(0);\n                  let first : i32 = ${i};\n                  let last : i32 = ${l};\n                  for (var i : i32 = first; i < last; i++) {\n                    ${o.indicesSet("inputIndices","uniforms.axis","u32(i)")};\n                    sum = sum + ${o.getByIndices("inputIndices")};\n                  }\n                  ${a.setByOffset("global_idx","sum")};\n                }`}}},Xi=(e,t)=>{let n=e.inputs[0].dims,r=e.inputs[0].dataType,i=e.inputs[1];e.compute(Hi(r,n,i,t),{inputs:[0]})},Qi=e=>{let t=1===e.exclusive,n=1===e.reverse;return rt({exclusive:t,reverse:n})}})),dl=V((()=>{Aa(),Da(),La(),Ra(),Zi="^"+(Yi="("+(Ki="[a-zA-Z]|\\.\\.\\.")+")+")+"$",Ji="^"+("("+Yi+",)*"+Yi)+"$",es=class{constructor(e=-1){this.symbolToIndices=new Map,this.inputIndex=e}addSymbol(e,t){let n=this.symbolToIndices.get(e);void 0===n?n=[t]:n.push(t),this.symbolToIndices.set(e,n)}},ts=class{constructor(e,t){this.equation=t,this.hasEllipsis=!1,this.symbolToInfo=new Map,this.lhs=new Array,this.outputDims=[];let[n,r]=t.includes("->")?t.split("->",2):[t,""];if(!n.match(RegExp(Ji)))throw new Error("Invalid LHS term");if(n.split(",").forEach(((t,n)=>{let r=e[n].dims.slice();if(!t.match(RegExp(Zi)))throw new Error("Invalid LHS term");let i=this.processTerm(t,!0,r,n);this.lhs.push(i)})),""===r)r+=[...this.symbolToInfo.entries()].filter((([e,t])=>1===t.count||"..."===e)).map((([e])=>e)).join("");else if(!r.match(RegExp(Yi)))throw new Error("Invalid RHS");r.match(RegExp(Ki,"g"))?.forEach((e=>{if("..."===e)this.outputDims=this.outputDims.concat(this.ellipsisDims);else{let t=this.symbolToInfo.get(e);if(void 0===t)throw new Error("Invalid RHS symbol");this.outputDims.push(t.dimValue)}})),this.rhs=this.processTerm(r,!1,this.outputDims)}addSymbol(e,t,n){let r=this.symbolToInfo.get(e);if(void 0!==r){if(r.dimValue!==t&&1!==r.count)throw new Error("Dimension mismatch");r.count++,r.inputIndices.push(n)}else r={count:1,dimValue:t,inputIndices:[n]};this.symbolToInfo.set(e,r)}processTerm(e,t,n,r=-1){let i=n.length,s=!1,o=[],a=0;if(!e.match(RegExp(Zi))&&!t&&""!==e)throw new Error("Invalid LHS term");let l=e.match(RegExp(Ki,"g")),d=new es(r);return l?.forEach(((e,u)=>{if("..."===e){if(s)throw new Error("Only one ellipsis is allowed per input term");s=!0;let e=i-l.length+1;if(e<0)throw new Error("Ellipsis out of bounds");if(o=n.slice(a,a+e),this.hasEllipsis){if(this.ellipsisDims.length!==o.length||this.ellipsisDims.toString()!==o.toString())throw new Error("Ellipsis dimensions mismatch")}else{if(!t)throw new Error("Ellipsis must be specified in the LHS");this.hasEllipsis=!0,this.ellipsisDims=o}for(let e=0;e<o.length;e++){let t=String.fromCharCode("0".charCodeAt(0)+e);d.addSymbol(t,u+e),this.addSymbol(t,n[a++],r)}}else d.addSymbol(e,u+(this.hasEllipsis?this.ellipsisDims.length-1:0)),this.addSymbol(e,n[a++],r)})),d}},ns=e=>e+"_max",rs=(e,t,n,r)=>{let i=e.map((e=>e.length)).map(((e,n)=>xt(`input${n}`,t,e))),s=ot.size(r),o=Mt("output",t,r.length),a=[...n.symbolToInfo.keys()].filter((e=>!n.rhs.symbolToIndices.has(e)));return{name:"Einsum",shaderCache:{hint:n.equation,inputDependencies:e.map((()=>"rank"))},getRunData:()=>{let i=a.filter((e=>n.symbolToInfo.has(e))).map((e=>({type:12,data:n.symbolToInfo.get(e)?.dimValue||0})));i.push({type:12,data:s});let o=e.map(((e,t)=>[...mt(e)])).reduce(((e,t)=>e.concat(t)),i);return o.push(...mt(r)),{outputs:[{dims:r,dataType:t}],dispatchGroup:{x:Math.ceil(s/64)},programUniforms:o}},getShaderSource:e=>{let t=[],r=[],s=[],l=[],d=[],u=n.symbolToInfo.size===n.rhs.symbolToIndices.size;n.symbolToInfo.forEach(((e,a)=>{if(n.rhs.symbolToIndices.has(a)){let r=n.rhs.symbolToIndices.get(a)?.[0];void 0!==r&&n.lhs.forEach(((n,s)=>{if(e.inputIndices.includes(s)){let e=n.symbolToIndices.get(a);if(void 0===e)throw new Error("Invalid symbol error");e.forEach((e=>{t.push(`${i[s].indicesSet(`input${s}Indices`,e,o.indicesGet("outputIndices",r))}`)}))}}))}else n.lhs.forEach(((t,n)=>{if(e.inputIndices.includes(n)){let e=t.symbolToIndices.get(a);if(void 0===e)throw new Error("Invalid symbol error");e.forEach((e=>{r.push(`${i[n].indicesSet(`input${n}Indices`,e,`${a}`)}`)})),d.push(`prod *= ${i[n].getByIndices(`input${n}Indices`)};`)}})),s.push(`for(var ${a}: u32 = 0; ${a} < uniforms.${ns(a)}; ${a}++) {`),l.push("}")}));let c=u?[...t,`let sum = ${i.map(((e,t)=>e.getByIndices(`input${t}Indices`))).join(" * ")};`]:[...t,"var sum = 0.0;",...s,...r,"var prod = 1.0;",...d,"sum += prod;",...l];return`\n            ${e.registerUniforms(a.map((e=>({name:`${ns(e)}`,type:"u32"})))).registerUniform("outputSize","u32").declareVariables(...i,o)}\n\n            ${e.mainStart()}\n            ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n            var outputIndices = ${o.offsetToIndices("global_idx")};\n            ${i.map(((e,t)=>`var input${t}Indices: ${i[t].type.indices};`)).join("\n")}\n            ${c.join("\n")};\n            ${o.setByOffset("global_idx","sum")};\n          }`}}},is=(e,t)=>{let n=new ts(e.inputs,t.equation),r=n.outputDims,i=e.inputs.map(((e,t)=>e.dims));e.compute(rs(i,e.inputs[0].dataType,n,r))},ss=e=>{let t=e.equation.replace(/\s+/g,"");return rt({equation:t})}})),ul=V((()=>{Aa(),Da(),Ra(),os=e=>{if(!e||2!==e.length)throw new Error("Expand requires 2 input.");let t=e[0].dims,n=Array.from(e[1].getBigInt64Array(),Number),r=n.length<t.length?0:n.length-t.length,i=t.length<n.length?0:t.length-n.length;for(;r<n.length&&i<t.length;++r,++i)if(n[r]!==t[i]&&1!==n[r]&&1!==t[i])throw new Error("Expand requires shape to be broadcastable to input")},as=(e,t)=>{let n=e.length-t.length,r=[];for(let t=0;t<n;++t)r.push(e[t]);for(let i=0;i<t.length;++i)r.push(1===t[i]?e[i+n]:t[i]);return r},ls=(e,t)=>e.length>t.length?as(e,t):as(t,e),ds=e=>{let t=e[0].dims,n=Array.from(e[1].getBigInt64Array(),Number),r=ls(t,n),i=e[0].dataType,s=9===i?4:1,o=Math.ceil(ot.size(r)/s),a=[{type:12,data:o},...mt(t,r)];return{name:"Expand",shaderCache:{hint:`${r.length}`,inputDependencies:["rank"]},getShaderSource:e=>{let n,o=xt("input",i,t.length,s),a=Mt("output",i,r.length,s);if(9===i){let e=(e,t,n="")=>`\n          let outputIndices${t} = ${a.offsetToIndices(`outputOffset + ${t}u`)};\n          let offset${t} = ${o.broadcastedIndicesToOffset(`outputIndices${t}`,a)};\n          let index${t} = offset${t} / 4u;\n          let component${t} = offset${t} % 4u;\n          ${e}[${t}] = ${n}(${o.getByOffset(`index${t}`)}[component${t}]);\n        `;n=`\n        let outputOffset = global_idx * ${s};\n        var data = vec4<u32>(0);\n        ${e("data",0,"u32")}\n        ${e("data",1,"u32")}\n        ${e("data",2,"u32")}\n        ${e("data",3,"u32")}\n        ${a.setByOffset("global_idx","data")}\n      }`}else n=`\n        let outputIndices = ${a.offsetToIndices("global_idx")};\n        let inputOffset = ${o.broadcastedIndicesToOffset("outputIndices",a)};\n        ${a.setByOffset("global_idx",o.getByOffset("inputOffset"))}\n      }`;return`\n    ${e.registerUniform("vec_size","u32").declareVariables(o,a)}\n    ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}\n    ${n}`},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(o/64)},programUniforms:a})}},us=e=>{os(e.inputs),e.compute(ds(e.inputs),{inputs:[0]})}})),cl=V((()=>{Aa(),Da(),Ra(),Ha(),cs=e=>{let t=e[0].dataType,n=ot.size(e[0].dims),r=ot.size(e[1].dims),i=r%4==0;return{name:"FastGeluWithBias",shaderCache:{hint:`${i}`,inputDependencies:["type","type"]},getShaderSource:e=>{let n=xt("x",t,[1],4),r=xt("bias",t,[1],4),s=Mt("y",t,[1],4),o=e=>`\n      let bias${e}_offset: u32 = (global_idx * 4 + ${e}) % uniforms.bias_size;\n      let bias${e} = ${r.getByOffset(`bias${e}_offset / 4`)}[bias${e}_offset % 4];`,a=i?`\n      let bias = ${r.getByOffset("global_idx % (uniforms.bias_size / 4)")};`:`${o(0)}${o(1)}${o(2)}${o(3)}\n      let bias = ${n.type.value}(bias0, bias1, bias2, bias3);`;return`${e.registerUniforms([{name:"output_vec_size",type:"u32"},{name:"bias_size",type:"u32"}]).declareVariables(n,r,s)}\n\n    ${Er(ft(t))}\n\n    ${e.mainStart(ct)}\n      ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_vec_size")}\n\n      let x = ${n.getByOffset("global_idx")};\n      ${a}\n      let x_in = x + bias;\n      ${s.setByOffset("global_idx",Ar("x_in"))}\n    }`},getRunData:e=>({outputs:[{dims:e[0].dims,dataType:e[0].dataType}],programUniforms:[{type:12,data:Math.ceil(n/4)},{type:12,data:r}],dispatchGroup:{x:Math.ceil(n/ct/4)}})}},ps=e=>{e.inputs.length<2||0===ot.size(e.inputs[1].dims)?Fr(e):e.compute(cs(e.inputs))}})),pl=V((()=>{Aa(),Da(),La(),Ra(),hs=e=>{if(!e||2!==e.length)throw new Error("Gather requires 2 inputs.")},fs=(e,t)=>{let n=e[0].dims,r=e[1].dims,i=n.length,s=ot.normalizeAxis(t.axis,i),o=n.slice(0);o.splice(s,1,...r);let a=n[s],l=9===e[0].dataType?4:1,d=Math.ceil(ot.size(o)/l),u=[{type:12,data:d},{type:6,data:a},{type:12,data:s},...mt(e[0].dims,e[1].dims,o)];return{name:"Gather",shaderCache:{hint:t.cacheKey,inputDependencies:["rank","rank"]},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(d/64)},programUniforms:u}),getShaderSource:t=>{let n,a=xt("data",e[0].dataType,e[0].dims.length,l),d=xt("inputIndices",e[1].dataType,e[1].dims.length),u=Mt("output",e[0].dataType,o.length,l),c=e=>{let t=r.length,n=`var indicesIndices${e}  = ${d.type.indices}(0);`;for(let r=0;r<t;r++)n+=`${t>1?`indicesIndices${e}[${r}]`:`indicesIndices${e}`} = ${o.length>1?`outputIndices${e}[uniforms.axis + ${r}]`:`outputIndices${e}`};`;n+=`\n          var idx${e} = ${d.getByIndices(`indicesIndices${e}`)};\n          if (idx${e} < 0) {\n            idx${e} = idx${e} + uniforms.axisDimLimit;\n          }\n          var dataIndices${e} : ${a.type.indices};\n        `;for(let r=0,a=0;r<i;r++)r===s?(n+=`${i>1?`dataIndices${e}[${r}]`:`dataIndices${e}`} = u32(idx${e});`,a+=t):(n+=`${i>1?`dataIndices${e}[${r}]`:`dataIndices${e}`} = ${o.length>1?`outputIndices${e}[${a}]`:`outputIndices${e}`};`,a++);return n};if(9===e[0].dataType){let e=(e,t,n="")=>`\n          let outputIndices${t} = ${u.offsetToIndices(`outputOffset + ${t}u`)};\n          ${c(t)};\n          let offset${t} = ${a.indicesToOffset(`dataIndices${t}`)};\n          let index${t} = offset${t} / 4u;\n          let component${t} = offset${t} % 4u;\n          ${e}[${t}] = ${n}(${a.getByOffset(`index${t}`)}[component${t}]);\n        `;n=`\n        let outputOffset = global_idx * ${l};\n        var value = vec4<u32>(0);\n        ${e("value",0,"u32")}\n        ${e("value",1,"u32")}\n        ${e("value",2,"u32")}\n        ${e("value",3,"u32")}\n        ${u.setByOffset("global_idx","value")}\n      `}else n=`\n      let outputIndices = ${u.offsetToIndices("global_idx")};\n      ${c("")};\n      let value = ${a.getByIndices("dataIndices")};\n      ${u.setByOffset("global_idx","value")};\n      `;return`\n      ${t.registerUniform("outputSize","u32").registerUniform("axisDimLimit","i32").registerUniform("axis","u32").declareVariables(a,d,u)}\n      ${t.mainStart()}\n        ${t.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n        ${n}\n      }`}}},ms=e=>rt({axis:e.axis}),gs=(e,t)=>{let n=e.inputs;hs(n),e.compute(fs(e.inputs,t))}})),hl=V((()=>{Aa(),Da(),La(),Ra(),_s=e=>{if(!e||2!==e.length)throw new Error("GatherElements requires 2 inputs.");if(e[0].dims.length<1)throw new Error("GatherElements requires that the data input be rank >= 1.");if(e[0].dims.length!==e[1].dims.length)throw new Error("GatherElements requires that the data input and\n                     indices input tensors be of same rank.")},ws=(e,t)=>{let n=e[0].dims,r=e[0].dataType,i=n.length,s=e[1].dims,o=e[1].dataType,a=ot.normalizeAxis(t.axis,i),l=n[a],d=s.slice(0),u=ot.size(d),c=xt("input",r,i),p=xt("indicesInput",o,s.length),h=Mt("output",r,d.length),f=[{type:12,data:u},{type:6,data:l},{type:12,data:a}];return f.push(...mt(n,s,d)),{name:"GatherElements",shaderCache:{inputDependencies:["rank","rank"]},getRunData:()=>({outputs:[{dims:d,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:f}),getShaderSource:e=>`\n      ${e.registerUniform("outputSize","u32").registerUniform("axisDimLimit","i32").registerUniform("axis","u32").declareVariables(c,p,h)}\n      ${e.mainStart()}\n      ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n\n      let outputIndices = ${h.offsetToIndices("global_idx")};\n\n      var idx = ${p.getByOffset("global_idx")};\n      if (idx < 0) {\n        idx = idx + uniforms.axisDimLimit;\n      }\n      var inputIndices = ${c.type.indices}(outputIndices);\n      ${c.indicesSet("inputIndices","uniforms.axis","u32(idx)")};\n      let value = ${c.getByIndices("inputIndices")};\n\n      ${h.setByOffset("global_idx","value")};\n  }`}},ys=e=>rt({axis:e.axis}),bs=(e,t)=>{let n=e.inputs;_s(n),e.compute(ws(e.inputs,t))}})),fl=V((()=>{Aa(),Da(),Ra(),vs=e=>{if(!e)throw new Error("Input is missing");if(e.length<2||e.length>3)throw new Error("Invaid input number.");if(3===e.length&&e[2].dims.length>2)throw new Error("Invalid input shape of C");if(e[0].dataType!==e[1].dataType||3===e.length&&e[0].dataType!==e[2].dataType)throw new Error("Input types are mismatched")},xs=(e,t)=>{let n=e[0].dims.slice(),r=e[1].dims.slice(),[i,s,o]=lt.getShapeOfGemmResult(n,t.transA,r,t.transB,3===e.length?e[2].dims:void 0),a=[i,s];if(!a)throw new Error("Can't use gemm on the given tensors");let l=ot.size(a),d=[{type:12,data:l},{type:12,data:i},{type:12,data:s},{type:12,data:o},{type:1,data:t.alpha},{type:1,data:t.beta}],u=["type","type"];3===e.length&&(d.push(...mt(e[2].dims)),u.push("rank")),d.push(...mt(a));return{name:"Gemm",shaderCache:{hint:`${t.cacheKey}`,inputDependencies:u},getRunData:()=>({outputs:[{dims:a,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(l/64)},programUniforms:d}),getShaderSource:n=>{let r="";t.transA&&t.transB?r="value += a[k * uniforms.M + m] * b[n * uniforms.K + k];":t.transA&&!t.transB?r="value += a[k * uniforms.M + m] * b[k * uniforms.N + n];":!t.transA&&t.transB?r="value += a[m * uniforms.K + k] * b[n * uniforms.K + k];":!t.transA&&!t.transB&&(r="value += a[m * uniforms.K + k] * b[k * uniforms.N + n];");let i=1===t.alpha?"":"value *= uniforms.alpha;",s=xt("a",e[0].dataType,e[0].dims),o=xt("b",e[1].dataType,e[1].dims),l=s.type.value,d=null,u=[s,o];3===e.length&&(d=xt("c",e[2].dataType,e[2].dims.length),u.push(d));let c=Mt("output",e[0].dataType,a.length);u.push(c);return`\n  ${n.registerUniforms([{name:"output_size",type:"u32"},{name:"M",type:"u32"},{name:"N",type:"u32"},{name:"K",type:"u32"},{name:"alpha",type:"f32"},{name:"beta",type:"f32"}]).declareVariables(...u)}\n\n  ${n.mainStart()}\n    ${n.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n\n    let m = global_idx / uniforms.N;\n    let n = global_idx % uniforms.N;\n\n    var value = ${l}(0);\n    for (var k: u32 = 0u; k < uniforms.K; k++) {\n      ${r}\n    }\n\n    ${i}\n    ${null!=d?`let cOffset = ${d.broadcastedIndicesToOffset("vec2(m, n)",c)}; value += ${l}(uniforms.beta) * ${d.getByOffset("cOffset")};`:""}\n    output[global_idx] = value;\n  }`}}},Ms=e=>({transA:e.transA,transB:e.transB,alpha:e.alpha,beta:e.beta,cacheKey:`${e.transA};${e.transB};${1===e.alpha}`}),Ts=(e,t)=>{vs(e.inputs),e.compute(xs(e.inputs,t))}})),ml=V((()=>{Aa(),Da(),Ra(),ks=(e,t)=>{let n=e[0].dims,r=n,i=ot.sizeToDimension(n,2),s=ot.sizeFromDimension(n,2),o=gt(s),a=s/o,l=[n[0],n[1],a],d=[{type:12,data:s},{type:12,data:a}];d.push(...mt(l,l));return{name:"InstanceNormalization",shaderCache:{hint:`${t.epsilon};${o}`,inputDependencies:["rank","type","type"]},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:i},programUniforms:d}),getShaderSource:n=>{let r=xt("x",e[0].dataType,l.length,o),i=xt("scale",e[1].dataType,e[1].dims),s=xt("bias",e[2].dataType,e[2].dims),a=Mt("output",e[0].dataType,l.length,o),d=[r,i,s,a],u=r.type.value,c=1===o?"f32":`vec${o}<f32>`;return`\n  var<workgroup> meanShared : f32;\n  var<workgroup> squaredNormShared : f32;\n  var<workgroup> workgroupShared : array<${c}, 64>;\n  const workgroupSize = 64u;\n  ${n.registerUniforms([{name:"normSize",type:"u32"},{name:"normPackedSize",type:"u32"}]).declareVariables(...d)}\n  ${n.mainStart(64)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / uniforms.x_shape[1];\n    let channel = norm % uniforms.x_shape[1];\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial = ${c}(0);\n    for (var h = localIndex; h < uniforms.normPackedSize; h += workgroupSize) {\n      initial = initial + ${c}(${r.get("batch","channel","h")});\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = ${yt("workgroupShared[0]",o)} / f32(uniforms.normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = ${c}(0);\n    for (var h = localIndex; h < uniforms.normPackedSize; h += workgroupSize) {\n      let deviation =  ${c}(${r.get("batch","channel","h")}) - ${c}(meanShared);\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = ${yt("workgroupShared[0]",o)};\n    }\n    workgroupBarrier();\n\n    let invStdDev = inverseSqrt(squaredNormShared / f32(uniforms.normSize) + f32(${t.epsilon}));\n    let channelScale = invStdDev * f32(${i.getByOffset("channel")});\n    let channelShift = f32(${s.getByOffset("channel")}) - meanShared * channelScale;\n    for (var h = localIndex; h < uniforms.normPackedSize; h += workgroupSize) {\n      let value = ${r.get("batch","channel","h")} * ${u}(${c}(channelScale)) + ${u}(${c}(channelShift));\n      ${a.set("batch","channel","h","value")};\n    }\n  }`}}},$s=(e,t,n,r,i,s,o,a)=>{let l=gt(o),d=64,u=1===l?"vec2f":`mat2x${l}f`,c=1===l?"f32":`vec${l}f`,p=(e,t)=>`${u}(${e}, ${t})`,h=i*o/l,f=[{type:12,data:Math.ceil(s/d)},{type:12,data:s},{type:12,data:Math.floor(o/l)},{type:12,data:Math.floor(s*o/l)}],m=e.compute({name:"InstanceNormComputeMean",shaderCache:{hint:`${l}`,inputDependencies:["type"]},getRunData:()=>({outputs:[{dims:[i,o,d,2],dataType:1}],dispatchGroup:{x:i*o/l},programUniforms:f}),getShaderSource:e=>{let n=xt("input",t.dataType,t.dims,l);return`\n  ${e.declareVariables(n)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${u}>;\n  struct Uniforms {wg_size:u32, H:u32, C:u32, image_size:u32};\n  @group(0) @binding(2) var<uniform> uniforms: Uniforms;\n\n  ${e.mainStart(d)}\n    let currentImageNumber = global_idx / 64 / uniforms.C;\n    let currentChannelNumber = (global_idx / 64) % uniforms.C;\n    let wgOffset = local_id.x * uniforms.wg_size;\n    if (wgOffset >= uniforms.H) {\n        return;\n    }\n    let wgMax = min(wgOffset + uniforms.wg_size, uniforms.H);\n\n    let offset = currentImageNumber * uniforms.image_size + currentChannelNumber;\n    var sum = ${_t("f32",l)};\n    var squaredSum = ${_t("f32",l)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${c}(input[offset + i * uniforms.C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${p("sum","squaredSum")};\n  }`}},{inputs:[t],outputs:[-1]})[0],g=[{type:12,data:h},{type:12,data:s},{type:12,data:Math.floor(o/l)},{type:12,data:Math.floor(d*o/l)}];return e.compute({name:"InstanceNormComputeChannelScaleShift",shaderCache:{hint:`${l};${a}`,inputDependencies:["type","type","type"]},getRunData:()=>({outputs:[{dims:[i,o,2],dataType:1}],dispatchGroup:{x:Math.ceil(h/64)},programUniforms:g}),getShaderSource:e=>{let t=xt("scale",n.dataType,n.dims,l),i=xt("bias",r.dataType,r.dims,l);return`\n  @group(0) @binding(0) var<storage, read> input : array<${u}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${t.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${i.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${u}>;\n  struct Uniforms {units_of_work : u32, H: u32, C : u32, image_size : u32};\n  @group(0) @binding(4) var<uniform> uniforms: Uniforms;\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.units_of_work")}\n    let currentImageNumber = global_idx / uniforms.C;\n    let currentChannelNumber = global_idx % uniforms.C;\n\n    let offset = currentImageNumber * uniforms.image_size;\n    var sum = ${_t("f32",l)};\n    var squaredSum = ${_t("f32",l)};\n    for (var i: u32 = 0; i < min(64, uniforms.H); i++) {\n        let value = input[offset + i + currentChannelNumber * 64];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(uniforms.H);\n    squaredSum = squaredSum / f32(uniforms.H);\n    let invStdDev = inverseSqrt(squaredSum - sum * sum + f32(${a}));\n    let channelScale = invStdDev * ${c}(scale[currentChannelNumber]);\n    let channelShift = ${c}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${p("channelScale","channelShift")};\n  }`}},{inputs:[m,n,r],outputs:[-1]})[0]},Ss=(e,t,n)=>{let r=t[0].dims,i=r,s=r[0],o=r[r.length-1],a=ot.sizeFromDimension(r,1)/o,l=gt(o),d=ot.size(i)/l,u=[{type:12,data:a},{type:12,data:Math.floor(o/l)}],c=$s(e,t[0],t[1],t[2],s,a,o,n.epsilon);e.compute({name:"InstanceNormalizationNHWC",shaderCache:{hint:`${l}`,inputDependencies:["type","type"]},getRunData:()=>({outputs:[{dims:i,dataType:t[0].dataType}],dispatchGroup:{x:Math.ceil(d/64)},programUniforms:u}),getShaderSource:e=>{let n=ht(t[0].dataType),r=1===l?"vec2f":`mat2x${l}f`,s=1===l?n:`vec${l}<${n}>`,o=xt("input",t[0].dataType,t[0].dims,l),a=Mt("output",t[0].dataType,i,l);return`\n  @group(0) @binding(0) var<storage, read> input : array<${o.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${r}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${a.type.storage}>;\n  struct Uniforms {H: u32, C : u32};\n  @group(0) @binding(3) var<uniform> uniforms: Uniforms;\n\n  ${e.mainStart()}\n    let currentImageNumber = global_idx / (uniforms.C * uniforms.H);\n    let currentChannelNumber = global_idx % uniforms.C;\n\n    let scaleOffset = currentImageNumber * uniforms.C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${s}(scale[0]), ${s}(scale[1]));\n  }`}},{inputs:[t[0],c]})},Cs=(e,t)=>{"NHWC"===t.format?Ss(e,e.inputs,t):e.compute(ks(e.inputs,t))}})),gl=V((()=>{Aa(),Da(),Ra(),Ps=e=>{if(!e||e.length<2)throw new Error("layerNorm requires at least 2 inputs.")},Es=(e,t,n)=>{let r=e[0].dims,i=e[1],s=e[2],o=r,a=ot.normalizeAxis(t.axis,r.length),l=ot.sizeToDimension(r,a),d=ot.sizeFromDimension(r,a),u=ot.size(i.dims),c=s?ot.size(s.dims):0;if(u!==d||s&&c!==d)throw new Error(`Size of X.shape()[axis:] == ${d}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${u} and bias size of ${c}`);let p=[];for(let e=0;e<r.length;++e)e<a?p.push(r[e]):p.push(1);let h=gt(d),f=["type","type"],m=[{type:12,data:l},{type:1,data:d},{type:12,data:Math.floor(d/h)},{type:1,data:t.epsilon}];s&&f.push("type");let g=n>1,_=n>2,w=[{dims:o,dataType:e[0].dataType}];return g&&w.push({dims:p,dataType:1}),_&&w.push({dims:p,dataType:1}),{name:"LayerNormalization",shaderCache:{hint:`${h};${n}`,inputDependencies:f},getRunData:()=>({outputs:w,dispatchGroup:{x:Math.ceil(l/64)},programUniforms:m}),getShaderSource:t=>{let n=ht(e[0].dataType),r=[xt("x",e[0].dataType,e[0].dims,h),xt("scale",i.dataType,i.dims,h)];s&&r.push(xt("bias",s.dataType,s.dims,h)),r.push(Mt("output",e[0].dataType,o,h)),g&&r.push(Mt("mean_data_output",1,p)),_&&r.push(Mt("inv_std_output",1,p));return`\n  ${t.registerUniforms([{name:"norm_count",type:"u32"},{name:"norm_size",type:"f32"},{name:"norm_size_vectorized",type:"u32"},{name:"epsilon",type:"f32"}]).declareVariables(...r)}\n  ${t.mainStart()}\n    ${t.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.norm_count")}\n    let offset = global_idx * uniforms.norm_size_vectorized;\n    var mean_vector = ${_t("f32",h)};\n    var mean_square_vector = ${_t("f32",h)};\n\n    for (var h: u32 = 0u; h < uniforms.norm_size_vectorized; h++) {\n      let value = ${wt(n,h,"x[h + offset]")};\n      mean_vector += value;\n      mean_square_vector += value * value;\n    }\n    let mean = ${yt("mean_vector",h)} / uniforms.norm_size;\n    let inv_std_dev = inverseSqrt(${yt("mean_square_vector",h)} / uniforms.norm_size - mean * mean + uniforms.epsilon);\n\n    for (var j: u32 = 0; j < uniforms.norm_size_vectorized; j++) {\n      let f32input = ${wt(n,h,"x[j + offset]")};\n      let f32scale = ${wt(n,h,"scale[j]")};\n      output[j + offset] = ${r[0].type.value}((f32input - mean) * inv_std_dev * f32scale\n        ${s?`+ ${wt(n,h,"bias[j]")}`:""}\n      );\n    }\n\n    ${g?"mean_data_output[global_idx] = mean":""};\n    ${_?"inv_std_output[global_idx] = inv_std_dev":""};\n  }`}}},As=(e,t)=>{Ps(e.inputs),e.compute(Es(e.inputs,t,e.outputCount))}})),_l=V((()=>{Aa(),Da(),La(),Ra(),Fs=(e,t)=>{if(e.length<3||e.length>4)throw new Error("MatMulNBits requires 3 or 4 inputs");let n=e[0],r=n.dims.length;if(n.dims[r-1]!==t.k)throw new Error("The last dim of input shape does not match the k value");let i=Math.floor((t.k+t.blockSize-1)/t.blockSize),s=t.blockSize/8*t.bits,o=e[1];if(!ot.areEqual(o.dims,[t.n,i,s]))throw new Error("The second inputs must be 3D tensor with shape N X nBlocksPerCol X blobSize");let a=e[2].dims;if(ot.size(a)!==t.n*i)throw new Error("scales input size error.");if(4===e.length){let n=e[3].dims,r=t.bits>4?t.n*i:t.n*Math.floor((i+1)/2);if(ot.size(n)!==r)throw new Error("zeroPoints input size error.")}},Is=(e,t)=>{let n=e[0].dims,r=n.length,i=n.slice(0,r-1).concat(t.n),s=n[r-2],o=t.blockSize/8*t.bits/4,a=gt(s),l=gt(t.n),d=gt(t.k),u=gt(o),c=ot.size(i)/l/a,p=[{type:12,data:c},{type:12,data:t.k},{type:12,data:t.n},{type:12,data:t.accuracyLevel},{type:12,data:t.bits},{type:12,data:t.blockSize}],h=n.slice();h.splice(-1,1,t.k/d);let f=ot.convertShape(e[1].dims).slice();f.splice(-1,1,o/u),p.push(...mt(h)),p.push(...mt(f)),p.push(...mt(e[2].dims)),4===e.length&&p.push(...mt(ot.convertShape(e[3].dims)));let m=i.slice();m.splice(-1,1,t.n/l),p.push(...mt(m));return{name:"MatMulNBits",shaderCache:{hint:`${t.cacheKey};${e.length}`,inputDependencies:Array(e.length).fill("rank")},getRunData:()=>({outputs:[{dims:i,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(c/64)},programUniforms:p}),getShaderSource:n=>{let s=xt("a",e[0].dataType,h.length,d),c=xt("b",12,f.length,u),p=xt("scales",e[2].dataType,e[2].dims.length),m=[s,c,p],g=4===e.length?xt("zero_points",12,e[3].dims.length):void 0;g&&m.push(g);let _=Mt("output",e[0].dataType,i.length,l),w=Math.floor((t.k+t.blockSize-1)/t.blockSize),y=ht(e[0].dataType),b=(()=>{switch(d){case 1:return`array<${y}, 8>`;case 2:return`mat4x2<${y}>`;case 4:return`mat2x4<${y}>`;default:throw new Error(`${d}-component is not supported.`)}})(),v=`\n        fn dequantize(quantized: ${b}, zero_point: ${y}, scale: ${y}) -> ${b} {\n          ${1===d?`var dequantized = ${b}(${Array.from({length:8},((e,t)=>`(quantized[${t}] - zero_point) * scale`)).join(", ")});\n              return dequantized;`:`var zero_points: ${b} = ${b}(${Array(8).fill("zero_point").join(",")});\n              return (quantized - zero_points) * scale;`}\n        }`,x=`\n        fn ortUnpack8x4snorm(value: u32) -> ${b} {\n          var quantized: ${b};\n          var offset: u32 = 0;\n          let count: u32 = 4;\n          for (var i: u32 = 0; i < 8u; i++) {\n            var result = ${y}(extractBits(value, offset, count));\n            ${(()=>{switch(d){case 1:return"quantized[i] = result;";case 2:return"quantized[i / 2][i % 2] = result;";case 4:return"quantized[i / 4][i % 4] = result;";default:throw new Error(`${d}-component is not supported.`)}})()}\n            offset += count;\n          }\n          return quantized;\n        }`,M=g?`\n          zero_point_offset += 4;\n          if (zero_point_offset == 32) {\n            zero_point_offset = 0;\n            zero_point_index++;\n            zero_point_word = ${g.getByOffset("zero_point_index")};\n          }`:"";return`\n        ${v};\n        ${x};\n        ${n.registerUniforms([{name:"output_size",type:"u32"},{name:"K",type:"u32"},{name:"N",type:"u32"},{name:"accuracy_level",type:"u32"},{name:"bits",type:"u32"},{name:"block_size",type:"u32"}]).declareVariables(...m,_)}\n        ${n.mainStart()}\n          ${n.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n          var output_values: array<${_.type.value}, ${a}>;\n          var output_indices = ${_.offsetToIndices("global_idx")};\n          var n = ${_.indicesGet("output_indices",r-1)};\n          var m = ${_.indicesGet("output_indices",r-2)};\n          var a_indices: ${s.type.indices} = output_indices;\n          // Two zero points are packed into one byte because uniforms.bits <= 4.\n          // zero_point_offset is either 0 or 4. It is bit offset within one byte.\n          // TODO support zero_point_offset for bits > 4\n          ${g?`\n          var zero_point_index: u32 = n * ${l} * ((${w} + 1) / 2) / 4;\n          var zero_point_word: u32 = ${g.getByOffset("zero_point_index")};\n          var zero_point_offset: u32 = 0;`:""}\n          var scale_index = n * ${w*l};\n          var b_indices: ${c.type.indices};\n          for (var c: u32 = 0; c < ${l}; c++) {\n            ${c.indicesSet("b_indices","0",`n * ${l} + c`)};\n            var block_offset: u32 = 0;\n            for (var block: u32 = 0; block < ${w}; block++) {\n              // The scale and zero points are computed per block.\n              let scale = ${p.getByOffset("scale_index")};\n              // The default zero point is 8 for unsigned 4-bit quantization.\n              let zero_point = ${y}(${g?"extractBits(zero_point_word, zero_point_offset, 4)":8});\n              ${c.indicesSet("b_indices","1","block")};\n              var word_offset: u32 = block_offset;\n              for (var word: u32 = 0; word < ${o}; word += ${u}) {\n                ${c.indicesSet("b_indices","2","word")};\n                let b_data = ${c.getByIndices("b_indices")};\n                for (var i: u32 = 0; i < ${u}; i++) {\n                  let b_value = ${1===u?"b_data":"b_data[word + i]"};\n                  let b_quantized_values: ${b} = ortUnpack8x4snorm(b_value);\n                  let b_dequantized_values = dequantize(b_quantized_values, zero_point, scale);\n                  // Number of B elements per 32-bit word is 32/bits = 32/4 = 8\n                  var offset: u32 = word_offset;\n                  for (var j: u32 = 0; j < 8/${d}; j++) {\n                    ${s.indicesSet("a_indices",r-1,`offset/${d}`)};\n                    for (var k: u32 = 0; k < ${a}u; k++) {\n                      ${s.indicesSet("a_indices",r-2,`m * ${a} + k`)};\n                      let a_data = ${s.getByIndices("a_indices")};\n                      output_values[k]${l>1?"[c]":""} += ${1===d?"a_data * b_dequantized_values[j]":"dot(a_data, b_dequantized_values[j])"};\n                    }\n                    offset += ${d};\n                  }\n                  word_offset += 8;\n                }\n              }\n              scale_index++;\n              ${M}\n              block_offset += uniforms.block_size;\n            }\n            // Drop the trailing 4 bits if the zero_poit_offset is not a byte boundary to align with the next byte.\n            ${g?`if (zero_point_offset % 8 > 0) {\n                ${M}\n              }`:""}\n            }\n            for (var k: u32 = 0u; k < ${a}u; k++) {\n              ${_.indicesSet("output_indices",r-2,""+(a+" * m + k"))};\n              ${_.setByIndices("output_indices","output_values[k]")}\n            }\n        }`}}},zs=(e,t)=>{Fs(e.inputs,t),e.compute(Is(e.inputs,t))},Bs=e=>rt(e)})),wl=V((()=>{Aa(),Da(),La(),Ba(),Ga(),Ra(),Na(),Os=(e,t)=>{let n=e[0],r=e[1],i=e[2],s=e[3],o=e[4],a=e[5],l=e[6],d=e[7];if(3!==n.dims.length&&5!==n.dims.length)throw new Error("Input query is expected to have 3 or 5 dimensions");let u,c=n.dims[0],p=n.dims[1],h=3===n.dims.length?n.dims[2]:t.numHeads*n.dims[4],f=p,m=0,g=0,_=Math.floor(h/t.numHeads);if(l&&d){if(4!==l.dims.length)throw new Error('Input "past_key" is expected to have 4 dimensions');if(4!==d.dims.length)throw new Error('Input "past_value" is expected to have 4 dimensions');m=l.dims[2],g=l.dims[2]}else if(l||d)throw new Error('Input "past_key" and "past_value" shall be both present or both absent');if(r){if(3!==n.dims.length)throw new Error('Input "query" is expected to have 3 dimensions when key is given');if(r.dims.length<3||r.dims.length>5)throw new Error('Input "key" is expected to have 3, 4, or 5 dimensions');if(n.dims[0]!==r.dims[0])throw new Error('Input "query" and "key" shall have same dim 0 (batch size)');if(3===r.dims.length){if(r.dims[2]!==n.dims[2])throw new Error('Input "query" and "key" shall have same dim 2 (hidden_size)');u=2,f=r.dims[1]}else if(5===r.dims.length){if(r.dims[2]!==t.numHeads||2!==r.dims[3]||r.dims[4]!==_)throw new Error('Expect "key" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');if(i)throw new Error('Expect "value" be none when "key" has packed kv format.');u=5,f=r.dims[1]}else{if(r.dims[1]!==t.numHeads||r.dims[3]!==_)throw new Error('Expect "key" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');u=0,f=r.dims[2]}}else{if(3!==n.dims.length&&5!==n.dims.length)throw new Error('Input "query" is expected to have 3 or 5 dimensions when key is empty');if(5===n.dims.length&&(n.dims[2]!==t.numHeads||3!==n.dims[3]))throw new Error('Expect "query" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');u=3}if(s){if(1!==s.dims.length)throw new Error('Input "bias" is expected to have 1 dimension');if(i&&5===n.dims.length&&2===n.dims[3])throw new Error("bias is not allowed for packed kv.")}let w=0;if(o){w=8;let e=o.dims;throw 1===e.length?e[0]===c?w=1:e[0]===3*c+2&&(w=3):2===e.length&&e[0]===c&&e[1]===f&&(w=5),8===w?new Error('Input "key_padding_mask" shape shall be (batch_size) or (batch_size, kv_sequence_length)'):new Error("Mask not supported")}let y=!1,b=h;if(i){if(3!==i.dims.length&&4!==i.dims.length)throw new Error('Input "value" is expected to have 3 or 4 dimensions');if(n.dims[0]!==i.dims[0])throw new Error('Input "query" and "value" shall have same dim 0 (batch_size)');if(3===i.dims.length){if(f!==i.dims[1])throw new Error('Input "key" and "value" shall have the same dim 1 (kv_sequence_length)');b=i.dims[2]}else{if(f!==i.dims[2])throw new Error('Input "past_key" and "past_value" shall have the same dim 2 (kv_sequence_length)');b=i.dims[1]*i.dims[3],y=!0}}let v=m+f;if(o)throw new Error("Key padding mask is not supported");if(a)throw new Error("extraAddQk is not supported");if(l)throw new Error("pastKey is not supported");if(d)throw new Error("pastValue is not supported");return{batchSize:c,sequenceLength:p,pastSequenceLength:m,kvSequenceLength:f,totalSequenceLength:v,maxSequenceLength:g,inputHiddenSize:0,hiddenSize:h,vHiddenSize:b,headSize:_,vHeadSize:Math.floor(b/t.numHeads),numHeads:t.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:t.maskFilterValue,maskType:w,scale:t.scale,broadcastResPosBias:!1,passPastInKv:y,qkvFormat:u}},Ls=e=>rt({...e}),Ds=rt({perm:[0,2,1,3]}),Rs=(e,t,n,r,i,s,o)=>{let a=[r,i,s],l=ot.size(a),d=[{type:12,data:l},{type:12,data:o},{type:12,data:s}];return e.compute({name:"MultiHeadAttentionAddBias",shaderCache:{inputDependencies:["type","type"]},getRunData:()=>({outputs:[{dims:a,dataType:t.dataType,gpuDataType:0}],dispatchGroup:{x:Math.ceil(l/64)},programUniforms:d}),getShaderSource:e=>{let r=Mt("qkv_with_bias",t.dataType,a),i=xt("qkv",t.dataType,a),s=xt("bias",n.dataType,a);return`\n  ${e.registerUniforms([{name:"output_size",type:"u32"},{name:"bias_offset",type:"u32"},{name:"hidden_size",type:"u32"}]).declareVariables(i,s,r)}\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n    let bias_offset_idx = (global_idx % uniforms.hidden_size) + uniforms.bias_offset;\n\n    qkv_with_bias[global_idx] = qkv[global_idx] + bias[bias_offset_idx];\n  }`}},{inputs:[t,n],outputs:[-1]})[0]},Ns=(e,t,n,r,i,s,o,a)=>{let l=s;if(o){if(1===r)throw new Error("AddBiasReshape is not implemented. Please export your model with packed QKV or KV");return l=Rs(e,s,o,t,r,n*i,a),l=l.reshape([t,r,n,i]),e.compute(Ft(l,Ds.perm),{inputs:[l],outputs:[-1]})[0]}return 3===s.dims.length&&(l=s.reshape([t,r,n,i])),e.compute(Ft(l,Ds.perm),{inputs:[l],outputs:[-1]})[0]},Vs=(e,t)=>{let n=Os(e.inputs,t);if(5===e.inputs[0].dims.length)throw new Error("Packed QKV is not implemented");if(5===e.inputs[1]?.dims.length)throw new Error("Packed KV is not implemented");let r=e.inputs[1]&&e.inputs[2]&&4===e.inputs[1].dims.length&&4===e.inputs[2].dims.length,i=Ns(e,n.batchSize,n.numHeads,n.sequenceLength,n.headSize,e.inputs[0],e.inputs[3],0);if(r)return Ln(e,i,e.inputs[1],e.inputs[2],e.inputs[4],void 0,void 0,void 0,e.inputs[5],n,t);let s=Ns(e,n.batchSize,n.numHeads,n.kvSequenceLength,n.headSize,e.inputs[1],e.inputs[3],n.hiddenSize),o=Ns(e,n.batchSize,n.numHeads,n.kvSequenceLength,n.vHeadSize,e.inputs[2],e.inputs[3],2*n.hiddenSize);Ln(e,i,s,o,e.inputs[4],void 0,e.inputs[6],e.inputs[7],e.inputs[5],n,t)}})),yl=V((()=>{Aa(),Da(),Ra(),js=e=>{if(!e||e.length<1)throw new Error("Too few inputs");if(1!==e[0].dataType&&10!==e[0].dataType)throw new Error("Input type must be float or float16.");if(e.length>=2){let t=2*e[0].dims.length===e[1].dims[0];if(4===e.length&&(t=2*e[3].dims[0]===e[1].dims[0]),!t)throw new Error("The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].")}},Us=(e,t,n)=>{let r="";for(let i=t-1;i>=0;--i)r+=`\n            k = i32(${e.indicesGet("indices",i)}) - ${bt("uniforms.pads",i,n)};\n            if (k < 0) {\n              break;\n            }\n            if (k >= i32(${bt("uniforms.x_shape",i,t)})) {\n              break;\n            }\n            offset += k * i32(${bt("uniforms.x_strides",i,t)});\n        `;return`\n          value = ${e.type.value}(uniforms.constant_value);\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${r}\n            value = x[offset];\n          }\n      `},Gs=(e,t,n)=>{let r="";for(let i=t-1;i>=0;--i)r+=`\n                k = i32(${e.indicesGet("indices",i)}) - ${bt("uniforms.pads",i,n)};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = 2 * (i32(${bt("uniforms.x_shape",i,t)}) - 1);\n                  k = k % _2n_1;\n                  if(k >= i32(${bt("uniforms.x_shape",i,t)})) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * i32(${bt("uniforms.x_strides",i,t)});\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${r}\n              value = x[offset];\n          `},qs=(e,t,n)=>{let r="";for(let i=t-1;i>=0;--i)r+=`\n                k = i32(${e.indicesGet("indices",i)}) - ${bt("uniforms.pads",i,n)};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= i32(${bt("uniforms.x_shape",i,t)})) {\n                  k = i32(${bt("uniforms.x_shape",i,t)}) - 1;\n                }\n                offset += k * i32(${bt("uniforms.x_strides",i,t)});\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${r}\n              value = x[offset];\n          `},Ws=(e,t,n)=>{let r="";for(let i=t-1;i>=0;--i)r+=`\n                k = i32(${e.indicesGet("indices",i)}) - ${bt("uniforms.pads",i,n)};\n                if (k < 0)  {\n                  k += i32(${bt("uniforms.x_shape",i,t)}]);\n                }\n                if (k >= i32(${bt("uniforms.x_shape",i,t)})) {\n                  k -= i32(${bt("uniforms.x_shape",i,t)});\n                }\n                offset += k * i32(${bt("uniforms.x_strides",i,t)});\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${r}\n              value = x[offset];\n          `},Hs=(e,t,n)=>{switch(n.mode){case 0:return Us(e,t,n.pads.length);case 1:return Gs(e,t,n.pads.length);case 2:return qs(e,t,n.pads.length);case 3:return Ws(e,t,n.pads.length);default:throw new Error("Invalid mode")}},Xs=(e,t)=>{let n=ot.padShape(e[0].dims.slice(),t.pads),r=e[0].dims,i=[{type:12,data:ot.size(n)},{type:6,data:t.pads}];0===t.mode&&i.push({type:e[0].dataType,data:t.value}),i.push(...mt(e[0].dims,n));return{name:"Pad",shaderCache:{hint:`${t.mode}`,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(ot.size(n)/64)},programUniforms:i}),getShaderSource:i=>{let s=Mt("output",e[0].dataType,n.length),o=xt("x",e[0].dataType,r.length),a=o.type.value,l=Hs(s,r.length,t),d=[{name:"output_size",type:"u32"},{name:"pads",type:"i32",length:t.pads.length}];return 0===t.mode&&d.push({name:"constant_value",type:a}),`\n            ${i.registerUniforms(d).declareVariables(o,s)}\n            ${i.mainStart()}\n            ${i.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n\n            let indices = ${s.offsetToIndices("global_idx")};\n\n            var value = ${a}(0);\n            ${l}\n            output[global_idx] = value;\n        }`}}},Qs=(e,t)=>{if(e.length>1){let n=e[1].getBigInt64Array(),r=e.length>=3&&e[2].data?e[2].getFloat32Array()[0]:0,i=e[0].dims.length,s=new Int32Array(2*i).fill(0);if(e.length>=4){let t=e[3].getBigInt64Array();for(let e=0;e<t.length;e++)s[Number(t[e])]=Number(n[e]),s[Number(t[e])+i]=Number(n[e+t.length])}else n.forEach(((e,t)=>s[Number(t)]=Number(e)));let o=[];return s.forEach((e=>o.push(e))),{mode:t.mode,value:r,pads:o}}return t},Ks=(e,t)=>{js(e.inputs);let n=Qs(e.inputs,t);e.compute(Xs(e.inputs,n),{inputs:[0]})}})),bl=V((()=>{Ta(),Aa(),Da(),Ra(),Ys=e=>{if(p.webgpu.validateInputContent&&(!e||1!==e.length))throw new Error("Pool ops requires 1 input.")},Zs=(e,t,n)=>{let r="NHWC"===t.format,i=e.dims.slice();r&&i.splice(1,0,i.pop());let s=Object.hasOwnProperty.call(t,"dilations"),o=t.kernelShape.slice(),a=t.strides.slice(),l=s?t.dilations.slice():[],d=t.pads.slice();at.adjustPoolAttributes(n,i,o,a,l,d);let u=at.computePoolOutputShape(n,i,a,l,o,d,t.autoPad),c=Object.assign({},t);s?Object.assign(c,{kernelShape:o,strides:a,pads:d,dilations:l,cacheKey:t.cacheKey}):Object.assign(c,{kernelShape:o,strides:a,pads:d,cacheKey:t.cacheKey});let p=u.slice();return p.push(p.splice(1,1)[0]),[c,r?p:u]},Js=(e,t)=>{let n="NHWC"===t.format,r=[{type:12,data:ot.size(e)},{type:12,data:ot.size(t.kernelShape)}],i=[{name:"outputSize",type:"u32"},{name:"kernelSize",type:"u32"}];if(t.kernelShape.length<=2){let e=t.kernelShape[t.kernelShape.length-1],n=t.strides[t.strides.length-1],s=t.pads[t.pads.length/2-1],o=t.pads[t.pads.length-1],a=!!(s+o);r.push({type:12,data:e},{type:12,data:n},{type:12,data:s},{type:12,data:o}),i.push({name:"kw",type:"u32"},{name:"sw",type:"u32"},{name:"pwStart",type:"u32"},{name:"pwEnd",type:"u32"});let l=!1;if(2===t.kernelShape.length){let e=t.kernelShape[t.kernelShape.length-2],n=t.strides[t.strides.length-2],s=t.pads[t.pads.length/2-2],o=t.pads[t.pads.length-2];l=!!(s+o),r.push({type:12,data:e},{type:12,data:n},{type:12,data:s},{type:12,data:o}),i.push({name:"kh",type:"u32"},{name:"sh",type:"u32"},{name:"phStart",type:"u32"},{name:"phEnd",type:"u32"})}return[r,i,!0,a,l]}{if(n)throw new Error("Pooling with kernelShape.length > 2 is not supported for NHWC format.");let e=ot.computeStrides(t.kernelShape);return r.push({type:12,data:e},{type:12,data:t.pads},{type:12,data:t.strides}),i.push({name:"kernelStrides",type:"u32",length:e.length},{name:"pads",type:"u32",length:t.pads.length},{name:"strides",type:"u32",length:t.strides.length}),[r,i,!!t.pads.reduce(((e,t)=>e+t)),!1,!1]}},eo=(e,t,n,r,i,s,o,a,l,d,u,c)=>{let p="NHWC"===i.format,h=t.type.value,f=Mt("output",t.type.tensor,r);if(i.kernelShape.length<=2){let r="",d="",m="",g=n-(p?2:1);if(r=u?`\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${g}] = indices[${g}] * uniforms.sw - uniforms.pwStart + i;\n                  if (xIndices[${g}] < 0 || xIndices[${g}]\n                      >= uniforms.x_shape[${g}]) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${t.indicesToOffset("xIndices")}];\n                  ${s}\n                }`:`\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${g}] = indices[${g}] * uniforms.sw - uniforms.pwStart + i;\n                  let x_val = x[${t.indicesToOffset("xIndices")}];\n                  ${s}\n                }`,2===i.kernelShape.length){let e=n-(p?3:2);d=c?`\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${e}] = indices[${e}] * uniforms.sh - uniforms.phStart + j;\n                  if (xIndices[${e}] < 0 || xIndices[${e}] >= uniforms.x_shape[${e}]) {\n                    pad += i32(uniforms.kw);\n                    continue;\n                  }\n              `:`\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${e}] = indices[${e}] * uniforms.sh - uniforms.phStart + j;\n                `,m="\n              }\n            "}return`\n            ${e.registerUniforms(l).declareVariables(t,f)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n\n              let indices = ${f.offsetToIndices("global_idx")};\n              var xIndices = ${f.offsetToIndices("global_idx")};\n\n              var value = ${h}(${a});\n              var pad = 0;\n              ${d}\n              ${r}\n              ${m}\n              ${o}\n\n              output[global_idx] = value;\n            }`}{if(p)throw new Error("Pooling with kernelShape.length > 2 is not supported for NHWC format.");let r=i.kernelShape.length,u=i.pads.length,c="";return c=d?`\n                if (xIndices[j] >= uniforms.x_shape[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${t.indicesToOffset("xIndices")}];\n                ${s}\n              }`:`\n              }\n              let x_val = x[${t.indicesToOffset("xIndices")}];\n              ${s}\n            `,`\n            ${e.registerUniforms(l).declareVariables(t,f)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n              let indices = ${f.offsetToIndices("global_idx")};\n              var xIndices = ${f.offsetToIndices("global_idx")};\n\n              var offsets: array<u32, ${r}>;\n\n              var value = ${h}(${a});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < uniforms.kernelSize; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${r-1}u; j++) {\n                  offsets[j] = offset / ${bt("uniforms.kernelStrides","j",r)};\n                  offset -= offsets[j] * ${bt("uniforms.kernelStrides","j",r)};\n                }\n                offsets[${r-1}] = offset;\n\n                isPad = false;\n                for (var j = ${n-r}u; j < ${n}u; j++) {\n                  xIndices[j] = indices[j] * ${bt("uniforms.strides",`j - ${n-r}u`,r)}\n                    + offsets[j - ${n-r}u] - ${bt("uniforms.pads","j - 2u",u)};\n                  ${c}\n              }\n              ${o}\n\n              output[global_idx] = value;\n            }`}},to=e=>`${e.format};${e.ceilMode};${e.autoPad};${e.kernelShape.length}`,no=e=>`${to(e)};${e.countIncludePad}`,ro=e=>`${to(e)};${e.storageOrder};${e.dilations}`,io=e=>({format:e.format,autoPad:["NOTSET","VALID","SAME_UPPER","SAME_LOWER"][e.auto_pad],ceilMode:e.ceil_mode,kernelShape:e.kernel_shape,strides:e.strides,pads:e.pads}),so=(e,t,n,r)=>{let[i,s]=Zs(t,r,n),o=xt("x",t.dataType,t.dims.length),a=o.type.value,l="";i.countIncludePad?l+=`value /= ${a}(uniforms.kernelSize);`:l+=`value /= ${a}(i32(uniforms.kernelSize) - pad);`;let[d,u,c,p,h]=Js(s,i);d.push(...mt(t.dims,s));return{name:e,shaderCache:{hint:`${r.cacheKey};${c};${p};${h}`,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(ot.size(s)/64)},programUniforms:d}),getShaderSource:e=>eo(e,o,t.dims.length,s.length,i,"value += x_val;",l,0,u,c,p,h)}},oo=e=>{let t=0!==e.count_include_pad,n=io(e);if(0!==n.ceilMode)throw new Error("using ceil() in shape computation is not yet supported for AveragePool");let r={countIncludePad:t,...n,cacheKey:""};return{...r,cacheKey:no(r)}},ao=(e,t)=>{Ys(e.inputs),e.compute(so("AveragePool",e.inputs[0],!1,t))},lo={autoPad:"",ceilMode:0,countIncludePad:!1,kernelShape:[],strides:[],pads:[],storageOrder:0,dilations:[]},uo=e=>{let t=e.format;return{format:t,...lo,cacheKey:t}},co=(e,t)=>{Ys(e.inputs),e.compute(so("GlobalAveragePool",e.inputs[0],!0,t))},po=(e,t,n,r)=>{let[i,s]=Zs(t,r,n),o=xt("x",t.dataType,t.dims.length),[a,l,d,u,c]=Js(s,i);return a.push(...mt(t.dims,s)),{name:e,shaderCache:{hint:`${r.cacheKey};${d};${u};${c}`,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(ot.size(s)/64)},programUniforms:a}),getShaderSource:e=>eo(e,o,t.dims.length,s.length,i,"\n      value = max(x_val, value);\n    ","",10===t.dataType?-65504:-1e5,l,d,u,c)}},ho=(e,t)=>{Ys(e.inputs),e.compute(po("MaxPool",e.inputs[0],!1,t))},fo=e=>{let t=e.storage_order,n=e.dilations,r=io(e);if(0!==t)throw new Error("column major storage order is not yet supported for MaxPool");if(0!==r.ceilMode)throw new Error("using ceil() in shape computation is not yet supported for MaxPool");let i={storageOrder:t,dilations:n,...r,cacheKey:""};return{...i,cacheKey:ro(i)}},mo=e=>{let t=e.format;return{format:t,...lo,cacheKey:t}},go=(e,t)=>{Ys(e.inputs),e.compute(po("GlobalMaxPool",e.inputs[0],!0,t))}})),vl=V((()=>{Ta(),Aa(),Ra(),_o=(e,t,n)=>{if(e===t||e<t&&n<0||e>t&&n>0)throw new Error("Range these inputs' contents are invalid.")},wo=(e,t,n,r)=>{let i=Math.abs(Math.ceil((t-e)/n)),s=[i],o=i,a=[{type:12,data:o},{type:r,data:e},{type:r,data:n},...mt(s)];return{name:"Range",shaderCache:{hint:`${r}`},getShaderSource:e=>{let t=Mt("output",r,s.length),n=t.type.value,i=[{name:"outputSize",type:"u32"},{name:"start",type:n},{name:"delta",type:n}];return`\n        ${e.registerUniforms(i).declareVariables(t)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n        output[global_idx] = uniforms.start + ${n}(global_idx) * uniforms.delta;\n      }`},getRunData:()=>({outputs:[{dims:s,dataType:r}],dispatchGroup:{x:Math.ceil(o/64)},programUniforms:a})}},yo=e=>{let t=0,n=0,r=0;6===e.inputs[0].dataType?(t=e.inputs[0].getInt32Array()[0],n=e.inputs[1].getInt32Array()[0],r=e.inputs[2].getInt32Array()[0]):1===e.inputs[0].dataType&&(t=e.inputs[0].getFloat32Array()[0],n=e.inputs[1].getFloat32Array()[0],r=e.inputs[2].getFloat32Array()[0]),p.webgpu.validateInputContent&&_o(t,n,r),e.compute(wo(t,n,r,e.inputs[0].dataType),{inputs:[]})}})),xl=V((()=>{Aa(),Da(),La(),Ra(),bo=(e,t)=>{if(e.every((e=>e>0||(()=>{throw new Error("Resize requires scales input values to be positive")}))),e.length>0)if("linear"===t.mode){if(!(2===e.length||3===e.length||4===e.length&&1===e[0]&&1===e[1]||4===e.length&&1===e[0]&&1===e[3]||5===e.length&&1===e[0]&&1===e[1]))throw new Error("For linear mode, Resize requires scales to be 2D, 3D, 4D with either two outermost or one innermost and\n            one outermost scale values equal to 1, or 5D with two outermost scale values equal to 1")}else if("cubic"===t.mode&&!(2===e.length||4===e.length&&1===e[0]&&1===e[1]||4===e.length&&1===e[0]&&1===e[3]))throw new Error("Resize requires scales input size to be 2 or 4 for cubic mode")},vo=(e,t,n)=>{t.every((e=>e>=0&&e<n||(()=>{throw new Error("Resize requires axes input values to be positive and less than rank")})));let r=new Array(n).fill(1);return t.forEach(((t,n)=>r[t]=e[n])),r},xo=(e,t,n,r,i,s)=>{let[o,a,l]=n>10?[1,2,3]:[-1,e.length>1?1:-1,-1],d=e[0].dims.length;if(o>0&&e.length>o&&e[o].dims.length>0)e[o].getFloat32Array().forEach((e=>s.push(e)));else if("tf_crop_and_resize"===t.coordinateTransformMode)throw new Error("Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize");if(a>0&&e.length>a&&e[a].dims.length>0){if(e[a].getFloat32Array().forEach((e=>r.push(e))),0!==r.length&&r.length!==d&&n>=18&&r.length!==t.axes.length)throw new Error("Resize requires scales input size to be same as input rank or axes size for opset 18 and up");bo(r,t),t.axes.length>0&&vo(r,t.axes,d).forEach(((e,t)=>r[t]=e))}if(l>0&&e.length>l&&(e[l].getBigInt64Array().forEach((e=>i.push(Number(e)))),i.length!==d||n>=18&&i.length===t.axes.length))throw new Error("Resize requires sizes input size to be same as input rank or axes size for opset 18 and up");if(t.axes.length>0){if(r.length!==t.axes.length)throw new Error('Resize requires "scales" input size to be of axes rank when axes attributes is specified');if(i.length!==t.axes.length)throw new Error('Resize requires "sizes" input size to be of rank axes rank when axes attributes is specified')}if(typeof r<"u"&&typeof i<"u"&&r.length>0&&i.length>d)throw new Error("Resize requires only of scales or sizes to be specified")},Mo=(e,t)=>`fn getOriginalCoordinateFromResizedCoordinate(xResized: u32, xScale: f32, lengthResized: u32,\n     lengthOriginal: u32, roiStart: f32, roiEnd: f32) -> ${t} { `+(()=>{switch(e){case"asymmetric":return`return ${t}(xResized) / ${t}(xScale);`;case"pytorch_half_pixel":return`if (lengthResized > 1) {\n                    return (${t}(xResized) + 0.5) / ${t}(xScale) - 0.5;\n                  } else {\n                    return 0.0;\n                  }`;case"tf_half_pixel_for_nn":return`return (${t}(xResized) + 0.5) / ${t}(xScale);`;case"align_corners":return`if (lengthResized == 1) {\n                    return 0.0;\n                  } else {\n                    // The whole part and the fractional part are calculated separately due to inaccuracy of floating\n                    // point division. As an example, f32(21) / f32(7) may evaluate to 2.99... instead of 3, causing an\n                    // offset-by-one error later in floor().\n                    let whole = ${t}(xResized * (lengthOriginal - 1) / (lengthResized - 1));\n                    let fract =\n                        ${t}(xResized * (lengthOriginal - 1) % (lengthResized - 1)) / ${t}(lengthResized - 1);\n                    return whole + fract;\n                  }`;case"tf_crop_and_resize":return`if (lengthResized > 1) {\n                    return ${t}(roiStart) * ${t}(lengthOriginal - 1) +\n                        (${t}(xResized) * ${t}(roiEnd - roiStart) * ${t}(lengthOriginal - 1)) /\n                        ${t}(lengthResized - 1);\n                  } else {\n                    return 0.5 * ${t}(roiStart + roiEnd) * ${t}(lengthOriginal - 1);\n                  }`;case"half_pixel_symmetric":return`const outputWidth = ${t}xScale * ${t}(lengthResized);\n                  const adjustment = ${t}(lengthResized) / outputWidth;\n                  const center = ${t}(lengthOriginal) / 2;\n                  const offset = center * (1 - adjustment);\n                  return offset + ((${t}(xResized) + 0.5) / ${t}(xScale)) - 0.5;`;case"half_pixel":return`return ((${t}(xResized) + 0.5) / ${t}(xScale)) - 0.5;`;default:throw new Error(`Coordinate transform mode ${e} is not supported`)}})()+"}",To=(e,t,n)=>`fn getNearestPixelFromOriginal(xOriginal: ${n}, isDownSample: bool) -> ${n} {`+(()=>{switch(e){case"round_prefer_ceil":return"if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }";case"floor":return"return floor(xOriginal);";case"ceil":return"return ceil(xOriginal);";case"round_prefer_floor":return"if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }";default:if(t<11)return"if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }";throw new Error(`Nearest mode ${e} is not supported`)}})()+"}",ko=(e,t,n)=>{let r=new Array(n).fill(0).concat(new Array(n).fill(1)),i=0===e.length?r:e.slice();return t.length>0?(t.forEach(((e,s)=>{r[e]=i[s],r[s+n]=i[t.length+s]})),r):i},$o=(e,t,n,r)=>{let i=[];if(n.length>0)if(r.length>0){if(e.forEach((e=>i.push(e))),Math.max(...r)>e.length)throw new Error("axes is out of bound");r.forEach(((e,t)=>i[e]=n[t]))}else n.forEach((e=>i.push(e)));else{if(0===t.length)throw new Error("Resize requires either scales or sizes.");i=e.map(((e,n)=>Math.round(e*t[n])))}return i},So=(e,t,n)=>{let r=(()=>{switch(n.keepAspectRatioPolicy){case"not_larger":return n.axes.length>0?Math.min(...n.axes.map((e=>t[e])),Number.MAX_VALUE):Math.min(...t,Number.MAX_VALUE);case"not_smaller":return n.axes.length>0?Math.max(...n.axes.map((e=>t[e])),Number.MIN_VALUE):Math.max(...t,Number.MIN_VALUE);default:throw new Error(`Keep aspect ratio policy ${n.keepAspectRatioPolicy} is not supported`)}})();t.fill(1,0,t.length);let i=e.slice();return n.axes.length>0?(n.axes.forEach((e=>t[e]=r)),n.axes.forEach((n=>i[n]=Math.round(e[n]*t[n])))):(t.fill(r,0,t.length),i.forEach(((e,n)=>i[n]=Math.round(e*t[n])))),i},Co=(e,t,n,r,i)=>`\n    fn calculateOriginalIndicesFromOutputIndices(output_indices: ${e.type.indices}) -> array<${e.type.value}, ${n.length}> {\n      var original_indices: array<${e.type.value}, ${n.length}>;\n      for (var i:u32 = 0; i < ${n.length}; i++) {\n        var output_index = ${e.indicesGet("output_indices","i")};\n        var scale = ${bt("uniforms.scales","i",r)};\n        var roi_low = ${bt("uniforms.roi","i",i)};\n        var roi_hi = ${bt("uniforms.roi",`i + ${t.length}`,i)};\n        if (scale == 1.0) {\n          original_indices[i] = ${e.type.value}(output_index);\n        } else {\n          var input_shape_i = ${bt("uniforms.input_shape","i",t.length)};\n          var output_shape_i = ${bt("uniforms.output_shape","i",n.length)};\n          original_indices[i] = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                           input_shape_i, roi_low, roi_hi);\n        }\n      }\n      return original_indices;\n    }`,Po=(e,t,n,r,i,s,o)=>`\n    fn calculateInputIndicesFromOutputIndices(output_indices: ${t.type.indices}) -> ${e.type.indices} {\n      var input_indices: ${e.type.indices};\n      for (var i:u32 = 0; i < ${r.length}; i++) {\n        var output_index = ${t.indicesGet("output_indices","i")};\n        var input_index: u32;\n        var scale = ${bt("uniforms.scales","i",i)};\n        if (scale == 1.0) {\n          input_index = output_index;\n        } else {\n          var roi_low = ${bt("uniforms.roi","i",s)};\n          var roi_hi = ${bt("uniforms.roi",`i + ${n.length}`,s)};\n          var input_shape_i = ${bt("uniforms.input_shape","i",n.length)};\n          var output_shape_i = ${bt("uniforms.output_shape","i",r.length)};\n          var original_idx = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                        input_shape_i, roi_low, roi_hi);\n          if (!${o} || (original_idx >= 0 && original_idx < ${t.type.value}(input_shape_i))) {\n            if (original_idx < 0) {\n              input_index = 0;\n            } else if (original_idx > ${t.type.value}(input_shape_i - 1)) {\n              input_index = input_shape_i - 1;\n            } else {\n              input_index = u32(getNearestPixelFromOriginal(original_idx, scale < 1));\n            }\n          } else {\n            input_index = u32(original_idx);\n          }\n        }\n        ${e.indicesSet("input_indices","i"," input_index")}\n      }\n      return input_indices;\n    }`,Eo=(e,t)=>`\n    fn checkInputIndices(input_indices: ${e.type.indices}) -> bool {\n      for (var i:u32 = 0; i < ${t.length}; i++) {\n        var input_index = ${e.indicesGet("input_indices","i")};\n        if (input_index < 0 || input_index >= ${bt("uniforms.input_shape","i",t.length)}) {\n          return false;\n        }\n      }\n      return true;\n    }`,Ao=(e,t,n,r)=>e.rank>r?`\n    ${e.indicesSet("input_indices",t,"channel")};\n    ${e.indicesSet("input_indices",n,"batch")};\n`:"",Fo=(e,t,n,r,i)=>{let[s,o,a,l]=2===n.length?[-1,0,1,-1]:[0,2,3,1],d=e.type.value;return`\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> ${d} {\n      var input_indices: ${e.type.indices};\n      ${e.indicesSet("input_indices",o,`max(0, min(row, ${n[o]} - 1))`)};\n      ${e.indicesSet("input_indices",a,`max(0, min(col, ${n[a]} - 1))`)};\n      ${Ao(e,l,s,2)}\n      return ${e.getByIndices("input_indices")};\n    }\n\n    fn bilinearInterpolation(output_indices: ${t.type.indices}) -> ${d} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var row:${d} = originalIndices[${o}];\n      var col:${d} = originalIndices[${a}];\n      ${r?`if (row < 0 || row > (${n[o]} - 1) || col < 0 || col > (${n[a]} - 1)) {\n        return ${i};\n      }`:""};\n      row = max(0, min(row, ${n[o]} - 1));\n      col = max(0, min(col, ${n[a]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = ${n.length>2?`u32(originalIndices[${l}])`:"0"};\n      var batch: u32 =  ${n.length>2?`u32(originalIndices[${s}])`:"0"};\n      var x11: ${d} = getInputValue(batch, channel, row1, col1);\n      var x12: ${d} = getInputValue(batch, channel, row1, col2);\n      var x21: ${d} = getInputValue(batch, channel, row2, col1);\n      var x22: ${d} = getInputValue(batch, channel, row2, col2);\n      var dx1: ${d} = abs(row - ${d}(row1));\n      var dx2: ${d} = abs(${d}(row2) - row);\n      var dy1: ${d} = abs(col - ${d}(col1));\n      var dy2: ${d} = abs(${d}(col2) - col);\n      if (row1 == row2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (col1 == col2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`},Io=(e,t,n,r,i,s,o,a,l,d)=>{let u=2===n.length,[c,p]=u?[0,1]:[2,3],h=e.type.value,f=o=>{let u=o===c?"row":"col";return`\n      fn ${u}CubicInterpolation(input_indices: ${e.type.indices}, output_indices: ${t.type.indices}) -> ${h} {\n        var output_index = ${t.indicesGet("output_indices",o)};\n        var originalIdx: ${h} = getOriginalCoordinateFromResizedCoordinate(output_index, ${i[o]},\n        ${r[o]}, ${n[o]}, ${s[o]}, ${s[o]} + ${n.length});\n        var fractOriginalIdx: ${h} = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${a} && (originalIdx < 0 || originalIdx > (${n[o]} - 1))) {\n          return ${l};\n        }\n        var data: array<${h}, 4> = array<${h}, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${u}: ${h} = originalIdx + ${h}(i);\n          if (${u} < 0 || ${u} >= ${n[o]}) {\n            ${d?"coefs[i + 1] = 0.0;\n                        continue;":a?`return ${l};`:`${u} = max(0, min(${u}, ${n[o]} - 1));`};\n          }\n        var input_indices_copy: ${e.type.indices} = input_indices;\n          ${e.indicesSet("input_indices_copy",o,`u32(${u})`)};\n          data[i + 1] = ${o===c?e.getByIndices("input_indices_copy"):"rowCubicInterpolation(input_indices_copy, output_indices)"};\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`};return`\n    ${f(c)};\n    ${f(p)};\n  fn getCubicInterpolationCoefs(s: ${h}) -> array<${h}, 4> {\n    var absS = abs(s);\n    var coeffs: array<${h}, 4> = array<${h}, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: ${h} = 1.0 - absS;\n    var twoMinusAbsS: ${h} = 2.0 - absS;\n    var onePlusAbsS: ${h} = 1.0 + absS;\n    coeffs[0] = ((${o} * onePlusAbsS - 5 * ${o}) * onePlusAbsS + 8 * ${o}) * onePlusAbsS - 4 * ${o};\n    coeffs[1] = ((${o} + 2) * absS - (${o} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${o} + 2) * oneMinusAbsS - (${o} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${o} * twoMinusAbsS - 5 * ${o}) * twoMinusAbsS + 8 * ${o}) * twoMinusAbsS - 4 * ${o};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<${h}, 4>, coefs: array<${h}, 4>) -> ${h} {\n    var coefsSum: ${h} = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(output_indices: ${t.type.indices}) -> ${h} {\n    var input_indices: ${e.type.indices} = output_indices;\n    return colCubicInterpolation(input_indices, output_indices);\n  }\n    `},zo=(e,t,n,r,i)=>{let[s,o,a,l,d]=3===n.length?[-1,0,1,2,-1]:[0,2,3,4,1],u=e.type.value;return`\n    fn getInputValue(batch: u32, channel: u32, depth:u32, height: u32, width: u32) -> ${u} {\n      var input_indices: ${e.type.indices};\n      ${e.indicesSet("input_indices",o,`max(0, min(depth, ${n[o]} - 1))`)};\n      ${e.indicesSet("input_indices",a,`max(0, min(height, ${n[a]} - 1))`)};\n      ${e.indicesSet("input_indices",l,`max(0, min(width, ${n[l]} - 1))`)};\n      ${Ao(e,d,s,3)}\n      return ${e.getByIndices("input_indices")};\n    }\n\n    fn trilinearInterpolation(output_indices: ${t.type.indices}) -> ${u} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var depth:${u} = originalIndices[${o}];\n      var height:${u} = originalIndices[${a}];\n      var width:${u} = originalIndices[${l}];\n      ${r?`if (depth < 0 || depth > (${n[o]} - 1) || height < 0 || height > (${n[a]} - 1) || width < 0 || (width > ${n[l]} - 1)) {\n      return ${i};\n        }`:""};\n\n    depth = max(0, min(depth, ${n[o]} - 1));\n      height = max(0, min(height, ${n[a]} - 1));\n      width = max(0, min(width, ${n[l]} - 1));\n      var depth1: u32 = u32(depth);\n      var height1: u32 = u32(height);\n      var width1: u32 = u32(width);\n      var depth2: u32 = u32(depth + 1);\n      var height2: u32 = u32(height + 1);\n      var width2: u32 = u32(width + 1);\n      var channel: u32 = ${n.length>3?`u32(originalIndices[${d}])`:"0"};\n      var batch: u32 =  ${n.length>3?`u32(originalIndices[${s}])`:"0"};\n\n      var x111: ${u} = getInputValue(batch, channel, depth1, height1, width1);\n      var x112: ${u} = getInputValue(batch, channel, depth1, height1, width2);\n      var x121: ${u} = getInputValue(batch, channel, depth1, height2, width1);\n      var x122: ${u} = getInputValue(batch, channel, depth1, height2, width2);\n      var x211: ${u} = getInputValue(batch, channel, depth2, height1, width1);\n      var x212: ${u} = getInputValue(batch, channel, depth2, height1, width2);\n      var x221: ${u} = getInputValue(batch, channel, depth2, height2, width1);\n      var x222: ${u} = getInputValue(batch, channel, depth2, height2, width2);\n      var dx1: ${u} = abs(depth - ${u}(depth1));\n      var dx2: ${u} = abs(${u}(depth2) - depth);\n      var dy1: ${u} = abs(height - ${u}(height1));\n      var dy2: ${u} = abs(${u}(height2) - height);\n      var dz1: ${u} = abs(width - ${u}(width1));\n      var dz2: ${u} = abs(${u}(width2) - width);\n      if (depth1 == depth2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (height1 == height2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      if (width1 == width2) {\n        dz1 = 0.5;\n        dz2 = 0.5;\n      }\n      return (x111 * dx2 * dy2 * dz2 + x112 * dx2 * dy2 * dz1 + x121 * dx2 * dy1 *dz2 + x122 * dx2 * dy1 * dz1 +\n              x211 * dx1 * dy2 * dz2 + x212 * dx1 * dy2 * dz1 + x221 * dx1 * dy1 *dz2 + x222 * dx1 * dy1 * dz1);\n    }`},Bo=(e,t,n,r,i,s)=>{let o=e.dims,a=ko(s,t.axes,o.length),l=$o(o,r,i,t.axes),d=r.slice();0===r.length&&(d=o.map(((e,t)=>0===e?1:l[t]/e)),"stretch"!==t.keepAspectRatioPolicy&&(l=So(o,d,t)));let u=Mt("output",e.dataType,l.length),c=xt("input",e.dataType,o.length),p=ot.size(l),h=o.length===l.length&&o.every(((e,t)=>e===l[t])),f="tf_crop_and_resize"===t.coordinateTransformMode,m=t.extrapolationValue,g=c.type.value;return{name:"Resize",shaderCache:{hint:`${t.cacheKey}|${n}|${d.length>0?d:""}|${i.length>0?i:""}|${a.length>0?a:""}|${h}|${o}`,inputDependencies:["rank"]},getShaderSource:e=>`\n      ${h?"":`\n      ${Mo(t.coordinateTransformMode,g)};\n      ${(()=>{switch(t.mode){case"nearest":return`\n              ${Eo(c,o)};\n              ${To(t.nearestMode,n,g)};\n              ${Po(c,u,o,l,d.length,a.length,f)};\n              `;case"linear":return`\n              ${Co(u,o,l,d.length,a.length)};\n              ${(()=>{if(2===o.length||4===o.length)return`${Fo(c,u,o,f,m)}`;if(3===o.length||5===o.length)return`${zo(c,u,o,f,m)}`;throw Error("Linear mode only supports input dims 2, 3, 4 and 5 are supported in linear mode.")})()};\n            `;case"cubic":return`\n            ${(()=>{if(2===o.length||4===o.length)return`${Io(c,u,o,l,d,a,t.cubicCoeffA,f,t.extrapolationValue,t.excludeOutside)}`;throw Error("Cubic mode only supports input dims 2 and 4 are supported in linear mode.")})()};\n            `;default:throw Error("Invalid resize mode")}})()};\n      `}\n      ${e.registerUniform("output_size","u32").registerUniform("scales","f32",d.length).registerUniform("roi","f32",a.length).declareVariables(c,u)}\n      ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n        ${h?"output[global_idx] = input[global_idx];":`\n        let output_indices = ${u.offsetToIndices("global_idx")};\n        var input_indices: ${c.type.indices};\n        ${(()=>{switch(t.mode){case"nearest":return`input_indices = calculateInputIndicesFromOutputIndices(output_indices);\n                if (checkInputIndices(input_indices)) {\n                  output[global_idx] = ${c.getByIndices("input_indices")};\n                } else {\n                  output[global_idx] = ${t.extrapolationValue};\n                }`;case"linear":return`output[global_idx] = ${2===o.length||4===o.length?"bilinearInterpolation":"trilinearInterpolation"}(output_indices);`;case"cubic":return"output[global_idx] = bicubicInterpolation(output_indices);";default:throw Error(`Unsupported resize mode: ${t.mode}`)}})()};\n`}\n      }`,getRunData:()=>({outputs:[{dims:l,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(p/64)},programUniforms:[{type:12,data:p},{type:1,data:d},{type:1,data:a},...mt(o,l)]})}},Oo=e=>{let t=e.customDataBuffer;return new Uint32Array(t,t.byteOffset,1)[0]},Lo=(e,t)=>{let n=[],r=[],i=[],s=Oo(e);if(0!==t.antialias)throw Error("Only default value (0) for Antialias attribute is supported");xo(e.inputs,t,s,n,r,i),e.compute(Bo(e.inputs[0],t,s,n,r,i),{inputs:[0]})},Do=e=>{let t=e.antialias,n=e.axes,r=e.coordinateTransformMode,i=e.cubicCoeffA,s=0!==e.excludeOutside,o=e.extrapolationValue,a=e.keepAspectRatioPolicy,l=e.mode,d=""===e.nearestMode?"simple":e.nearestMode;return rt({antialias:t,axes:n,coordinateTransformMode:r,cubicCoeffA:i,excludeOutside:s,extrapolationValue:o,keepAspectRatioPolicy:a,mode:l,nearestMode:d})}})),Ml=V((()=>{Aa(),Da(),La(),Ra(),Ro=(e,t)=>{let[n,r,i,s]=e,{numHeads:o,rotaryEmbeddingDim:a}=t;if(3!==n.dims.length&&4!==n.dims.length)throw new Error(`Input 'x' is expected to have 3 or 4 dimensions, got ${n.dims.length}`);if(!ot.areEqual(r.dims,[])&&!ot.areEqual(r.dims,[1])&&2!==r.dims.length)throw new Error(`Input 'position_ids' is expected to have 0, 1, or 2 dimensions, got ${r.dims.length}`);if(2!==i.dims.length)throw new Error(`Input 'cos_cache' is expected to have 2 dimensions, got ${i.dims.length}`);if(2!==s.dims.length)throw new Error(`Input 'sin_cache' is expected to have 2 dimensions, got ${s.dims.length}`);if(!ot.areEqual(i.dims,s.dims))throw new Error("Inputs 'cos_cache' and 'sin_cache' are expected to have the same shape");if(a>0&&0===o)throw new Error("num_heads must be provided if rotary_embedding_dim is specified");let l=n.dims[0],d=n.dims[n.dims.length-2],u=i.dims[0],c=ot.sizeFromDimension(n.dims,1)/d,p=0===a?2*i.dims[1]:c/o;if(a>p)throw new Error("rotary_embedding_dim must be less than or equal to head_size");if(2===r.dims.length){if(l!==r.dims[0])throw new Error(`Input 'position_ids' dimension 0 should be of size batch_size, got ${r.dims[0]}`);if(d!==r.dims[1])throw new Error(`Input 'position_ids' dimension 1 should be of size sequence_length, got ${r.dims[1]}`)}if(p/2!==i.dims[1]&&a/2!==i.dims[1])throw new Error(`Input 'cos_cache' dimension 1 should be same as head_size / 2 or rotary_embedding_dim / 2, got ${i.dims[1]}`);if(d>u)throw new Error("Updating cos_cache and sin_cache in RotaryEmbedding is not currently supported")},No=(e,t)=>{let{interleaved:n,numHeads:r,rotaryEmbeddingDim:i,scale:s}=t,o=e[0].dims[0],a=ot.sizeFromDimension(e[0].dims,1),l=e[0].dims[e[0].dims.length-2],d=a/l,u=e[2].dims[1],c=0===i?2*u:d/r,p=new Array(o,l,d/c,c-u),h=ot.computeStrides(p),f=[{type:1,data:s},{type:12,data:p},{type:12,data:h},...3===e[0].dims.length?new Array({type:12,data:[a,d,c,1]}):[],...4===e[0].dims.length?new Array({type:12,data:[a,c,l*c,1]}):[],...mt(e[0].dims,e[1].dims,e[2].dims,e[3].dims,e[0].dims)];return{name:"RotaryEmbedding",shaderCache:{hint:rt({interleaved:n}).cacheKey,inputDependencies:["rank","rank","rank","rank"]},getShaderSource:t=>{let r=xt("input",e[0].dataType,e[0].dims.length),i=xt("position_ids",e[1].dataType,e[1].dims.length),s=xt("cos_cache",e[2].dataType,e[2].dims.length),o=xt("sin_cache",e[3].dataType,e[3].dims.length),a=Mt("output",e[0].dataType,e[0].dims.length);return t.registerUniforms([{name:"scale",type:"f32"},{name:"global_shape",type:"u32",length:p.length},{name:"global_strides",type:"u32",length:h.length},{name:"input_output_strides",type:"u32",length:h.length}]),`\n        ${t.declareVariables(r,i,s,o,a)}\n\n        ${t.mainStart(ct)}\n          let half_rotary_emb_dim = uniforms.${s.name}_shape[1];\n          let bsnh = global_idx / uniforms.global_strides % uniforms.global_shape;\n          let size = uniforms.global_shape[0] * uniforms.global_strides[0];\n          ${t.guardAgainstOutOfBoundsWorkgroupSizes("size")}\n\n          if (bsnh[3] < half_rotary_emb_dim) {\n            let position_ids_idx =\n                ${i.broadcastedIndicesToOffset("bsnh.xy",Mt("",i.type.tensor,2))};\n            let position_id =\n                u32(${i.getByOffset("position_ids_idx")}) + select(0, bsnh[1], position_ids_idx == 0);\n            let i = dot(bsnh, uniforms.input_output_strides) + select(0, bsnh[3], ${n});\n            let j = i + select(half_rotary_emb_dim, 1, ${n});\n            let re = ${r.getByOffset("i")} * ${s.get("position_id","bsnh[3]")} -\n                ${r.getByOffset("j")} * ${o.get("position_id","bsnh[3]")};\n            ${a.setByOffset("i","re")}\n            let im = ${r.getByOffset("i")} * ${o.get("position_id","bsnh[3]")} +\n                ${r.getByOffset("j")} * ${s.get("position_id","bsnh[3]")};\n            ${a.setByOffset("j","im")}\n          } else {\n            let k = dot(bsnh, uniforms.input_output_strides) + half_rotary_emb_dim;\n            ${a.setByOffset("k",r.getByOffset("k"))}\n          }\n        }`},getRunData:()=>({outputs:[{dims:e[0].dims,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(ot.size(p)/ct)},programUniforms:f})}},Vo=(e,t)=>{Ro(e.inputs,t),e.compute(No(e.inputs,t))}})),Tl=V((()=>{Aa(),Da(),Ra(),jo=e=>{if(!e||e.length<3)throw new Error("layerNorm requires at least 3 inputs.");let t=e[0],n=e[1],r=e[2];if(t.dataType!==n.dataType||t.dataType!==r.dataType)throw new Error("All inputs must have the same data type");if(3!==t.dims.length&&2!==t.dims.length)throw new Error("Input must be 2D or 3D");if(3!==n.dims.length&&2!==n.dims.length)throw new Error("Skip must be 2D or 3D");let i=t.dims[t.dims.length-1],s=t.dims[t.dims.length-2];if(n.dims[n.dims.length-1]!==i)throw new Error("Skip must have the same hidden size as input");if(n.dims[n.dims.length-2]!==s)throw new Error("Skip must have the same sequence length as input");if(1!==r.dims.length)throw new Error("Gamma must be 1D");if(r.dims[r.dims.length-1]!==i)throw new Error("Gamma must have the same hidden size as input");if(e.length>3){let t=e[3];if(1!==t.dims.length)throw new Error("Beta must be 1D");if(t.dims[t.dims.length-1]!==i)throw new Error("Beta must have the same hidden size as input")}if(e.length>4){let t=e[4];if(1!==t.dims.length)throw new Error("Bias must be 1D");if(t.dims[t.dims.length-1]!==i)throw new Error("Bias must have the same hidden size as input")}},Uo=(e,t,n,r)=>{let i=e[0].dims,s=ot.size(i),o=i,a=s,l=i.slice(-1)[0],d=r?i.slice(0,-1).concat(1):[],u=e.length>3,c=e.length>4,p=r&&n>1,h=r&&n>2,f=n>3,m=gt(l),g=[{type:12,data:a},{type:12,data:m},{type:12,data:l},{type:1,data:t.epsilon}],_=[{dims:o,dataType:e[0].dataType}];return n>1&&_.push({dims:d,dataType:1}),n>2&&_.push({dims:d,dataType:1}),n>3&&_.push({dims:i,dataType:e[0].dataType}),{name:"SkipLayerNormalization",shaderCache:{hint:`${m};${p};${h};${f}`,inputDependencies:e.map(((e,t)=>"type"))},getShaderSource:t=>{let n=[xt("x",e[0].dataType,e[0].dims,m),xt("skip",e[1].dataType,e[1].dims,m),xt("gamma",e[2].dataType,e[2].dims,m)];u&&n.push(xt("beta",e[3].dataType,e[3].dims,m)),c&&n.push(xt("bias",e[4].dataType,e[4].dims,m)),n.push(Mt("output",e[0].dataType,o,m)),p&&n.push(Mt("mean_output",1,d)),h&&n.push(Mt("inv_std_output",1,d)),f&&n.push(Mt("input_skip_bias_sum",e[0].dataType,o,m));let r=ht(e[0].dataType);return`\n\n      ${t.registerUniforms([{name:"output_size",type:"u32"},{name:"components",type:"u32"},{name:"hidden_size",type:"u32"},{name:"epsilon",type:"f32"}]).declareVariables(...n)}\n\n      ${t.mainStart()}\n        ${t.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size / uniforms.hidden_size")}\n        let hidden_size_vectorized: u32 = uniforms.hidden_size / uniforms.components;\n        let offset = global_idx * hidden_size_vectorized;\n        var sum = ${_t("f32",m)};\n        var squareSum = ${_t("f32",m)};\n        for (var i: u32 = 0; i < hidden_size_vectorized; i++) {\n          let skip_value = skip[offset + i];\n          let bias_value = ${c?"bias[i]":"0.0"};\n          let input_value = x[offset + i];\n          let value = input_value + skip_value + bias_value;\n          ${f?"input_skip_bias_sum[offset + i] = value;":""}\n          output[offset + i] = value;\n          let f32_value = ${wt(r,m,"value")};\n          sum += f32_value;\n          squareSum += f32_value * f32_value;\n        }\n        let mean = ${yt("sum",m)} / f32(uniforms.hidden_size);\n        let inv_std_dev = inverseSqrt(${yt("squareSum",m)} / f32(uniforms.hidden_size) - mean * mean + uniforms.epsilon);\n        ${p?"mean_output[global_idx] = mean;":""}\n        ${h?"inv_std_output[global_idx] = inv_std_dev;":""}\n        for (var i: u32 = 0; i < hidden_size_vectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${r}(mean)) * ${r}(inv_std_dev) * gamma[i] + ${u?"beta[i]":"0.0"};\n        }\n      }`},getRunData:()=>({outputs:_,dispatchGroup:{x:Math.ceil(a/l/64)},programUniforms:g})}},Go=(e,t)=>{jo(e.inputs);let n=[0];e.outputCount>1&&n.push(-3),e.outputCount>2&&n.push(-3),e.outputCount>3&&n.push(3),e.compute(Uo(e.inputs,t,e.outputCount,!1),{outputs:n})}})),kl=V((()=>{Aa(),Da(),La(),Ra(),qo=(e,t)=>{if(!e||e.length<1)throw new Error("too few inputs");if(0!==t.axes.length){if(t.axes.length!==t.starts.length||t.axes.length!==t.ends.length)throw new Error("axes, starts and ends must have the same length")}else if(t.starts.length!==t.ends.length)throw new Error("starts and ends must have the same length");e.slice(1).forEach(((t,n)=>{if(6!==e[n+1].dataType&&7!==e[n+1].dataType)throw new Error(`Input ${n} must be an array of int32 or int64`)}))},Wo=(e,t)=>{let n=[];if(e.length>t)if(7===e[t].dataType)e[t].getBigInt64Array().forEach((e=>n.push(Number(e))));else{if(6!==e[t].dataType)throw new Error(`Input ${t} must be an array of int32 or int64`);e[t].getInt32Array().forEach((e=>n.push(Number(e))))}return n},Ho=(e,t)=>{if(e.length>1){let t=Wo(e,1),n=Wo(e,2),r=Wo(e,3);return 0===r.length&&(r=[...Array(e[0].dims.length).keys()]),rt({starts:t,ends:n,axes:r})}return t},Xo=(e,t,n,r,i)=>{let s=e;return e<0&&(s+=n[r[t]]),i[t]<0?Math.max(0,Math.min(s,n[r[t]]-1)):Math.max(0,Math.min(s,n[r[t]]))},Qo=(e,t,n)=>`fn calculateInputIndices(output_indices: ${t.type.indices}) -> ${e.type.indices} {\n          var input_indices: ${e.type.indices};\n          var carry = 0u;\n          for (var i = ${n.length}; i >= 0; i--) {\n            let input_shape_i = ${bt("uniforms.input_shape","i",n.length)};\n            let steps_i = ${bt("uniforms.steps","i",n.length)};\n            let signs_i = ${bt("uniforms.signs","i",n.length)};\n            let starts_i = ${bt("uniforms.starts","i",n.length)};\n            var output_index = ${t.indicesGet("output_indices","i")};\n            var input_index = output_index * steps_i + starts_i + carry;\n            carry = input_index / input_shape_i;\n            input_index = input_index % input_shape_i;\n            if (signs_i < 0) {\n              input_index = input_shape_i - input_index - 1u + starts_i;\n            }\n            ${e.indicesSet("input_indices","i","input_index")};\n          }\n          return input_indices;\n      }`,Ko=(e,t)=>{let n=e[0].dims,r=ot.size(n),i=t.axes.length>0?ot.normalizeAxes(t.axes,n.length):[...Array(n.length).keys()],s=Wo(e,4);s.forEach((e=>0!==e||(()=>{throw new Error("step cannot be 0")}))),0===s.length&&(s=Array(i.length).fill(1));let o=t.starts.map(((e,t)=>Xo(e,t,n,i,s))),a=t.ends.map(((e,t)=>Xo(e,t,n,i,s)));if(i.length!==o.length||i.length!==a.length)throw new Error("start, ends and axes should have the same number of elements");if(i.length!==n.length)for(let e=0;e<n.length;++e)i.includes(e)||(o.splice(e,0,0),a.splice(e,0,n[e]),s.splice(e,0,1));let l=s.map((e=>Math.sign(e)));s.forEach(((e,t,n)=>{if(e<0){let r=(a[t]-o[t])/e,i=o[t],l=i+r*s[t];o[t]=l,a[t]=i,n[t]=-e}}));let d=n.slice(0);i.forEach(((e,t)=>{d[e]=Math.ceil((a[e]-o[e])/s[e])}));let u={dims:d,dataType:e[0].dataType},c=Mt("output",e[0].dataType,d.length),p=xt("input",e[0].dataType,e[0].dims.length),h=ot.size(d),f=[{name:"outputSize",type:"u32"},{name:"starts",type:"u32",length:o.length},{name:"signs",type:"i32",length:l.length},{name:"steps",type:"u32",length:s.length}],m=[{type:12,data:h},{type:12,data:o},{type:6,data:l},{type:12,data:s},...mt(e[0].dims,d)];return{name:"Slice",shaderCache:{hint:`${l.length}_${o.length}_${s.length}`,inputDependencies:["rank"]},getShaderSource:e=>`\n      ${e.registerUniforms(f).declareVariables(p,c)}\n        ${Qo(p,c,n)}\n        ${e.mainStart()}\n          ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n          let output_indices = ${c.offsetToIndices("global_idx")};\n          let input_indices = calculateInputIndices(output_indices);\n          ${c.setByOffset("global_idx",p.getByIndices("input_indices"))}\n      }`,getRunData:()=>({outputs:[u],dispatchGroup:{x:Math.ceil(r/64)},programUniforms:m})}},Yo=(e,t)=>{qo(e.inputs,t);let n=Ho(e.inputs,t);e.compute(Ko(e.inputs,n),{inputs:[0]})},Zo=e=>{let t=e.starts,n=e.ends,r=e.axes;return rt({starts:t,ends:n,axes:r})}})),$l=V((()=>{Aa(),Da(),La(),Ra(),Jo=e=>{if(!e||1!==e.length)throw new Error("Softmax op requires 1 input.")},ea=(e,t)=>{let n=e.dims,r=ot.size(n),i=t.axis;if(i<0&&(i=n.length+i),i<n.length-1)throw new Error("softmax only supports last axis for now.");let s=n[i],o=r/s,a=gt(s),l=s/a,d=xt("x",e.dataType,e.dims,a),u=Mt("result",e.dataType,e.dims,a),c=d.type.value,p="f32"===ht(e.dataType)?`var threadMax = ${c}(-3.402823e+38f);`:`var threadMax = ${c}(-65504.0h);`;return{name:"Softmax",shaderCache:{hint:`${a}`,inputDependencies:["type"]},getRunData:()=>({outputs:[{dims:n,dataType:e.dataType}],dispatchGroup:{x:o},programUniforms:[{type:6,data:l}]}),getShaderSource:e=>`\n      var<workgroup> rowMaxShared : ${c};\n      var<workgroup> rowSumShared : ${c};\n      var<workgroup> threadShared : array<${c}, 64>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${c} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${c}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${e.registerUniform("packedCols","i32").declareVariables(d,u)}\n      ${e.mainStart()}\n        let gindex = i32(global_idx);\n        let lindex = i32(local_idx);\n        const wg = 64;\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${p}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${c}(${((e,t)=>4===t?`max(max(${e}.x, ${e}.y), max(${e}.z, ${e}.w))`:2===t?`max(${e}.x, ${e}.y)`:3===t?`max(max(${e}.x, ${e}.y), ${e}.z)`:e)("threadShared[0]",a)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${c}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${c}(${yt("threadShared[0]",a)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`}},ta=(e,t)=>{Jo(e.inputs),e.compute(ea(e.inputs[0],t))},na=e=>rt({axis:e.axis})})),Sl=V((()=>{Aa(),Da(),La(),Ra(),ra=e=>{if(!e||e.length<1)throw new Error("too few inputs")},ia=(e,t)=>{let n=[],r=t.numOutputs;return e[1].dims[0]>0&&(e[1].getBigInt64Array().forEach((e=>n.push(Number(e)))),r=n.length),rt({numOutputs:r,axis:t.axis,splitSizes:n})},sa=e=>`\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n    if (index < ${bt("uniforms.size_in_split_axis","i",e)}) {\n        return i;\n    }\n    }\n    return ${e}u;\n}`,oa=e=>{let t=e.length,n=[];for(let r=0;r<t;++r){let i=e[r].setByIndices("indices","input[global_idx]");1===t?n.push(i):0===r?n.push(`if (output_number == ${r}u) { ${i} }`):r===t-1?n.push(`else { ${i} }`):n.push(`else if (output_number == ${r}) { ${i} }`)}return`\n      fn writeBufferData(output_number: u32, indices: ${e[0].type.indices}, global_idx: u32) {\n        ${n.join("\n")}\n      }`},aa=(e,t)=>{let n=e[0].dims,r=ot.size(n),i=e[0].dataType,s=ot.normalizeAxis(t.axis,n.length),o=new Array(t.numOutputs),a=xt("input",i,n.length),l=new Array(t.numOutputs),d=[],u=[],c=0,p=[{type:12,data:r}];for(let r=0;r<t.numOutputs;r++){c+=t.splitSizes[r],l[r]=c;let s=n.slice();s[t.axis]=t.splitSizes[r],u.push(s),o[r]=Mt(`output${r}`,i,s.length),d.push({dims:u[r],dataType:e[0].dataType})}p.push({type:12,data:l},...mt(n,...u));return{name:"Split",shaderCache:{hint:t.cacheKey,inputDependencies:["rank"]},getShaderSource:e=>`\n  ${e.registerUniform("input_size","u32").registerUniform("size_in_split_axis","u32",l.length).declareVariables(a,...o)}\n  ${sa(l.length)}\n  ${oa(o)}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.input_size")}\n\n    var indices = ${a.offsetToIndices("global_idx")};\n    var index = ${a.indicesGet("indices",s)};\n    let output_number = calculateOutputIndex(index);\n    if (output_number != 0) {\n      index -= ${bt("uniforms.size_in_split_axis","output_number - 1u",l.length)};\n      ${a.indicesSet("indices",s,"index")};\n    }\n    writeBufferData(output_number, indices, global_idx);\n  }`,getRunData:()=>({outputs:d,dispatchGroup:{x:Math.ceil(r/64)},programUniforms:p})}},la=(e,t)=>{ra(e.inputs);let n=1===e.inputs.length?t:ia(e.inputs,t);e.compute(aa(e.inputs,n),{inputs:[0]})},da=e=>{let t=e.axis,n=e.splitSizes,r=e.numOutputs<0?n.length:e.numOutputs;if(r!==n.length)throw new Error("numOutputs and splitSizes lengh must be equal");return rt({axis:t,numOutputs:r,splitSizes:n})}})),Cl=V((()=>{Aa(),Da(),Ra(),ua=e=>Array.from(e.getBigInt64Array(),Number),ca=e=>{if(!e||2!==e.length)throw new Error("Tile requires 2 inputs.");if(1!==e[0].dataType&&6!==e[0].dataType&&12!==e[0].dataType)throw new Error("Tile only support float, int32, and uint32 data types");if(7!==e[1].dataType)throw new Error("Tile `repeats` input should be of int64 data type");if(1!==e[1].dims.length)throw new Error("Tile `repeats` input should be 1-D");if(ua(e[1]).length!==e[0].dims.length)throw new Error("Tile `repeats` input should have same number of elements as rank of input data tensor")},pa=(e,t)=>{let n=[];for(let r=0;r<e.length;++r)n.push(e[r]*t[r]);return n},ha=e=>{let t=e[0].dims,n=ua(e[1]),r=pa(t,n),i=ot.size(r),s=e[0].dataType,o=xt("input",s,t.length),a=Mt("output",s,r.length);return{name:"Tile",shaderCache:{hint:`${n}`,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(i/64)},programUniforms:[{type:12,data:i},...mt(e[0].dims,r)]}),getShaderSource:e=>`\n      const inputShape = ${o.indices(...t)};\n      ${e.registerUniform("output_size","u32").declareVariables(o,a)}\n      ${e.mainStart()}\n      ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n      let output_indices = ${a.offsetToIndices("global_idx")};\n      var input_indices: ${o.type.indices};\n      for (var i = 0; i < ${t.length}; i++) {\n        let input_dim_i = ${o.indicesGet("uniforms.input_shape","i")};\n        let input_dim_value = ${a.indicesGet("output_indices","i")}  % input_dim_i;\n\n        ${o.indicesSet("input_indices","i","input_dim_value")}\n      }\n      ${a.setByOffset("global_idx",o.getByIndices("input_indices"))}\n    }`}},fa=e=>{ca(e.inputs),e.compute(ha(e.inputs),{inputs:[0]})}})),Pl=V((()=>{Aa(),Da(),Ra(),ma=(e,t,n,r,i)=>{let s,o=Mt("output_data",i,n.length,4),a=xt("a_data",t[1].dataType,t[1].dims.length,4),l=xt("b_data",t[2].dataType,t[2].dims.length,4),d=xt("c_data",t[0].dataType,t[0].dims.length,4),u=(e,t,n)=>`select(${t}, ${e}, ${n})`;if(r){let e=(e,t,n="")=>{let r=`a_data[index_a${t}][component_a${t}]`,i=`b_data[index_b${t}][component_b${t}]`,s=`bool(c_data[index_c${t}] & (0xffu << (component_c${t} * 8)))`;return`\n            let output_indices${t} = ${o.offsetToIndices(`global_idx * 4u + ${t}u`)};\n            let offset_a${t} = ${a.broadcastedIndicesToOffset(`output_indices${t}`,o)};\n            let offset_b${t} = ${l.broadcastedIndicesToOffset(`output_indices${t}`,o)};\n            let offset_c${t} = ${d.broadcastedIndicesToOffset(`output_indices${t}`,o)};\n            let index_a${t} = offset_a${t} / 4u;\n            let index_b${t} = offset_b${t} / 4u;\n            let index_c${t} = offset_c${t} / 4u;\n            let component_a${t} = offset_a${t} % 4u;\n            let component_b${t} = offset_b${t} % 4u;\n            let component_c${t} = offset_c${t} % 4u;\n            ${e}[${t}] = ${n}(${u(r,i,s)});\n          `};s=9===i?`\n            var data = vec4<u32>(0);\n            ${e("data",0,"u32")}\n            ${e("data",1,"u32")}\n            ${e("data",2,"u32")}\n            ${e("data",3,"u32")}\n            output_data[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:`\n            ${e("output_data[global_idx]",0)}\n            ${e("output_data[global_idx]",1)}\n            ${e("output_data[global_idx]",2)}\n            ${e("output_data[global_idx]",3)}\n          `}else s=o.setByOffset("global_idx",u(a.getByOffset("global_idx"),l.getByOffset("global_idx"),d.getByOffset("global_idx")));return`\n        ${e.registerUniform("vec_size","u32").declareVariables(d,a,l,o)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}\n        ${s}\n      }`},ga=e=>{let t=e[1].dims,n=e[2].dims,r=e[0].dims,i=e[1].dataType,s=!(ot.areEqual(t,n)&&ot.areEqual(n,r)),o=t,a=ot.size(t);if(s){let e=st.calcShape(st.calcShape(t,n,!1),r,!1);if(!e)throw new Error("Can't perform where op on the given tensors");o=e,a=ot.size(o)}let l=Math.ceil(a/4);return{name:"Where",shaderCache:{inputDependencies:["rank","rank","rank"]},getShaderSource:t=>ma(t,e,o,s,i),getRunData:()=>({outputs:[{dims:o,dataType:i}],dispatchGroup:{x:Math.ceil(a/64/4)},programUniforms:[{type:12,data:l},...mt(r,t,n,o)]})}},_a=e=>{e.compute(ga(e.inputs))}})),El=V((()=>{Ua(),Ga(),qa(),Wa(),Xa(),Qa(),Ka(),il(),al(),ll(),dl(),ul(),cl(),pl(),hl(),fl(),ml(),gl(),rl(),_l(),wl(),yl(),bl(),vl(),ja(),xl(),Ml(),Tl(),kl(),$l(),Sl(),Cl(),Na(),Ha(),Pl(),wa=new Map([["Abs",[Qn]],["Acos",[Kn]],["Acosh",[Yn]],["Add",[Vr]],["ArgMax",[An,Fn]],["ArgMin",[En,Fn]],["Asin",[Zn]],["Asinh",[Jn]],["Atan",[er]],["Atanh",[tr]],["Attention",[Rn]],["AveragePool",[ao,oo]],["BatchNormalization",[Un]],["BiasAdd",[Wn]],["BiasSplitGelu",[Lr]],["Cast",[rr,nr]],["Ceil",[or]],["Clip",[sr]],["Concat",[ti,ni]],["Conv",[Fi,Pi]],["ConvTranspose",[Wi,Vi]],["Cos",[ar]],["Cosh",[lr]],["CumSum",[Xi,Qi]],["Div",[jr]],["Einsum",[is,ss]],["Elu",[ur,dr]],["Equal",[Ur]],["Erf",[pr]],["Exp",[hr]],["Expand",[us]],["FastGelu",[ps]],["Floor",[fr]],["FusedConv",[Fi,Pi]],["Gather",[gs,ms]],["GatherElements",[bs,ys]],["Gelu",[mr]],["Gemm",[Ts,Ms]],["GlobalAveragePool",[co,uo]],["GlobalMaxPool",[go,mo]],["Greater",[Hr]],["GreaterOrEqual",[Qr]],["HardSigmoid",[Mr,xr]],["InstanceNormalization",[Cs]],["LayerNormalization",[As]],["LeakyRelu",[gr,dr]],["Less",[Xr]],["LessOrEqual",[Kr]],["Log",[zr]],["MatMul",[Ti]],["MatMulNBits",[zs,Bs]],["MaxPool",[ho,fo]],["Mul",[Gr]],["MultiHeadAttention",[Vs,Ls]],["Neg",[wr]],["Not",[_r]],["Pad",[Ks]],["Pow",[qr]],["Range",[yo]],["Reciprocal",[yr]],["ReduceMin",[Tn]],["ReduceMean",[yn]],["ReduceMax",[Mn]],["ReduceSum",[$n]],["ReduceProd",[kn]],["ReduceL1",[bn]],["ReduceL2",[vn]],["ReduceLogSum",[Cn]],["ReduceLogSumExp",[xn]],["ReduceSumSquare",[Sn]],["Relu",[br]],["Resize",[Lo,Do]],["RotaryEmbedding",[Vo]],["Sigmoid",[vr]],["Sin",[Tr]],["Sinh",[kr]],["Slice",[Yo,Zo]],["SkipLayerNormalization",[Go]],["Split",[la,da]],["Sqrt",[$r]],["Softmax",[ta,na]],["Sub",[Wr]],["Tan",[Sr]],["Tanh",[Pr]],["ThresholdedRelu",[Ir,dr]],["Tile",[fa]],["Transpose",[It,zt]],["Where",[_a]]])})),Al=V((()=>{Ta(),Ia(),Ra(),ya=class{constructor(e){this.backend=e,this.repo=new Map,this.attributesBound=!1}getArtifact(e){return this.repo.get(e)}setArtifact(e,t){this.repo.set(e,t)}run(e,t,n,r,i){E(e.programInfo.name);let s=this.backend.device,o=this.backend.getComputePassEncoder();this.backend.writeTimestamp(2*this.backend.pendingDispatchNumber);let a=[];for(let e of t)a.push({binding:a.length,resource:{buffer:e.buffer}});for(let e of n)a.push({binding:a.length,resource:{buffer:e.buffer}});i&&a.push({binding:a.length,resource:i});let l=s.createBindGroup({layout:e.computePipeline.getBindGroupLayout(0),entries:a,label:e.programInfo.name});if("capturing"===this.backend.sessionStatus){let t={kernelId:this.backend.currentKernelId,computePipeline:e.computePipeline,bindGroup:l,dispatchGroup:r};this.backend.capturedCommandList.get(this.backend.currentSessionId).push(t)}o.setPipeline(e.computePipeline),o.setBindGroup(0,l),o.dispatchWorkgroups(...r),this.backend.writeTimestamp(2*this.backend.pendingDispatchNumber+1),this.backend.pendingDispatchNumber++,(this.backend.pendingDispatchNumber>=this.backend.maxDispatchNumber||"at-passes"===this.backend.queryType)&&this.backend.endComputePass(),this.backend.pendingDispatchNumber>=this.backend.maxDispatchNumber&&this.backend.flush(),A(e.programInfo.name)}dispose(){}build(e,t){E(e.name);let n=this.backend.device,r=[];n.features.has("shader-f16")&&r.push("enable f16;");let i=$t(t,this.backend.device.limits),s=e.getShaderSource(i),o=`${r.join("\n")}\n${i.additionalImplementations}\n${s}`,a=n.createShaderModule({code:o,label:e.name});Xe("verbose",(()=>`[WebGPU] ${e.name} shader code: ${o}`));let l=n.createComputePipeline({compute:{module:a,entryPoint:"main"},layout:"auto",label:e.name});return A(e.name),{programInfo:e,computePipeline:l,uniformVariablesInfo:i.variablesInfo}}normalizeDispatchGroupSize(e){let t="number"==typeof e?e:e.x,n="number"==typeof e?1:e.y||1,r="number"==typeof e?1:e.z||1,i=this.backend.device.limits.maxComputeWorkgroupsPerDimension;if(t<=i&&n<=i&&r<=i)return[t,n,r];let s=t*n*r,o=Math.ceil(Math.sqrt(s));if(o>i){if(o=Math.ceil(Math.cbrt(s)),o>i)throw new Error("Total dispatch size exceeds WebGPU maximum.");return[o,o,o]}return[o,o,1]}}})),Fl=V((()=>{Ta(),Aa(),Ia(),za(),Oa(),El(),Al(),ba=(e,t)=>{if(t.length!==e.length)throw new Error(`inputDependencies length ${t.length} is not equal to inputTensors length ${e.length}.`);let n=[];for(let r=0;r<e.length;++r){let i=e[r].dataType;switch(t[r]){case"none":n.push("");break;case"type":n.push(`${i}`);break;case"rank":{let t=e[r].dims.length;n.push(`${i};${t}`);break}case"dims":{let t=e[r].dims.join(",");n.push(`${i};${t}`);break}default:throw new Error(`unsupported input dependency: ${t[r]}`)}}return n.join("|")},va=(e,t,n)=>{let r=e.name;return e.shaderCache?.hint&&(r+="["+e.shaderCache.hint+"]"),r+=":"+n+`:${ba(t,e.shaderCache?.inputDependencies??new Array(t.length).fill("dims"))}`,r},xa=class{constructor(e){e&&(this.architecture=e.architecture,this.vendor=e.vendor)}isArchitecture(e){return this.architecture===e}isVendor(e){return this.vendor===e}},Ma=class{constructor(){this.currentSessionId=null,this.currentKernelId=null,this.commandEncoder=null,this.computePassEncoder=null,this.maxDispatchNumber=16,this.pendingDispatchNumber=0,this.pendingKernels=[],this.pendingQueries=new Map,this.sessionStatus="default",this.capturedCommandList=new Map,this.capturedPendingKernels=new Map,this.sessionExternalDataMapping=new Map}get currentKernelCustomData(){if(null===this.currentKernelId)throw new Error("currentKernelCustomData(): currentKernelId is null. (should not happen)");let e=this.kernelCustomData.get(this.currentKernelId);return e||(e={},this.kernelCustomData.set(this.currentKernelId,e)),e}async initialize(e,t){this.env=e;let n=[],r={requiredLimits:{maxComputeWorkgroupStorageSize:t.limits.maxComputeWorkgroupStorageSize,maxComputeWorkgroupsPerDimension:t.limits.maxComputeWorkgroupsPerDimension,maxStorageBufferBindingSize:t.limits.maxStorageBufferBindingSize,maxBufferSize:t.limits.maxBufferSize,maxComputeInvocationsPerWorkgroup:t.limits.maxComputeInvocationsPerWorkgroup,maxComputeWorkgroupSizeX:t.limits.maxComputeWorkgroupSizeX,maxComputeWorkgroupSizeY:t.limits.maxComputeWorkgroupSizeY,maxComputeWorkgroupSizeZ:t.limits.maxComputeWorkgroupSizeZ},requiredFeatures:n};t.features.has("chromium-experimental-timestamp-query-inside-passes")?n.push("chromium-experimental-timestamp-query-inside-passes"):t.features.has("timestamp-query")&&n.push("timestamp-query"),t.features.has("shader-f16")&&n.push("shader-f16"),this.device=await t.requestDevice(r),this.adapterInfo=new xa(await t.requestAdapterInfo()),this.gpuDataManager=tt(this),this.programManager=new ya(this),this.kernels=new Map,this.kernelPersistentData=new Map,this.kernelCustomData=new Map,We(e.logLevel,!!e.debug),this.device.onuncapturederror=e=>{e.error instanceof GPUValidationError&&console.error(`An uncaught WebGPU validation error was raised: ${e.error.message}`)},Object.defineProperty(this.env.webgpu,"device",{value:this.device,writable:!1,enumerable:!0,configurable:!1}),Object.defineProperty(this.env.webgpu,"adapter",{value:t,writable:!1,enumerable:!0,configurable:!1}),this.setQueryType()}dispose(){typeof this.querySet<"u"&&this.querySet.destroy(),this.gpuDataManager.dispose()}getCommandEncoder(){return this.commandEncoder||(this.commandEncoder=this.device.createCommandEncoder()),this.commandEncoder}getComputePassEncoder(){if(!this.computePassEncoder){let e=this.getCommandEncoder(),t={};"at-passes"===this.queryType&&(t.timestampWrites={querySet:this.querySet,beginningOfPassWriteIndex:2*this.pendingDispatchNumber,endOfPassWriteIndex:2*this.pendingDispatchNumber+1}),this.computePassEncoder=e.beginComputePass(t)}return this.computePassEncoder}endComputePass(){this.computePassEncoder&&(this.computePassEncoder.end(),this.computePassEncoder=null)}flush(){if(!this.commandEncoder)return;let e;E(),this.endComputePass(),"none"!==this.queryType&&(this.commandEncoder.resolveQuerySet(this.querySet,0,2*this.pendingDispatchNumber,this.queryResolveBuffer,0),e=this.device.createBuffer({size:2*this.pendingDispatchNumber*8,usage:GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST}),this.pendingQueries.set(e,this.pendingKernels),this.pendingKernels=[],this.commandEncoder.copyBufferToBuffer(this.queryResolveBuffer,0,e,0,2*this.pendingDispatchNumber*8)),this.device.queue.submit([this.commandEncoder.finish()]),this.gpuDataManager.refreshPendingBuffers(),this.commandEncoder=null,this.pendingDispatchNumber=0,"none"!==this.queryType&&e.mapAsync(GPUMapMode.READ).then((()=>{let t=new BigUint64Array(e.getMappedRange()),n=this.pendingQueries.get(e);for(let e=0;e<t.length/2;e++){let r=n[e],i=r.kernelId,s=this.kernels.get(i),o=s.kernelType,a=s.kernelName,l=r.programName,d=r.inputTensorViews,u=r.outputTensorViews,c=t[2*e],p=t[2*e+1];typeof this.queryTimeBase>"u"&&(this.queryTimeBase=c);let h=Number(c-this.queryTimeBase),f=Number(p-this.queryTimeBase);if(!Number.isSafeInteger(h)||!Number.isSafeInteger(f))throw new RangeError("incorrect timestamp range");if(this.env.webgpu.profiling?.ondata)this.env.webgpu.profiling.ondata({version:1,inputsMetadata:d.map((e=>({dims:e.dims,dataType:Be(e.dataType)}))),outputsMetadata:u.map((e=>({dims:e.dims,dataType:Be(e.dataType)}))),kernelId:i,kernelType:o,kernelName:a,programName:l,startTime:h,endTime:f});else{let e="";d.forEach(((t,n)=>{e+=`input[${n}]: [${t.dims}] | ${Be(t.dataType)}, `}));let t="";u.forEach(((e,n)=>{t+=`output[${n}]: [${e.dims}] | ${Be(e.dataType)}, `})),console.log(`[profiling] kernel "${i}|${o}|${a}|${l}" ${e}${t}execution time: ${f-h} ns`)}C("GPU",`${l}::${c}::${p}`)}e.unmap(),this.pendingQueries.delete(e)})),A()}run(e,t,n,r,i){E(e.name);let s=[];for(let e=0;e<t.length;++e){let n=t[e].data;if(0===n)continue;let r=this.gpuDataManager.get(n);if(!r)throw new Error(`no GPU data for input: ${n}`);s.push(r)}let{outputs:o,dispatchGroup:a,programUniforms:l}=e.getRunData(t),d=0===n.length?o.map(((e,t)=>t)):n;if(d.length!==o.length)throw new Error(`Output size ${d.length} must be equal to ${o.length}.`);let u,c=[],p=[];for(let e=0;e<o.length;++e){if(!Number.isInteger(d[e])||d[e]<-3||d[e]>=o.length)throw new Error(`Invalid output index: ${d[e]}`);if(-3===d[e])continue;let t=-1===d[e],n=-2===d[e],s=t||n?i(o[e].dataType,o[e].dims):r(d[e],o[e].dataType,o[e].dims);if(c.push(s),0===s.data)continue;let a=this.gpuDataManager.get(s.data);if(!a)throw new Error(`no GPU data for output: ${s.data}`);if(t&&this.temporaryData.push(a),n){let e=this.kernelPersistentData.get(this.currentKernelId);e||(e=[],this.kernelPersistentData.set(this.currentKernelId,e)),e.push(a)}p.push(a)}if(s.length!==t.length||p.length!==c.length){if(0===p.length)return A(e.name),c;throw new Error(`Program ${e.name} has zero-sized tensor(s) in inputs or outputs. This is not supported now.`)}if(l){let e=0,t=[];l.forEach((n=>{let r="number"==typeof n.data?[n.data]:n.data;if(0===r.length)return;let i,s,o=10===n.type?2:4;10===n.type?(s=r.length>4?16:r.length>2?8:r.length*o,i=r.length>4?16:o*r.length):(s=r.length<=2?r.length*o:16,i=16),e=Math.ceil(e/s)*s,t.push(e);let a=10===n.type?8:4;e+=r.length>4?Math.ceil(r.length/a)*i:r.length*o}));let n=16;e=Math.ceil(e/n)*n;let r=new ArrayBuffer(e);l.forEach(((e,n)=>{let i=t[n],s="number"==typeof e.data?[e.data]:e.data;if(6===e.type)new Int32Array(r,i,s.length).set(s);else if(12===e.type)new Uint32Array(r,i,s.length).set(s);else if(10===e.type)new Uint16Array(r,i,s.length).set(s);else{if(1!==e.type)throw new Error(`Unsupported uniform type: ${Be(e.type)}`);new Float32Array(r,i,s.length).set(s)}}));let i=this.gpuDataManager.create(e,GPUBufferUsage.COPY_DST|GPUBufferUsage.UNIFORM);this.device.queue.writeBuffer(i.buffer,0,r,0,e),this.gpuDataManager.release(i.id),u={offset:0,size:e,buffer:i.buffer}}let h=this.programManager.normalizeDispatchGroupSize(a),f=1===h[1]&&1===h[2],m=va(e,t,f),g=this.programManager.getArtifact(m);if(g||(g=this.programManager.build(e,h),this.programManager.setArtifact(m,g),Xe("info",(()=>`[artifact] key: ${m}, programName: ${e.name}`))),l&&g.uniformVariablesInfo){if(l.length!==g.uniformVariablesInfo.length)throw new Error(`Uniform variables count mismatch: expect ${g.uniformVariablesInfo.length}, got ${l.length} in program "${g.programInfo.name}".`);for(let e=0;e<l.length;e++){let t=l[e],n=t.type,r="number"==typeof t.data?1:t.data.length,[i,s]=g.uniformVariablesInfo[e];if(n!==i||r!==s)throw new Error(`Uniform variable ${e} mismatch: expect type ${i} with size ${s}, got type ${n} with size ${r} in program "${g.programInfo.name}".`)}}if(Xe("info",(()=>`[ProgramManager] run "${e.name}" (key=${m}) with ${h[0]}x${h[1]}x${h[2]}`)),"none"!==this.queryType||"capturing"===this.sessionStatus){let e={kernelId:this.currentKernelId,programName:g.programInfo.name,inputTensorViews:t,outputTensorViews:c};this.pendingKernels.push(e),"capturing"===this.sessionStatus&&this.capturedPendingKernels.get(this.currentSessionId).push(e)}return this.programManager.run(g,s,p,h,u),A(e.name),c}upload(e,t){this.gpuDataManager.upload(e,t)}memcpy(e,t){this.gpuDataManager.memcpy(e,t)}async download(e,t){await this.gpuDataManager.download(e,t)}alloc(e){return this.gpuDataManager.create(e).id}free(e){return this.gpuDataManager.release(e)}createKernel(e,t,n,r){let i=wa.get(e);if(!i)throw new Error(`kernel not implemented: ${e}`);let s={kernelType:e,kernelName:r,kernelEntry:i[0],attributes:[i[1],n]};this.kernels.set(t,s)}releaseKernel(e){let t=this.kernelPersistentData.get(e);if(t){for(let e of t)this.gpuDataManager.release(e.id);this.kernelPersistentData.delete(e)}this.kernelCustomData.delete(e),this.kernels.delete(e)}computeKernel(e,t,n){let r=this.kernels.get(e);if(!r)throw new Error(`kernel not created: ${e}`);let i=r.kernelType,s=r.kernelName,o=r.kernelEntry,a=r.attributes;if(null!==this.currentKernelId)throw new Error(`kernel "[${i}] ${s}" is not allowed to be called recursively`);this.currentKernelId=e,a[0]&&(a[1]=a[0](a[1]),a[0]=void 0),Xe("info",(()=>`[WebGPU] Start to run kernel "[${i}] ${s}"...`));let l=this.env.debug;this.temporaryData=[];try{return l&&this.device.pushErrorScope("validation"),o(t,a[1]),0}catch(e){return n.push(Promise.resolve(`[WebGPU] Kernel "[${i}] ${s}" failed. ${e}`)),1}finally{l&&n.push(this.device.popErrorScope().then((e=>e?`GPU validation error for kernel "[${i}] ${s}": ${e.message}`:null)));for(let e of this.temporaryData)this.gpuDataManager.release(e.id);this.temporaryData=[],this.currentKernelId=null}}registerBuffer(e,t,n,r){let i=this.sessionExternalDataMapping.get(e);i||(i=new Map,this.sessionExternalDataMapping.set(e,i));let s=i.get(t),o=this.gpuDataManager.registerExternalBuffer(n,r,s?.[1]);return i.set(t,[o,n]),o}unregisterBuffers(e){let t=this.sessionExternalDataMapping.get(e);t&&(t.forEach((e=>this.gpuDataManager.unregisterExternalBuffer(e[1]))),this.sessionExternalDataMapping.delete(e))}getBuffer(e){let t=this.gpuDataManager.get(e);if(!t)throw new Error(`no GPU data for buffer: ${e}`);return t.buffer}createDownloader(e,t,n){return async()=>{let r=await Je(this,e,t);return Qe(r.buffer,n)}}writeTimestamp(e){"inside-passes"===this.queryType&&this.computePassEncoder.writeTimestamp(this.querySet,e)}setQueryType(){this.queryType="none",("default"===this.env.webgpu.profiling?.mode||(typeof this.env.trace>"u"?this.env.wasm.trace:this.env.trace))&&(this.device.features.has("chromium-experimental-timestamp-query-inside-passes")?this.queryType="inside-passes":this.device.features.has("timestamp-query")&&(this.queryType="at-passes"),"none"!==this.queryType&&typeof this.querySet>"u"&&(this.querySet=this.device.createQuerySet({type:"timestamp",count:2*this.maxDispatchNumber}),this.queryResolveBuffer=this.device.createBuffer({size:2*this.maxDispatchNumber*8,usage:GPUBufferUsage.COPY_SRC|GPUBufferUsage.QUERY_RESOLVE})))}captureBegin(){Xe("info","captureBegin"),this.capturedCommandList.get(this.currentSessionId)||this.capturedCommandList.set(this.currentSessionId,[]),this.capturedPendingKernels.get(this.currentSessionId)||this.capturedPendingKernels.set(this.currentSessionId,[]),this.flush(),this.sessionStatus="capturing"}captureEnd(){Xe("info","captureEnd"),this.flush(),this.sessionStatus="default"}replay(){Xe("info","replay"),this.sessionStatus="replaying";let e=this.capturedCommandList.get(this.currentSessionId),t=this.capturedPendingKernels.get(this.currentSessionId),n=e.length;this.pendingKernels=[];for(let r=0;r<n;r++){let n=this.getComputePassEncoder(),i=e[r];this.writeTimestamp(2*this.pendingDispatchNumber),n.setPipeline(i.computePipeline),n.setBindGroup(0,i.bindGroup),n.dispatchWorkgroups(...i.dispatchGroup),this.writeTimestamp(2*this.pendingDispatchNumber+1),this.pendingDispatchNumber++,"none"!==this.queryType&&this.pendingKernels.push(t[r]),(this.pendingDispatchNumber>=this.maxDispatchNumber||"at-passes"===this.queryType)&&this.endComputePass(),this.pendingDispatchNumber>=this.maxDispatchNumber&&this.flush()}this.flush(),this.sessionStatus="default"}onReleaseSession(e){this.unregisterBuffers(e),this.capturedCommandList.has(e)&&this.capturedCommandList.delete(e),this.capturedPendingKernels.has(e)&&this.capturedPendingKernels.delete(e),this.gpuDataManager.onReleaseSession(e)}onRunStart(e){this.currentSessionId=e,this.setQueryType()}}})),Il={};j(Il,{init:()=>Ol});var zl,Bl,Ol,Ll,Dl,Rl,Nl,Vl,jl,Ul,Gl,ql,Wl,Hl,Xl,Ql,Kl,Yl,Zl,Jl,ed,td,nd,rd,id,sd,od,ad,ld,dd,ud,cd,pd,hd,fd,md,gd,_d=V((()=>{Aa(),Fl(),Ia(),Da(),zl=class e{constructor(e,t,n,r){this.module=e,this.dataType=t,this.data=n,this.dims=r}getFloat32Array(){if(1!==this.dataType)throw new Error("Invalid data type");let e=ot.size(this.dims);return 0===e?new Float32Array:new Float32Array(this.module.HEAP8.buffer,this.data,e)}getBigInt64Array(){if(7!==this.dataType)throw new Error("Invalid data type");let e=ot.size(this.dims);return 0===e?new BigInt64Array:new BigInt64Array(this.module.HEAP8.buffer,this.data,e)}getInt32Array(){if(6!==this.dataType)throw new Error("Invalid data type");let e=ot.size(this.dims);return 0===e?new Int32Array:new Int32Array(this.module.HEAP8.buffer,this.data,e)}reshape(t){if(ot.size(t)!==ot.size(this.dims))throw new Error("Invalid new shape");return new e(this.module,this.dataType,this.data,t)}},Bl=class{constructor(e,t,n){this.module=e,this.backend=t,this.customDataOffset=0,this.customDataSize=0,this.adapterInfo=t.adapterInfo;let r=e.HEAPU32,i=n>>>2;this.opKernelContext=r[i++];let s=r[i++];this.outputCount=r[i++],this.customDataOffset=r[i++],this.customDataSize=r[i++];let o=[];for(let t=0;t<s;t++){let t=r[i++],n=r[i++],s=r[i++],a=[];for(let e=0;e<s;e++)a.push(r[i++]);o.push(new zl(e,t,n,a))}this.inputs=o}get kernelCustomData(){return this.backend.currentKernelCustomData}get customDataBuffer(){return this.module.HEAPU8.subarray(this.customDataOffset,this.customDataOffset+this.customDataSize)}compute(e,t){let n=t?.inputs?.map((e=>"number"==typeof e?this.inputs[e]:e))??this.inputs,r=t?.outputs??[];return this.backend.run(e,n,r,((e,t,n)=>new zl(this.module,t,this.output(e,n),n)),((e,t)=>{let n=Oe(e);if(!n)throw new Error(`Unsupported data type: ${e}`);let r=n*ot.size(t),i=r>0?this.backend.gpuDataManager.create(r).id:0;return new zl(this.module,e,i,t)}))}output(e,t){let n=this.module.stackSave();try{let n=this.module.stackAlloc(4*(1+t.length)),r=n>>2;this.module.HEAPU32[r++]=t.length;for(let e=0;e<t.length;e++)this.module.HEAPU32[r++]=t[e];return this.module._JsepOutput(this.opKernelContext,e,n)}catch(n){throw new Error(`Failed to generate kernel's output[${e}] with dims [${t}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${n}`)}finally{this.module.stackRestore(n)}}},Ol=async(e,t,n,r)=>{let i=t.jsepInit;if(!i)throw new Error("Failed to initialize JSEP. The WebAssembly module is not built with JSEP support.");if("webgpu"===e){let e=new Ma;await e.initialize(n,r),i("webgpu",[e,t=>e.alloc(t),t=>e.free(t),(n,r,i,s=!1)=>{if(s)Xe("verbose",(()=>`[WebGPU] jsepCopyGpuToGpu: src=${n}, dst=${r}, size=${i}`)),e.memcpy(n,r);else{Xe("verbose",(()=>`[WebGPU] jsepCopyCpuToGpu: dataOffset=${n}, gpuDataId=${r}, size=${i}`));let s=t.HEAPU8.subarray(n>>>0,(n>>>0)+i);e.upload(r,s)}},async(n,r,i)=>{Xe("verbose",(()=>`[WebGPU] jsepCopyGpuToCpu: gpuDataId=${n}, dataOffset=${r}, size=${i}`)),await e.download(n,(()=>t.HEAPU8.subarray(r>>>0,(r>>>0)+i)))},(n,r,i)=>e.createKernel(n,r,i,t.UTF8ToString(t._JsepGetNodeName(r))),t=>e.releaseKernel(t),(n,r,i,s)=>{Xe("verbose",(()=>`[WebGPU] jsepRun: sessionHandle=${i}, kernel=${n}, contextDataOffset=${r}`));let o=new Bl(t,e,r);return e.computeKernel(n,o,s)},()=>e.captureBegin(),()=>e.captureEnd(),()=>e.replay()])}else i("webnn")}})),wd=V((()=>{Pa(),Ea(),Aa(),Sa(),Ca(),Fa(),Ll=(e,t)=>{0!==Te()._OrtInit(e,t)&&Se("Can't initialize onnxruntime.")},Dl=async e=>{Ll(e.wasm.numThreads,De(e.logLevel))},Rl=async(e,t)=>{{let n=(_d(),U(Il)).init;if("webgpu"===t){if(typeof navigator>"u"||!navigator.gpu)throw new Error("WebGPU is not supported in current environment");let t=e.webgpu.adapter;if(t){if("object"!=typeof t.limits||"object"!=typeof t.features||"function"!=typeof t.requestDevice)throw new Error("Invalid GPU adapter set in `env.webgpu.adapter`. It must be a GPUAdapter object.")}else{let n=e.webgpu.powerPreference;if(void 0!==n&&"low-power"!==n&&"high-performance"!==n)throw new Error(`Invalid powerPreference setting: "${n}"`);let r=e.webgpu.forceFallbackAdapter;if(void 0!==r&&"boolean"!=typeof r)throw new Error(`Invalid forceFallbackAdapter setting: "${r}"`);if(t=await navigator.gpu.requestAdapter({powerPreference:n,forceFallbackAdapter:r}),!t)throw new Error('Failed to get GPU adapter. You may need to enable flag "--enable-unsafe-webgpu" if you are using Chrome.')}if(!e.wasm.simd)throw new Error("Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using `webgpu` EP");await n("webgpu",Te(),e,t)}if("webnn"===t){if(typeof navigator>"u"||!navigator.ml)throw new Error("WebNN is not supported in current environment");await n("webnn",Te(),e)}}},Nl=new Map,Vl=e=>{let t=Te(),n=t.stackSave();try{let n=t.stackAlloc(8);return 0!==t._OrtGetInputOutputCount(e,n,n+4)&&Se("Can't get session input/output count."),[t.HEAP32[n/4],t.HEAP32[n/4+1]]}finally{t.stackRestore(n)}},jl=e=>{let t=Te(),n=t._malloc(e.byteLength);if(0===n)throw new Error(`Can't create a session. failed to allocate a buffer of size ${e.byteLength}.`);return t.HEAPU8.set(e,n),[n,e.byteLength]},Ul=async(e,t)=>{let n,r,i=Te();Array.isArray(e)?[n,r]=e:e.buffer===i.HEAPU8.buffer?[n,r]=[e.byteOffset,e.byteLength]:[n,r]=jl(e);let s=0,o=0,a=0,l=[],d=[],u=[];try{if([o,l]=Ie(t),t?.externalData&&i.mountExternalData){let e=[];for(let n of t.externalData){let t="string"==typeof n?n:n.path;e.push(Ve("string"==typeof n?n:n.data).then((e=>{i.mountExternalData(t,e)})))}await Promise.all(e)}s=await i._OrtCreateSession(n,r,o),0===s&&Se("Can't create a session.");let[e,c]=Vl(s),p=!!t?.enableGraphCapture,h=[],f=[],m=[];for(let t=0;t<e;t++){let e=i._OrtGetInputName(s,t);0===e&&Se("Can't get an input name."),d.push(e),h.push(i.UTF8ToString(e))}for(let e=0;e<c;e++){let n=i._OrtGetOutputName(s,e);0===n&&Se("Can't get an output name."),u.push(n);let r=i.UTF8ToString(n);f.push(r);{if(p&&void 0===t?.preferredOutputLocation){m.push("gpu-buffer");continue}let e="string"==typeof t?.preferredOutputLocation?t.preferredOutputLocation:t?.preferredOutputLocation?.[r]??"cpu";if("cpu"!==e&&"cpu-pinned"!==e&&"gpu-buffer"!==e)throw new Error(`Not supported preferred output location: ${e}.`);if(p&&"gpu-buffer"!==e)throw new Error(`Not supported preferred output location: ${e}. Only 'gpu-buffer' location is supported when enableGraphCapture is true.`);m.push(e)}}let g=null;return m.some((e=>"gpu-buffer"===e))&&(a=i._OrtCreateBinding(s),0===a&&Se("Can't create IO binding."),g={handle:a,outputPreferredLocations:m,outputPreferredLocationsEncoded:m.map((e=>Ne(e)))}),Nl.set(s,[s,d,u,g,p,!1]),[s,h,f]}catch(e){throw d.forEach((e=>i._OrtFree(e))),u.forEach((e=>i._OrtFree(e))),0!==a&&i._OrtReleaseBinding(a),0!==s&&i._OrtReleaseSession(s),e}finally{i._free(n),0!==o&&i._OrtReleaseSessionOptions(o),l.forEach((e=>i._free(e))),i.unmountExternalData?.()}},Gl=e=>{let t=Te(),n=Nl.get(e);if(!n)throw new Error(`cannot release session. invalid session id: ${e}`);let[r,i,s,o,a]=n;o&&(a&&t._OrtClearBoundOutputs(o.handle),t._OrtReleaseBinding(o.handle)),t.jsepOnReleaseSession?.(e),i.forEach((e=>t._OrtFree(e))),s.forEach((e=>t._OrtFree(e))),t._OrtReleaseSession(r),Nl.delete(e)},ql=(e,t,n,r,i,s=!1)=>{if(!e)return void t.push(0);let o,a,l=Te(),d=e[0],u=e[1],c=e[3];if("string"===d&&"gpu-buffer"===c)throw new Error("String tensor is not supported on GPU.");if(s&&"gpu-buffer"!==c)throw new Error(`External buffer must be provided for input/output index ${i} when enableGraphCapture is true.`);if("gpu-buffer"===c){let t=e[2].gpuBuffer,n=Oe(ze(d));a=u.reduce(((e,t)=>e*t),1)*n;let s=l.jsepRegisterBuffer;if(!s)throw new Error('Tensor location "gpu-buffer" is not supported without using WebGPU.');o=s(r,i,t,a)}else{let t=e[2];if(Array.isArray(t)){a=4*t.length,o=l._malloc(a),n.push(o);let e=o/4;for(let r=0;r<t.length;r++){if("string"!=typeof t[r])throw new TypeError(`tensor data at index ${r} is not a string`);l.HEAPU32[e++]=ke(t[r],n)}}else a=t.byteLength,o=l._malloc(a),n.push(o),l.HEAPU8.set(new Uint8Array(t.buffer,t.byteOffset,a),o)}let p=l.stackSave(),h=l.stackAlloc(4*u.length);try{let e=h/4;u.forEach((t=>l.HEAP32[e++]=t));let n=l._OrtCreateTensor(ze(d),o,a,h,u.length,Ne(c));0===n&&Se(`Can't create tensor for input/output. session=${r}, index=${i}.`),t.push(n)}finally{l.stackRestore(p)}},Wl=async(e,t,n,r,i,s)=>{let o=Te(),a=Nl.get(e);if(!a)throw new Error(`cannot run inference. invalid session id: ${e}`);let l=a[0],d=a[1],u=a[2],c=a[3],p=a[4],h=a[5],f=t.length,m=r.length,g=0,_=[],w=[],y=[],b=[],v=o.stackSave(),x=o.stackAlloc(4*f),M=o.stackAlloc(4*f),T=o.stackAlloc(4*m),k=o.stackAlloc(4*m);try{[g,_]=Ce(s);for(let r=0;r<f;r++)ql(n[r],w,b,e,t[r],p);for(let t=0;t<m;t++)ql(i[t],y,b,e,f+r[t],p);let a,v=x/4,$=M/4,S=T/4,C=k/4;for(let e=0;e<f;e++)o.HEAPU32[v++]=w[e],o.HEAPU32[$++]=d[t[e]];for(let e=0;e<m;e++)o.HEAPU32[S++]=y[e],o.HEAPU32[C++]=u[r[e]];if(c&&!h){let{handle:n,outputPreferredLocations:s,outputPreferredLocationsEncoded:a}=c;if(d.length!==f)throw new Error(`input count from feeds (${f}) is expected to be always equal to model's input count (${d.length}).`);for(let r=0;r<f;r++){let i=t[r];0!==await o._OrtBindInput(n,d[i],w[r])&&Se(`Can't bind input[${r}] for session=${e}.`)}for(let t=0;t<m;t++){let l=r[t];i[t]?.[3]?0!==o._OrtBindOutput(n,u[l],y[t],0)&&Se(`Can't bind pre-allocated output[${t}] for session=${e}.`):0!==o._OrtBindOutput(n,u[l],0,a[l])&&Se(`Can't bind output[${t}] to ${s[t]} for session=${e}.`)}Nl.set(e,[l,d,u,c,p,!0])}o.jsepOnRunStart?.(l),a=c?await o._OrtRunWithBinding(l,c.handle,m,T,g):await o._OrtRun(l,M,x,f,k,m,T,g),0!==a&&Se("failed to call OrtRun().");let P=[];for(let e=0;e<m;e++){let t=o.HEAPU32[T/4+e];if(t===y[e]){P.push(i[e]);continue}let n,s=o.stackSave(),a=o.stackAlloc(16),l=!1,d=0;try{0!==o._OrtGetTensorData(t,a,a+4,a+8,a+12)&&Se(`Can't access output tensor data on index ${e}.`);let i=a/4,s=o.HEAPU32[i++];d=o.HEAPU32[i++];let u=o.HEAPU32[i++],p=o.HEAPU32[i++],h=[];for(let e=0;e<p;e++)h.push(o.HEAPU32[u/4+e]);o._OrtFree(u);let f=h.reduce(((e,t)=>e*t),1);n=Be(s);let m=c?.outputPreferredLocations[r[e]];if("string"===n){if("gpu-buffer"===m)throw new Error("String tensor is not supported on GPU.");let e=[],t=d/4;for(let n=0;n<f;n++){let r=o.HEAPU32[t++],i=n===f-1?void 0:o.HEAPU32[t]-r;e.push(o.UTF8ToString(r,i))}P.push([n,h,e,"cpu"])}else if("gpu-buffer"===m&&f>0){let e=o.jsepGetBuffer;if(!e)throw new Error('preferredLocation "gpu-buffer" is not supported without using WebGPU.');let r=e(d),i=Oe(s);if(void 0===i||!Re(n))throw new Error(`Unsupported data type: ${n}`);l=!0,P.push([n,h,{gpuBuffer:r,download:o.jsepCreateDownloader(r,f*i,n),dispose:()=>{o._OrtReleaseTensor(t)}},"gpu-buffer"])}else{let e=new(Le(n))(f);new Uint8Array(e.buffer,e.byteOffset,e.byteLength).set(o.HEAPU8.subarray(d,d+e.byteLength)),P.push([n,h,e,"cpu"])}}finally{o.stackRestore(s),"string"===n&&d&&o._free(d),l||o._OrtReleaseTensor(t)}}return c&&!p&&(o._OrtClearBoundOutputs(c.handle),Nl.set(e,[l,d,u,c,p,!1])),P}finally{o.stackRestore(v),w.forEach((e=>o._OrtReleaseTensor(e))),y.forEach((e=>o._OrtReleaseTensor(e))),b.forEach((e=>o._free(e))),0!==g&&o._OrtReleaseRunOptions(g),_.forEach((e=>o._free(e)))}},Hl=e=>{let t=Te(),n=Nl.get(e);if(!n)throw new Error("invalid session id");let r=n[0],i=t._OrtEndProfiling(r);0===i&&Se("Can't get an profile file name."),t._OrtFree(i)},Xl=e=>{let t=[];for(let n of e){let e=n[2];!Array.isArray(e)&&"buffer"in e&&t.push(e.buffer)}return t}})),yd=V((()=>{Ta(),wd(),Sa(),$a(),Ql=()=>!!p.wasm.proxy&&typeof document<"u",Yl=!1,Zl=!1,Jl=!1,td=new Map,nd=(e,t)=>{let n=td.get(e);n?n.push(t):td.set(e,[t])},rd=()=>{if(Yl||!Zl||Jl||!Kl)throw new Error("worker not ready")},id=e=>{switch(e.data.type){case"init-wasm":Yl=!1,e.data.err?(Jl=!0,ed[1](e.data.err)):(Zl=!0,ed[0]());break;case"init-ep":case"copy-from":case"create":case"release":case"run":case"end-profiling":{let t=td.get(e.data.type);e.data.err?t.shift()[1](e.data.err):t.shift()[0](e.data.out);break}}},sd=async()=>{if(!Zl){if(Yl)throw new Error("multiple calls to 'initWasm()' detected.");if(Jl)throw new Error("previous call to 'initWasm()' failed.");if(Yl=!0,Ql())return new Promise(((e,t)=>{Kl?.terminate();let n="string"==typeof p.wasm.wasmPaths?p.wasm.wasmPaths:void 0;fe("ort.webgpu.proxy.min.mjs?import=1",n).then((async r=>{try{(Kl=await r(n)).onerror=e=>t(e),Kl.onmessage=id,ed=[e,t];let i={type:"init-wasm",in:p};Kl.postMessage(i)}catch(e){t(e)}}),t)}));try{await Me(p.wasm),await Dl(p),Zl=!0}catch(e){throw Jl=!0,e}finally{Yl=!1}}},od=async e=>{if(Ql())return rd(),new Promise(((t,n)=>{nd("init-ep",[t,n]);let r={type:"init-ep",in:{epName:e,env:p}};Kl.postMessage(r)}));await Rl(p,e)},ad=async e=>Ql()?(rd(),new Promise(((t,n)=>{nd("copy-from",[t,n]);let r={type:"copy-from",in:{buffer:e}};Kl.postMessage(r,[e.buffer])}))):jl(e),ld=async(e,t)=>{if(Ql()){if(t?.preferredOutputLocation)throw new Error('session option "preferredOutputLocation" is not supported for proxy.');return rd(),new Promise(((n,r)=>{nd("create",[n,r]);let i={type:"create",in:{model:e,options:{...t}}},s=[];e instanceof Uint8Array&&s.push(e.buffer),Kl.postMessage(i,s)}))}return Ul(e,t)},dd=async e=>{if(Ql())return rd(),new Promise(((t,n)=>{nd("release",[t,n]);let r={type:"release",in:e};Kl.postMessage(r)}));Gl(e)},ud=async(e,t,n,r,i,s)=>{if(Ql()){if(n.some((e=>"cpu"!==e[3])))throw new Error("input tensor on GPU is not supported for proxy.");if(i.some((e=>e)))throw new Error("pre-allocated output tensor is not supported for proxy.");return rd(),new Promise(((i,o)=>{nd("run",[i,o]);let a=n,l={type:"run",in:{sessionId:e,inputIndices:t,inputs:a,outputIndices:r,options:s}};Kl.postMessage(l,Xl(a))}))}return Wl(e,t,n,r,i,s)},cd=async e=>{if(Ql())return rd(),new Promise(((t,n)=>{nd("end-profiling",[t,n]);let r={type:"end-profiling",in:e};Kl.postMessage(r)}));Hl(e)}})),bd=V((()=>{Ta(),yd(),Aa(),ka(),Fa(),pd=(e,t)=>{switch(e.location){case"cpu":return[e.type,e.dims,e.data,"cpu"];case"gpu-buffer":return[e.type,e.dims,{gpuBuffer:e.gpuBuffer},"gpu-buffer"];default:throw new Error(`invalid data location: ${e.location} for ${t()}`)}},hd=e=>{switch(e[3]){case"cpu":return new S(e[0],e[2],e[1]);case"gpu-buffer":{let t=e[0];if(!Re(t))throw new Error(`not supported data type: ${t} for deserializing GPU tensor`);let{gpuBuffer:n,download:r,dispose:i}=e[2];return S.fromGpuBuffer(n,{dataType:t,dims:e[1],download:r,dispose:i})}default:throw new Error(`invalid data location: ${e[3]}`)}},fd=class{async fetchModelAndCopyToWasmMemory(e){return ad(await Ve(e))}async loadModel(e,t){let n;E(),n="string"==typeof e?ce?await Ve(e):await this.fetchModelAndCopyToWasmMemory(e):e,[this.sessionId,this.inputNames,this.outputNames]=await ld(n,t),A()}async dispose(){return dd(this.sessionId)}async run(e,t,n){E();let r=[],i=[];Object.entries(e).forEach((e=>{let t=e[0],n=e[1],s=this.inputNames.indexOf(t);if(-1===s)throw new Error(`invalid input '${t}'`);r.push(n),i.push(s)}));let s=[],o=[];Object.entries(t).forEach((e=>{let t=e[0],n=e[1],r=this.outputNames.indexOf(t);if(-1===r)throw new Error(`invalid output '${t}'`);s.push(n),o.push(r)}));let a=r.map(((e,t)=>pd(e,(()=>`input "${this.inputNames[i[t]]}"`)))),l=s.map(((e,t)=>e?pd(e,(()=>`output "${this.outputNames[o[t]]}"`)):null)),d=await ud(this.sessionId,i,a,o,l,n),u={};for(let e=0;e<d.length;e++)u[this.outputNames[o[e]]]=s[e]??hd(d[e]);return A(),u}startProfiling(){}endProfiling(){cd(this.sessionId)}}})),vd=V((()=>{Ta(),yd(),bd(),$a(),md=()=>{if(("number"!=typeof p.wasm.initTimeout||p.wasm.initTimeout<0)&&(p.wasm.initTimeout=0),"boolean"!=typeof p.wasm.simd&&(p.wasm.simd=!0),"boolean"!=typeof p.wasm.proxy&&(p.wasm.proxy=!1),"boolean"!=typeof p.wasm.trace&&(p.wasm.trace=!1),"number"!=typeof p.wasm.numThreads||!Number.isInteger(p.wasm.numThreads)||p.wasm.numThreads<=0)if(typeof self<"u"&&!self.crossOriginIsolated)p.wasm.numThreads=1;else{let e=typeof navigator>"u"?N("node:os").cpus().length:navigator.hardwareConcurrency;p.wasm.numThreads=Math.min(4,Math.ceil((e||1)/2))}void 0===p.wasm.wasmPaths&&pe&&0!==pe.indexOf("blob:")&&(p.wasm.wasmPaths=pe.substring(0,pe.lastIndexOf("/")+1))},gd=class{async init(e){md(),await sd(),await od(e)}async createInferenceSessionHandler(e,t){let n=new fd;return await n.loadModel(e,t),Promise.resolve(n)}}})),xd={};j(xd,{wasmBackend:()=>Md});var Md,Td=V((()=>{vd(),Md=new gd}));Ta(),Ta(),Ta();var kd=ue;{let e=(Td(),U(xd)).wasmBackend;o("webgpu",e,5),o("webnn",e,5),o("cpu",e,10),o("wasm",e,10)}Object.defineProperty(p.versions,"web",{value:"1.18.0-esmtest.20240411-1abb64e894",enumerable:!0})}
/**
 * @license
 * Copyright 2021 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2019 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */,"./src/backends/onnx.js":
/*!******************************!*\
  !*** ./src/backends/onnx.js ***!
  \******************************/(e,t,n)=>{var r;n.r(t),n.d(t,{Tensor:()=>a.Tensor,createInferenceSession:()=>h,deviceToExecutionProviders:()=>p,isONNXProxy:()=>g,isONNXTensor:()=>f});var i=n(/*! ../env.js */"./src/env.js"),s=n(/*! onnxruntime-node */"?2ce3"),o=n(/*! onnxruntime-web/webgpu */"./node_modules/onnxruntime-web/dist/ort.webgpu.min.mjs"),a=n(/*! onnxruntime-common */"./node_modules/onnxruntime-common/dist/esm/index.js");const l=[];let d,u;i.apis.IS_NODE_ENV?(u=s??(r||(r=n.t(s,2))),l.push("cpu"),d=["cpu"]):(u=o,i.apis.IS_WEBGPU_AVAILABLE&&l.push("webgpu"),i.apis.IS_WEBNN_AVAILABLE&&l.push("webnn"),l.push("wasm"),d=["wasm"]);const c=u.InferenceSession;function p(e){let t=d;if(e){if(!l.includes(e))throw new Error(`Unsupported device: "${e}". Should be one of: ${l.join(", ")}.`);t=[e]}return t}async function h(e,t){return console.log("- createInferenceSession (*, session_options) -"),console.log(t),await c.create(e,t)}function f(e){return e instanceof u.Tensor}const m=u?.env;if(m?.wasm){m.wasm.wasmPaths="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0-esmtest.20240411-1abb64e894/dist/",m.wasm.proxy=!i.apis.IS_WEBWORKER_ENV,"undefined"!=typeof crossOriginIsolated&&crossOriginIsolated||(m.wasm.numThreads=1);"undefined"!=typeof navigator&&/iP(hone|od|ad).+16_4.+AppleWebKit/.test(navigator.userAgent)&&(m.wasm.simd=!1)}function g(){return m?.wasm?.proxy}i.env.backends.onnx=m},"./src/configs.js":
/*!************************!*\
  !*** ./src/configs.js ***!
  \************************/(e,t,n)=>{n.r(t),n.d(t,{AutoConfig:()=>s,PretrainedConfig:()=>i});var r=n(/*! ./utils/hub.js */"./src/utils/hub.js");class i{constructor(e){this.model_type=null,this.is_encoder_decoder=!1,Object.assign(this,e)}static async from_pretrained(e,{progress_callback:t=null,config:n=null,cache_dir:i=null,local_files_only:s=!1,revision:o="main"}={}){let a=n??await async function(e,t){return await(0,r.getModelJSON)(e,"config.json",!0,t)}(e,{progress_callback:t,config:n,cache_dir:i,local_files_only:s,revision:o});return new this(a)}}class s{static async from_pretrained(...e){return i.from_pretrained(...e)}}},"./src/env.js":
/*!********************!*\
  !*** ./src/env.js ***!
  \********************/(e,t,n)=>{n.r(t),n.d(t,{apis:()=>f,env:()=>y});var r=n(/*! fs */"?569f"),i=n(/*! path */"?3f59"),s=n(/*! url */"?154a");const o="undefined"!=typeof self,a=o&&"DedicatedWorkerGlobalScope"===self.constructor.name,l=o&&"caches"in self,d="undefined"!=typeof navigator&&"gpu"in navigator,u="undefined"!=typeof navigator&&"ml"in navigator,c="undefined"!=typeof process&&"node"===process?.release?.name,p=!b(r),h=!b(i),f=Object.freeze({IS_BROWSER_ENV:o,IS_WEBWORKER_ENV:a,IS_WEB_CACHE_AVAILABLE:l,IS_WEBGPU_AVAILABLE:d,IS_WEBNN_AVAILABLE:u,IS_NODE_ENV:c,IS_FS_AVAILABLE:p,IS_PATH_AVAILABLE:h}),m=p&&h,g=m?i.dirname(i.dirname(s.fileURLToPath("file:///home/belem/github/transformers.js/src/env.js"))):"./",_=m?i.join(g,"/.cache/"):null,w="/models/",y={version:"3.0.0-alpha.0",backends:{onnx:{},tfjs:{}},allowRemoteModels:!0,remoteHost:"https://huggingface.co/",remotePathTemplate:"{model}/resolve/{revision}/",allowLocalModels:!o,localModelPath:m?i.join(g,w):w,useFS:p,useBrowserCache:l,useFSCache:p,cacheDir:_,useCustomCache:!1,customCache:null};function b(e){return 0===Object.keys(e).length}},"./src/generation/configuration_utils.js":
/*!***********************************************!*\
  !*** ./src/generation/configuration_utils.js ***!
  \***********************************************/(e,t,n)=>{n.r(t),n.d(t,{GenerationConfig:()=>i});var r=n(/*! ../utils/core.js */"./src/utils/core.js");class i{max_length=20;max_new_tokens=null;min_length=0;min_new_tokens=null;early_stopping=!1;max_time=null;do_sample=!1;num_beams=1;num_beam_groups=1;penalty_alpha=null;use_cache=!0;temperature=1;top_k=50;top_p=1;typical_p=1;epsilon_cutoff=0;eta_cutoff=0;diversity_penalty=0;repetition_penalty=1;encoder_repetition_penalty=1;length_penalty=1;no_repeat_ngram_size=0;bad_words_ids=null;force_words_ids=null;renormalize_logits=!1;constraints=null;forced_bos_token_id=null;forced_eos_token_id=null;remove_invalid_values=!1;exponential_decay_length_penalty=null;suppress_tokens=null;begin_suppress_tokens=null;forced_decoder_ids=null;guidance_scale=null;num_return_sequences=1;output_attentions=!1;output_hidden_states=!1;output_scores=!1;return_dict_in_generate=!1;pad_token_id=null;bos_token_id=null;eos_token_id=null;encoder_no_repeat_ngram_size=0;decoder_start_token_id=null;generation_kwargs={};constructor(e){Object.assign(this,(0,r.pick)(e,Object.getOwnPropertyNames(this)))}}},"./src/generation/logits_process.js":
/*!******************************************!*\
  !*** ./src/generation/logits_process.js ***!
  \******************************************/(e,t,n)=>{n.r(t),n.d(t,{ClassifierFreeGuidanceLogitsProcessor:()=>_,ForcedBOSTokenLogitsProcessor:()=>l,ForcedEOSTokenLogitsProcessor:()=>d,LogitsProcessor:()=>s,LogitsProcessorList:()=>a,LogitsWarper:()=>o,MinLengthLogitsProcessor:()=>f,MinNewTokensLengthLogitsProcessor:()=>m,NoBadWordsLogitsProcessor:()=>g,NoRepeatNGramLogitsProcessor:()=>p,RepetitionPenaltyLogitsProcessor:()=>h,SuppressTokensAtBeginLogitsProcessor:()=>u,TemperatureLogitsWarper:()=>w,TopKLogitsWarper:()=>b,TopPLogitsWarper:()=>y,WhisperTimeStampLogitsProcessor:()=>c});var r=n(/*! ../utils/generic.js */"./src/utils/generic.js"),i=(n(/*! ../utils/tensor.js */"./src/utils/tensor.js"),n(/*! ../utils/maths.js */"./src/utils/maths.js"));class s extends r.Callable{_call(e,t){throw Error("`_call` should be implemented in a subclass")}}class o extends r.Callable{_call(e,t){throw Error("`_call` should be implemented in a subclass")}}class a extends r.Callable{constructor(){super(),this.processors=[]}push(e){this.processors.push(e)}extend(e){this.processors.push(...e)}_call(e,t){let n=t;for(const t of this.processors)n=t(e,n);return n}[Symbol.iterator](){return this.processors.values()}}class l extends s{constructor(e){super(),this.bos_token_id=e}_call(e,t){for(let n=0;n<e.length;++n)if(1===e[n].length){const e=t[n];e.data.fill(-1/0),e.data[this.bos_token_id]=0}return t}}class d extends s{constructor(e,t){super(),this.max_length=e,this.forced_eos_token_id=t}_call(e,t){}}class u extends s{constructor(e,t){super(),this.begin_suppress_tokens=e,this.begin_index=t}_call(e,t){for(let n=0;n<e.length;++n)if(e[n].length===this.begin_index){const e=t[n];for(const t of this.begin_suppress_tokens)e.data[t]=-1/0}return t}}class c extends s{constructor(e){super(),this.eos_token_id=e.eos_token_id,this.no_timestamps_token_id=e.no_timestamps_token_id,this.timestamp_begin=this.no_timestamps_token_id+1,this.begin_index=(e.forced_decoder_ids||[]).length+2,e.forced_decoder_ids.slice(-1)[0][1]===this.no_timestamps_token_id&&(this.begin_index-=1),this.max_initial_timestamp_index=e.max_initial_timestamp_index}_call(e,t){for(let n=0;n<e.length;++n){const r=t[n].data;if(r[this.no_timestamps_token_id]=-1/0,e[n].length===this.begin_index-1){r.fill(-1/0),r[this.timestamp_begin]=0;continue}const s=e[n].slice(this.begin_index),o=s.length>=1&&s[s.length-1]>=this.timestamp_begin,a=s.length<2||s[s.length-2]>=this.timestamp_begin;if(o&&(a?r.subarray(this.timestamp_begin).fill(-1/0):r.subarray(0,this.eos_token_id).fill(-1/0)),e[n].length===this.begin_index&&null!==this.max_initial_timestamp_index){const e=this.timestamp_begin+this.max_initial_timestamp_index;r.subarray(e+1).fill(-1/0)}const l=(0,i.log_softmax)(r);Math.log(l.subarray(this.timestamp_begin).map(Math.exp).reduce(((e,t)=>e+t)))>(0,i.max)(l.subarray(0,this.timestamp_begin))[0]&&r.subarray(0,this.timestamp_begin).fill(-1/0)}return t}}class p extends s{constructor(e){super(),this.no_repeat_ngram_size=e}getNgrams(e){const t=e.length,n=[];for(let r=0;r<t+1-this.no_repeat_ngram_size;++r){const t=[];for(let n=0;n<this.no_repeat_ngram_size;++n)t.push(e[r+n]);n.push(t)}const r=new Map;for(const e of n){const t=e.slice(0,e.length-1),n=JSON.stringify(t),i=r.get(n)??[];i.push(e[e.length-1]),r.set(n,i)}return r}getGeneratedNgrams(e,t){const n=t.slice(t.length+1-this.no_repeat_ngram_size,t.length);return e.get(JSON.stringify(n))??[]}calcBannedNgramTokens(e){const t=[];if(e.length+1<this.no_repeat_ngram_size)return t;{const t=this.getNgrams(e);return this.getGeneratedNgrams(t,e)}}_call(e,t){for(let n=0;n<e.length;++n){const r=t[n],i=this.calcBannedNgramTokens(e[n]);for(const e of i)r.data[e]=-1/0}return t}}class h extends s{constructor(e){super(),this.penalty=e}_call(e,t){for(let n=0;n<e.length;++n){const r=t[n];for(const t of e[n])r.data[t]<0?r.data[t]*=this.penalty:r.data[t]/=this.penalty}return t}}class f extends s{constructor(e,t){super(),this.min_length=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){for(let n=0;n<e.length;++n)if(e[n].length<this.min_length){const e=t[n];for(const t of this.eos_token_id)e.data[t]=-1/0}return t}}class m extends s{constructor(e,t,n){super(),this.prompt_length_to_skip=e,this.min_new_tokens=t,this.eos_token_id=Array.isArray(n)?n:[n]}_call(e,t){for(let n=0;n<e.length;++n){if(e[n].length-this.prompt_length_to_skip<this.min_new_tokens){const e=t[n];for(const t of this.eos_token_id)e[t]=-1/0}}return t}}class g extends s{constructor(e,t){super(),this.bad_words_ids=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){for(let n=0;n<e.length;++n){const r=t[n];for(const t of this.bad_words_ids){let n=!0;for(let r=1;r<=t.length-1&&t.length<e[r].length;++r)if(t.at(-r-1)!==e[r].at(-r)){n=!1;break}n&&(r[t.at(-1)]=-1/0)}}return t}}class _ extends s{constructor(e){if(super(),e<=1)throw new Error(`Require guidance scale >1 to use the classifier free guidance processor, got guidance scale ${e}.`);this.guidance_scale=e}_call(e,t){if(t.dims[0]!==2*e.length)throw new Error(`Logits should have twice the batch size of the input ids, the first half of batches corresponding to the conditional inputs, and the second half of batches corresponding to the unconditional inputs. Got batch size ${t.dims[0]} for the logits and ${e.length} for the input ids.`);const n=e.length,r=t.slice([0,n],null),i=t.slice([n,t.dims[0]],null);for(let e=0;e<i.data.length;++e)i.data[e]+=(r.data[e]-i.data[e])*this.guidance_scale;return i}}class w extends o{constructor(e){if(super(),"number"!=typeof e||e<=0){let t=`\`temperature\` (=${e}) must be a strictly positive float, otherwise your next token scores will be invalid.`;0===e&&(t+=" If you're looking for greedy decoding strategies, set `do_sample=false`.")}this.temperature=e}_call(e,t){const n=t.data;for(let e=0;e<n.length;++e)n[e]/=this.temperature;return t}}class y extends o{constructor(e,{filter_value:t=-1/0,min_tokens_to_keep:n=1}={}){if(super(),e<0||e>1)throw new Error(`\`top_p\` must be a float > 0 and < 1, but is ${e}`);if(!Number.isInteger(n)||n<1)throw new Error(`\`min_tokens_to_keep\` must be a positive integer, but is ${n}`);this.top_p=e,this.filter_value=t,this.min_tokens_to_keep=n}}class b extends o{constructor(e,{filter_value:t=-1/0,min_tokens_to_keep:n=1}={}){if(super(),!Number.isInteger(e)||e<0)throw new Error(`\`top_k\` must be a positive integer, but is ${e}`);this.top_k=Math.max(e,n),this.filter_value=t}}},"./src/generation/logits_sampler.js":
/*!******************************************!*\
  !*** ./src/generation/logits_sampler.js ***!
  \******************************************/(e,t,n)=>{n.r(t),n.d(t,{LogitsSampler:()=>s});var r=n(/*! ../utils/generic.js */"./src/utils/generic.js"),i=(n(/*! ../utils/tensor.js */"./src/utils/tensor.js"),n(/*! ../utils/maths.js */"./src/utils/maths.js"));n(/*! ../generation/configuration_utils.js */"./src/generation/configuration_utils.js");class s extends r.Callable{constructor(e){super(),this.generation_config=e}_call(e,t=-1){return this.sample(e,t)}sample(e,t){throw Error("sample should be implemented in subclasses.")}getLogits(e,t){let n=e.dims.at(-1),r=e.data;if(-1===t)r=r.slice(-n);else{let e=t*n;r=r.slice(e,e+n)}return r}randomSelect(e){let t=e.reduce(((e,t)=>e+t),0),n=Math.random()*t;for(let t=0;t<e.length;++t)if(n-=e[t],n<=0)return t;return 0}static getSampler(e){if(e.do_sample)return new a(e);if(e.num_beams>1)return new l(e);if(e.num_return_sequences>1)throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${e.num_return_sequences}.`);return new o(e)}}class o extends s{sample(e,t=-1){let n=this.getLogits(e,t);return[[(0,i.max)(n)[1],0]]}}class a extends s{sample(e,t=-1){let n=e.dims.at(-1);this.generation_config.top_k>0&&(n=Math.min(this.generation_config.top_k,n));const r=this.getLogits(e,t),s=(0,i.getTopItems)(r,n),o=(0,i.softmax)(s.map((e=>e[1])));return Array.from({length:this.generation_config.num_beams},(()=>{const e=this.randomSelect(o);return[s[e][0],Math.log(o[e])]}))}}class l extends s{sample(e,t=-1){let n=e.dims.at(-1);this.generation_config.top_k>0&&(n=Math.min(this.generation_config.top_k,n));const r=this.getLogits(e,t),s=(0,i.getTopItems)(r,n),o=(0,i.softmax)(s.map((e=>e[1])));return Array.from({length:this.generation_config.num_beams},((e,t)=>[s[t][0],Math.log(o[t])]))}}},"./src/generation/stopping_criteria.js":
/*!*********************************************!*\
  !*** ./src/generation/stopping_criteria.js ***!
  \*********************************************/(e,t,n)=>{n.r(t),n.d(t,{EosTokenCriteria:()=>a,MaxLengthCriteria:()=>o,StoppingCriteria:()=>i,StoppingCriteriaList:()=>s});var r=n(/*! ../utils/generic.js */"./src/utils/generic.js");class i extends r.Callable{_call(e,t){throw Error("StoppingCriteria needs to be subclassed")}}class s extends r.Callable{constructor(){super(),this.criteria=[]}push(e){this.criteria.push(e)}extend(e){e instanceof s&&(e=e.criteria),this.criteria.push(...e)}_call(e,t){const n=new Array(e.length).fill(!1);for(const r of this.criteria){const i=r(e,t);for(let e=0;e<n.length;++e)n[e]||=i[e]}return n}[Symbol.iterator](){return this.criteria.values()}}class o extends i{constructor(e,t=null){super(),this.max_length=e,this.max_position_embeddings=t}_call(e){return e.map((e=>e.length>=this.max_length))}}class a extends i{constructor(e){super(),Array.isArray(e)||(e=[e]),this.eos_token_id=e}_call(e,t){return e.map((e=>this.eos_token_id.includes(e.at(-1))))}}},"./src/generation/streamers.js":
/*!*************************************!*\
  !*** ./src/generation/streamers.js ***!
  \*************************************/(e,t,n)=>{n.r(t),n.d(t,{BaseStreamer:()=>r});class r{put(e){throw Error("Not implemented")}end(){throw Error("Not implemented")}}},"./src/models.js":
/*!***********************!*\
  !*** ./src/models.js ***!
  \***********************/(e,t,n)=>{n.r(t),n.d(t,{ASTForAudioClassification:()=>en,ASTModel:()=>Jt,ASTPreTrainedModel:()=>Zt,AlbertForMaskedLM:()=>dt,AlbertForQuestionAnswering:()=>lt,AlbertForSequenceClassification:()=>at,AlbertModel:()=>ot,AlbertPreTrainedModel:()=>st,AutoModel:()=>uo,AutoModelForAudioClassification:()=>Co,AutoModelForAudioFrameClassification:()=>Eo,AutoModelForCTC:()=>So,AutoModelForCausalLM:()=>_o,AutoModelForDepthEstimation:()=>zo,AutoModelForDocumentQuestionAnswering:()=>Ao,AutoModelForImageClassification:()=>vo,AutoModelForImageFeatureExtraction:()=>Bo,AutoModelForImageMatting:()=>Fo,AutoModelForImageSegmentation:()=>xo,AutoModelForImageToImage:()=>Io,AutoModelForMaskGeneration:()=>$o,AutoModelForMaskedLM:()=>wo,AutoModelForObjectDetection:()=>To,AutoModelForQuestionAnswering:()=>yo,AutoModelForSemanticSegmentation:()=>Mo,AutoModelForSeq2SeqLM:()=>ho,AutoModelForSequenceClassification:()=>co,AutoModelForSpeechSeq2Seq:()=>fo,AutoModelForTextToSpectrogram:()=>mo,AutoModelForTextToWaveform:()=>go,AutoModelForTokenClassification:()=>po,AutoModelForVision2Seq:()=>bo,AutoModelForXVector:()=>Po,AutoModelForZeroShotObjectDetection:()=>ko,BartForConditionalGeneration:()=>vt,BartForSequenceClassification:()=>xt,BartModel:()=>bt,BartPretrainedModel:()=>yt,BaseModelOutput:()=>V,BeitForImageClassification:()=>br,BeitModel:()=>yr,BeitPreTrainedModel:()=>wr,BertForMaskedLM:()=>G,BertForQuestionAnswering:()=>H,BertForSequenceClassification:()=>q,BertForTokenClassification:()=>W,BertModel:()=>U,BertPreTrainedModel:()=>j,BlenderbotForConditionalGeneration:()=>Et,BlenderbotModel:()=>Pt,BlenderbotPreTrainedModel:()=>Ct,BlenderbotSmallForConditionalGeneration:()=>It,BlenderbotSmallModel:()=>Ft,BlenderbotSmallPreTrainedModel:()=>At,BloomForCausalLM:()=>Yn,BloomModel:()=>Kn,BloomPreTrainedModel:()=>Qn,CLIPModel:()=>un,CLIPPreTrainedModel:()=>dn,CLIPSegForImageSegmentation:()=>vn,CLIPSegModel:()=>bn,CLIPSegPreTrainedModel:()=>yn,CLIPTextModelWithProjection:()=>cn,CLIPVisionModelWithProjection:()=>pn,CamembertForMaskedLM:()=>ge,CamembertForQuestionAnswering:()=>ye,CamembertForSequenceClassification:()=>_e,CamembertForTokenClassification:()=>we,CamembertModel:()=>me,CamembertPreTrainedModel:()=>fe,CausalLMOutput:()=>jo,CausalLMOutputWithPast:()=>Uo,ChineseCLIPModel:()=>wn,ChineseCLIPPreTrainedModel:()=>_n,ClapAudioModelWithProjection:()=>fs,ClapModel:()=>ps,ClapPreTrainedModel:()=>cs,ClapTextModelWithProjection:()=>hs,CodeGenForCausalLM:()=>Rn,CodeGenModel:()=>Dn,CodeGenPreTrainedModel:()=>Ln,ConvBertForMaskedLM:()=>ie,ConvBertForQuestionAnswering:()=>ae,ConvBertForSequenceClassification:()=>se,ConvBertForTokenClassification:()=>oe,ConvBertModel:()=>re,ConvBertPreTrainedModel:()=>ne,ConvNextForImageClassification:()=>ti,ConvNextModel:()=>ei,ConvNextPreTrainedModel:()=>Jr,ConvNextV2ForImageClassification:()=>ii,ConvNextV2Model:()=>ri,ConvNextV2PreTrainedModel:()=>ni,DPTForDepthEstimation:()=>qr,DPTModel:()=>Gr,DPTPreTrainedModel:()=>Ur,DebertaForMaskedLM:()=>xe,DebertaForQuestionAnswering:()=>ke,DebertaForSequenceClassification:()=>Me,DebertaForTokenClassification:()=>Te,DebertaModel:()=>ve,DebertaPreTrainedModel:()=>be,DebertaV2ForMaskedLM:()=>Ce,DebertaV2ForQuestionAnswering:()=>Ae,DebertaV2ForSequenceClassification:()=>Pe,DebertaV2ForTokenClassification:()=>Ee,DebertaV2Model:()=>Se,DebertaV2PreTrainedModel:()=>$e,DeiTForImageClassification:()=>Ir,DeiTModel:()=>Fr,DeiTPreTrainedModel:()=>Ar,DepthAnythingForDepthEstimation:()=>Hr,DepthAnythingPreTrainedModel:()=>Wr,DetrForObjectDetection:()=>Mr,DetrForSegmentation:()=>Tr,DetrModel:()=>xr,DetrObjectDetectionOutput:()=>kr,DetrPreTrainedModel:()=>vr,DetrSegmentationOutput:()=>$r,Dinov2ForImageClassification:()=>ai,Dinov2Model:()=>oi,Dinov2PreTrainedModel:()=>si,DistilBertForMaskedLM:()=>Le,DistilBertForQuestionAnswering:()=>Oe,DistilBertForSequenceClassification:()=>ze,DistilBertForTokenClassification:()=>Be,DistilBertModel:()=>Ie,DistilBertPreTrainedModel:()=>Fe,DonutSwinModel:()=>Zr,DonutSwinPreTrainedModel:()=>Yr,EfficientNetForImageClassification:()=>$s,EfficientNetModel:()=>ks,EfficientNetPreTrainedModel:()=>Ts,ElectraForMaskedLM:()=>ue,ElectraForQuestionAnswering:()=>he,ElectraForSequenceClassification:()=>ce,ElectraForTokenClassification:()=>pe,ElectraModel:()=>de,ElectraPreTrainedModel:()=>le,EsmForMaskedLM:()=>Ne,EsmForSequenceClassification:()=>Ve,EsmForTokenClassification:()=>je,EsmModel:()=>Re,EsmPreTrainedModel:()=>De,FalconForCausalLM:()=>us,FalconModel:()=>ds,FalconPreTrainedModel:()=>ls,GLPNForDepthEstimation:()=>Kr,GLPNModel:()=>Qr,GLPNPreTrainedModel:()=>Xr,GPT2LMHeadModel:()=>Tn,GPT2Model:()=>Mn,GPT2PreTrainedModel:()=>xn,GPTBigCodeForCausalLM:()=>On,GPTBigCodeModel:()=>Bn,GPTBigCodePreTrainedModel:()=>zn,GPTJForCausalLM:()=>In,GPTJModel:()=>Fn,GPTJPreTrainedModel:()=>An,GPTNeoForCausalLM:()=>Sn,GPTNeoModel:()=>$n,GPTNeoPreTrainedModel:()=>kn,GPTNeoXForCausalLM:()=>En,GPTNeoXModel:()=>Pn,GPTNeoXPreTrainedModel:()=>Cn,HubertForCTC:()=>Vi,HubertForSequenceClassification:()=>ji,HubertModel:()=>Ni,HubertPreTrainedModel:()=>Ri,ImageMattingOutput:()=>Go,LlamaForCausalLM:()=>jn,LlamaModel:()=>Vn,LlamaPreTrainedModel:()=>Nn,LlavaForConditionalGeneration:()=>ln,LlavaPreTrainedModel:()=>an,LongT5ForConditionalGeneration:()=>mt,LongT5Model:()=>ft,LongT5PreTrainedModel:()=>ht,M2M100ForConditionalGeneration:()=>bi,M2M100Model:()=>yi,M2M100PreTrainedModel:()=>wi,MBartForCausalLM:()=>St,MBartForConditionalGeneration:()=>kt,MBartForSequenceClassification:()=>$t,MBartModel:()=>Tt,MBartPreTrainedModel:()=>Mt,MPNetForMaskedLM:()=>Ke,MPNetForQuestionAnswering:()=>Je,MPNetForSequenceClassification:()=>Ye,MPNetForTokenClassification:()=>Ze,MPNetModel:()=>Qe,MPNetPreTrainedModel:()=>Xe,MT5ForConditionalGeneration:()=>wt,MT5Model:()=>_t,MT5PreTrainedModel:()=>gt,MarianMTModel:()=>_i,MarianModel:()=>gi,MarianPreTrainedModel:()=>mi,MaskedLMOutput:()=>No,MistralForCausalLM:()=>is,MistralModel:()=>rs,MistralPreTrainedModel:()=>ns,MobileBertForMaskedLM:()=>qe,MobileBertForQuestionAnswering:()=>He,MobileBertForSequenceClassification:()=>We,MobileBertModel:()=>Ge,MobileBertPreTrainedModel:()=>Ue,MobileViTForImageClassification:()=>cr,MobileViTModel:()=>ur,MobileViTPreTrainedModel:()=>dr,ModelOutput:()=>N,MptForCausalLM:()=>er,MptModel:()=>Jn,MptPreTrainedModel:()=>Zn,MusicgenForCausalLM:()=>Ps,MusicgenForConditionalGeneration:()=>Es,MusicgenModel:()=>Cs,MusicgenPreTrainedModel:()=>Ss,NomicBertModel:()=>Q,NomicBertPreTrainedModel:()=>X,OPTForCausalLM:()=>rr,OPTModel:()=>nr,OPTPreTrainedModel:()=>tr,OwlViTForObjectDetection:()=>fr,OwlViTModel:()=>hr,OwlViTPreTrainedModel:()=>pr,Owlv2ForObjectDetection:()=>_r,Owlv2Model:()=>gr,Owlv2PreTrainedModel:()=>mr,PhiForCausalLM:()=>Xn,PhiModel:()=>Hn,PhiPreTrainedModel:()=>Wn,PreTrainedModel:()=>R,PretrainedMixin:()=>As,QuestionAnsweringModelOutput:()=>Vo,Qwen2ForCausalLM:()=>qn,Qwen2Model:()=>Gn,Qwen2PreTrainedModel:()=>Un,ResNetForImageClassification:()=>Or,ResNetModel:()=>Br,ResNetPreTrainedModel:()=>zr,RoFormerForMaskedLM:()=>Z,RoFormerForQuestionAnswering:()=>te,RoFormerForSequenceClassification:()=>J,RoFormerForTokenClassification:()=>ee,RoFormerModel:()=>Y,RoFormerPreTrainedModel:()=>K,RobertaForMaskedLM:()=>Ot,RobertaForQuestionAnswering:()=>Rt,RobertaForSequenceClassification:()=>Lt,RobertaForTokenClassification:()=>Dt,RobertaModel:()=>Bt,RobertaPreTrainedModel:()=>zt,SamImageSegmentationOutput:()=>fi,SamModel:()=>hi,SamPreTrainedModel:()=>pi,SegformerForImageClassification:()=>ys,SegformerForSemanticSegmentation:()=>bs,SegformerModel:()=>ws,SegformerPreTrainedModel:()=>_s,Seq2SeqLMOutput:()=>Oo,SequenceClassifierOutput:()=>Lo,SiglipModel:()=>fn,SiglipPreTrainedModel:()=>hn,SiglipTextModel:()=>mn,SiglipVisionModel:()=>gn,SpeechT5ForSpeechToText:()=>Yi,SpeechT5ForTextToSpeech:()=>Zi,SpeechT5HifiGan:()=>Ji,SpeechT5Model:()=>Ki,SpeechT5PreTrainedModel:()=>Qi,SqueezeBertForMaskedLM:()=>nt,SqueezeBertForQuestionAnswering:()=>it,SqueezeBertForSequenceClassification:()=>rt,SqueezeBertModel:()=>tt,SqueezeBertPreTrainedModel:()=>et,StableLmForCausalLM:()=>Ms,StableLmModel:()=>xs,StableLmPreTrainedModel:()=>vs,Starcoder2ForCausalLM:()=>as,Starcoder2Model:()=>os,Starcoder2PreTrainedModel:()=>ss,Swin2SRForImageSuperResolution:()=>jr,Swin2SRModel:()=>Vr,Swin2SRPreTrainedModel:()=>Nr,SwinForImageClassification:()=>Rr,SwinModel:()=>Dr,SwinPreTrainedModel:()=>Lr,T5ForConditionalGeneration:()=>pt,T5Model:()=>ct,T5PreTrainedModel:()=>ut,TableTransformerForObjectDetection:()=>Pr,TableTransformerModel:()=>Cr,TableTransformerObjectDetectionOutput:()=>Er,TableTransformerPreTrainedModel:()=>Sr,TokenClassifierOutput:()=>Ro,TrOCRForCausalLM:()=>ts,TrOCRPreTrainedModel:()=>es,UniSpeechForCTC:()=>Ci,UniSpeechForSequenceClassification:()=>Pi,UniSpeechModel:()=>Si,UniSpeechPreTrainedModel:()=>$i,UniSpeechSatForAudioFrameClassification:()=>zi,UniSpeechSatForCTC:()=>Fi,UniSpeechSatForSequenceClassification:()=>Ii,UniSpeechSatModel:()=>Ai,UniSpeechSatPreTrainedModel:()=>Ei,ViTForImageClassification:()=>or,ViTModel:()=>sr,ViTPreTrainedModel:()=>ir,VisionEncoderDecoderModel:()=>on,VitMatteForImageMatting:()=>lr,VitMattePreTrainedModel:()=>ar,VitsModel:()=>gs,VitsModelOutput:()=>qo,VitsPreTrainedModel:()=>ms,Wav2Vec2BertForCTC:()=>Li,Wav2Vec2BertForSequenceClassification:()=>Di,Wav2Vec2BertModel:()=>Oi,Wav2Vec2BertPreTrainedModel:()=>Bi,Wav2Vec2ForAudioFrameClassification:()=>ki,Wav2Vec2ForCTC:()=>Mi,Wav2Vec2ForSequenceClassification:()=>Ti,Wav2Vec2Model:()=>xi,Wav2Vec2PreTrainedModel:()=>vi,WavLMForAudioFrameClassification:()=>Xi,WavLMForCTC:()=>qi,WavLMForSequenceClassification:()=>Wi,WavLMForXVector:()=>Hi,WavLMModel:()=>Gi,WavLMPreTrainedModel:()=>Ui,WhisperForConditionalGeneration:()=>sn,WhisperModel:()=>nn,WhisperPreTrainedModel:()=>tn,XLMForQuestionAnswering:()=>qt,XLMForSequenceClassification:()=>Ut,XLMForTokenClassification:()=>Gt,XLMModel:()=>Vt,XLMPreTrainedModel:()=>Nt,XLMRobertaForMaskedLM:()=>Xt,XLMRobertaForQuestionAnswering:()=>Yt,XLMRobertaForSequenceClassification:()=>Qt,XLMRobertaForTokenClassification:()=>Kt,XLMRobertaModel:()=>Ht,XLMRobertaPreTrainedModel:()=>Wt,XLMWithLMHeadModel:()=>jt,XVectorOutput:()=>Do,YolosForObjectDetection:()=>ui,YolosModel:()=>di,YolosObjectDetectionOutput:()=>ci,YolosPreTrainedModel:()=>li,getPerf:()=>E});var r=n(/*! ./configs.js */"./src/configs.js"),i=n(/*! ./backends/onnx.js */"./src/backends/onnx.js"),s=n(/*! ./utils/dtypes.js */"./src/utils/dtypes.js"),o=n(/*! ./utils/generic.js */"./src/utils/generic.js"),a=n(/*! ./utils/core.js */"./src/utils/core.js"),l=n(/*! ./utils/hub.js */"./src/utils/hub.js"),d=n(/*! ./generation/logits_process.js */"./src/generation/logits_process.js"),u=n(/*! ./generation/configuration_utils.js */"./src/generation/configuration_utils.js"),c=n(/*! ./utils/tensor.js */"./src/utils/tensor.js"),p=n(/*! ./utils/maths.js */"./src/utils/maths.js"),h=n(/*! ./generation/stopping_criteria.js */"./src/generation/stopping_criteria.js"),f=n(/*! ./generation/logits_sampler.js */"./src/generation/logits_sampler.js");const m=0,g=1,_=2,w=3,y=4,b=5,v=6,x=7,M=new Map,T=new Map,k=new Map;async function $(e,t,n){const r=Object.keys(t),o=await Promise.all(r.map((async r=>async function(e,t,n){let r=n.device;r&&"string"!=typeof r&&(r.hasOwnProperty(t)?r=r[t]:(console.warn(`Device not specified for ${t}. Using the default device.`),r=null));const o=(0,i.deviceToExecutionProviders)(r);console.log("- executionProviders -"),console.log(o);let a=n.dtype;if("string"!=typeof a&&(a&&a.hasOwnProperty(t)?a=a[t]:(a=s.DEFAULT_DEVICE_DTYPE_MAPPING[o[0]],console.warn(`Dtype not specified for ${t}. Using the default dtype: ${a}.`))),!s.DEFAULT_DTYPE_SUFFIX_MAPPING.hasOwnProperty(a))throw new Error(`Invalid dtype: ${a}. Should be one of: ${Object.keys(s.DATA_TYPES).join(", ")}`);if(a===s.DATA_TYPES.fp16&&!await(0,s.isFp16Supported)())throw new Error("The device does not support fp16.");const d=s.DEFAULT_DTYPE_SUFFIX_MAPPING[a],u=`${n.subfolder??""}/${t}${d}.onnx`,c=await(0,l.getModelFile)(e,u,!0,n),p={...n.session_options}??{};if(p.executionProviders??=o,void 0!==p.externalData)for(let t=0;t<p.externalData.length;++t){const r=p.externalData[t];if("string"==typeof r.data){const t=await(0,l.getModelFile)(e,r.data,!0,n);r.data=t}}return{buffer:c,session_options:p}}(e,t[r],n)))),a={};for(let e=0;e<r.length;++e){const{buffer:t,session_options:n}=o[e];console.log(n);const s=await(0,i.createInferenceSession)(t,n);a[r[e]]=s}return a}const S=e=>new URLSearchParams(window.location.search).get(e);let C={warmup:0,inference:[],throughput:0},P=1;function E(){return C}async function A(e,t){C={warmup:0,inference:[],throughput:0};const n=function(e,t){const n=Object.create(null),r=[];for(const s of e.inputNames){const e=t[s];e instanceof c.Tensor?n[s]=(0,i.isONNXProxy)()?e.clone():e:r.push(s)}if(r.length>0)throw new Error(`An error occurred during model execution: "Missing the following inputs: ${r.join(", ")}.`);const s=Object.keys(t).length,o=e.inputNames.length;if(s>o){let n=Object.keys(t).filter((t=>!e.inputNames.includes(t)));console.warn(`WARNING: Too many inputs were provided (${s} > ${o}). The following inputs will be ignored: "${n.join(", ")}".`)}return n}(e,t);try{const t=Object.fromEntries(Object.entries(n).map((([e,t])=>[e,t.ort_tensor])));let r,i=1;console.log("-- number of test runs --"),P=S("run")?parseInt(S("run")):1,console.log(P);let s,o,a=performance.now(),l=[];for(let n=0;n<i+P;n++)s=performance.now(),r=await e.run(t),o=performance.now()-s,0==n?C.warmup=o:l.push(o),console.log(`Session run time: ${o}ms`);C.inference=l,C.throughput=parseFloat((1e3/((performance.now()-a)/(i+P))).toFixed(2)),r=F(r);for(const[e,t]of Object.entries(n))e.startsWith("past_key_values")&&t.dispose();return r}catch(e){throw console.error(`An error occurred during model execution: "${e}".`),console.error("Inputs given to model:",n),e}}function F(e){for(let t in e)(0,i.isONNXTensor)(e[t])?e[t]=new c.Tensor(e[t]):"object"==typeof e[t]&&F(e[t]);return e}function I(e){return new c.Tensor("bool",[e],[1])}async function z(e,t){let{encoder_outputs:n,past_key_values:r}=t;if(!n){const r=(0,a.pick)(t,e.sessions.model.inputNames);n=(await B(e,r)).last_hidden_state}const{input_ids:i,decoder_input_ids:s,...o}=t;o.input_ids=s,o.encoder_hidden_states=n,e.sessions.decoder_model_merged.inputNames.includes("encoder_attention_mask")&&(o.encoder_attention_mask=t.attention_mask);return await O(e,o,!0)}async function B(e,t){const n=e.sessions.model,r=Object.create(null);for(const e of n.inputNames)r[e]=t[e];return n.inputNames.includes("token_type_ids")&&!r.token_type_ids&&(r.token_type_ids=new c.Tensor("int64",new BigInt64Array(r.input_ids.data.length),r.input_ids.dims)),await A(n,r)}async function O(e,t,n=!1){const r=e.sessions[n?"decoder_model_merged":"model"],{past_key_values:i,...s}=t;r.inputNames.includes("use_cache_branch")&&(s.use_cache_branch=I(!!i)),e.addPastKeyValues(s,i);const o=(0,a.pick)(s,r.inputNames);return await A(r,o)}function L(e,t,n,r){if(e.sessions.model.inputNames.includes("position_ids")&&n.attention_mask&&!n.position_ids){const[e,t]=n.attention_mask.dims,r=new BigInt64Array(n.attention_mask.data.length);for(let i=0;i<e;++i){const e=i*t;let s=BigInt(0);for(let i=0;i<t;++i){const t=e+i;0n===n.attention_mask.data[t]?r[t]=BigInt(1):(r[t]=s,s+=n.attention_mask.data[t])}}n.position_ids=new c.Tensor("int64",r,n.attention_mask.dims),n.past_key_values&&(n.position_ids=n.position_ids.slice(null,-1).unsqueeze_(-1))}return n}function D(e,t,n,r){const{...i}=n;return n.past_key_values&&(t=t.map((e=>[e.at(-1)]))),i.decoder_input_ids=function(e){if(e instanceof c.Tensor)return e;if(0===e.length)throw Error("items must be non-empty");if(Array.isArray(e[0])){if(e.some((t=>t.length!==e[0].length)))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");return new c.Tensor("int64",BigInt64Array.from(e.flat().map((e=>BigInt(e)))),[e.length,e[0].length])}return new c.Tensor("int64",BigInt64Array.from(e.map((e=>BigInt(e)))),[1,e.length])}(t),i}class R extends o.Callable{main_input_name="input_ids";forward_params=["input_ids","attention_mask"];constructor(e,t){super(),this.config=e,this.sessions=t;const n=k.get(this.constructor),r=M.get(n);this.can_generate=!1,this._forward=null,this._prepare_inputs_for_generation=null,r===y?(this.can_generate=!0,this._forward=O,this._prepare_inputs_for_generation=L):r===_||r===w||r===x?(this.can_generate=!0,this._forward=z,this._prepare_inputs_for_generation=D):r===g?this._forward=z:r===v?(this.can_generate=!0,console.warn("TODO: Implement visionDecoderForward")):this._forward=B}async dispose(){const e=[];for(let t of Object.keys(this)){let n=this[t];void 0!==n?.handler?.dispose&&e.push(n.handler.dispose())}return await Promise.all(e)}static async from_pretrained(e,{progress_callback:t=null,config:n=null,cache_dir:i=null,local_files_only:s=!1,revision:o="main",model_file_name:a=null,subfolder:d="onnx",device:u=null,dtype:c=null,session_options:p={}}={}){let h={progress_callback:t,config:n,cache_dir:i,local_files_only:s,revision:o,model_file_name:a,subfolder:d,device:u,dtype:c,session_options:p};const f=k.get(this),T=M.get(f);let S;return T===y?S=await Promise.all([r.AutoConfig.from_pretrained(e,h),$(e,{model:h.model_file_name??"model"},h),(0,l.getModelJSON)(e,"generation_config.json",!1,h)]):T===_||T===w?S=await Promise.all([r.AutoConfig.from_pretrained(e,h),$(e,{model:"encoder_model",decoder_model_merged:"decoder_model_merged"},h),(0,l.getModelJSON)(e,"generation_config.json",!1,h)]):T===b?S=await Promise.all([r.AutoConfig.from_pretrained(e,h),$(e,{model:"vision_encoder",prompt_encoder_mask_decoder:"prompt_encoder_mask_decoder"},h)]):T===g?S=await Promise.all([r.AutoConfig.from_pretrained(e,h),$(e,{model:"encoder_model",decoder_model_merged:"decoder_model_merged"},h)]):T===v?S=await Promise.all([r.AutoConfig.from_pretrained(e,h),$(e,{embed_tokens:"embed_tokens",vision_encoder:"vision_encoder",decoder_model_merged:"decoder_model_merged"},h),(0,l.getModelJSON)(e,"generation_config.json",!1,h)]):T===x?S=await Promise.all([r.AutoConfig.from_pretrained(e,h),$(e,{model:"text_encoder",decoder_model_merged:"decoder_model_merged",encodec_decode:"encodec_decode"},h),(0,l.getModelJSON)(e,"generation_config.json",!1,h)]):(T!==m&&console.warn(`Model type for '${f??n?.model_type}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`),S=await Promise.all([r.AutoConfig.from_pretrained(e,h),$(e,{model:h.model_file_name??"model"},h)])),new this(...S)}async _call(e){return await this.forward(e)}async forward(e){return await this._forward(this,e)}_get_logits_warper(e){const t=new d.LogitsProcessorList;return null!==e.temperature&&1!==e.temperature&&t.push(new d.TemperatureLogitsWarper(e.temperature)),null!==e.top_k&&0!==e.top_k&&t.push(new d.TopKLogitsWarper(e.top_k)),null!==e.top_p&&e.top_p<1&&t.push(new d.TopPLogitsWarper(e.top_p)),t}_get_logits_processor(e,t,n=null){const r=new d.LogitsProcessorList;if(null!==e.repetition_penalty&&1!==e.repetition_penalty&&r.push(new d.RepetitionPenaltyLogitsProcessor(e.repetition_penalty)),null!==e.no_repeat_ngram_size&&e.no_repeat_ngram_size>0&&r.push(new d.NoRepeatNGramLogitsProcessor(e.no_repeat_ngram_size)),null!==e.bad_words_ids&&r.push(new d.NoBadWordsLogitsProcessor(e.bad_words_ids,e.eos_token_id)),null!==e.min_length&&null!==e.eos_token_id&&e.min_length>0&&r.push(new d.MinLengthLogitsProcessor(e.min_length,e.eos_token_id)),null!==e.min_new_tokens&&null!==e.eos_token_id&&e.min_new_tokens>0&&r.push(new d.MinNewTokensLengthLogitsProcessor(t,e.min_new_tokens,e.eos_token_id)),null!==e.forced_bos_token_id&&r.push(new d.ForcedBOSTokenLogitsProcessor(e.forced_bos_token_id)),null!==e.forced_eos_token_id&&r.push(new d.ForcedEOSTokenLogitsProcessor(e.max_length,e.forced_eos_token_id)),null!==e.begin_suppress_tokens){let n=t>1||null===e.forced_bos_token_id?t:t+1;null!==e.forced_decoder_ids&&(n+=e.forced_decoder_ids[e.forced_decoder_ids.length-1][0]),r.push(new d.SuppressTokensAtBeginLogitsProcessor(e.begin_suppress_tokens,n))}return null!==e.guidance_scale&&e.guidance_scale>1&&r.push(new d.ClassifierFreeGuidanceLogitsProcessor(e.guidance_scale)),null!==n&&r.extend(n),r}_prepare_generation_config(e,t){const n=new u.GenerationConfig(this.config);return"generation_config"in this&&Object.assign(n,this.generation_config),e&&Object.assign(n,e),t&&Object.assign(n,(0,a.pick)(t,Object.getOwnPropertyNames(n))),n}_get_stopping_criteria(e,t=null){const n=new h.StoppingCriteriaList;return null!==e.max_length&&n.push(new h.MaxLengthCriteria(e.max_length,this.config.max_position_embeddings??null)),null!==e.eos_token_id&&n.push(new h.EosTokenCriteria(e.eos_token_id)),t&&n.extend(t),n}_validate_model_class(){if(!this.can_generate){const e=[Vs,Gs,Ns,Bs],t=k.get(this.constructor),n=new Set,r=this.config.model_type;for(const t of e){const e=t.get(r);e&&n.add(e[0])}let i=`The current model class (${t}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`;throw n.size>0&&(i+=` Please use the following class instead: ${[...n].join(", ")}`),Error(i)}}prepare_inputs_for_generation(...e){return this._prepare_inputs_for_generation(this,...e)}_update_model_kwargs_for_generation({generated_input_ids:e,outputs:t,model_inputs:n,is_encoder_decoder:r}){return n.past_key_values=this.getPastKeyValues(t,n.past_key_values),n.input_ids=new c.Tensor("int64",e,[e.length,1]),r||(n.attention_mask=(0,c.cat)([n.attention_mask,(0,c.ones)([n.attention_mask.dims[0],1])],1)),n.position_ids=null,n}_prepare_model_inputs({inputs:e,bos_token_id:t,model_kwargs:n}){const r=(0,a.pick)(n,this.forward_params),i=this.main_input_name;if(i in r){if(e)throw new Error("`inputs`: {inputs}` were passed alongside {input_name} which is not allowed. Make sure to either pass {inputs} or {input_name}=...")}else r[i]=e;return{inputs_tensor:r[i],model_inputs:r,model_input_name:i}}async _prepare_encoder_decoder_kwargs_for_generation({inputs_tensor:e,model_inputs:t,model_input_name:n,generation_config:r}){const i=(0,a.pick)(t,this.sessions.model.inputNames);let{last_hidden_state:s}=await B(this,i);return null!==r.guidance_scale&&r.guidance_scale>1&&(s=(0,c.cat)([s,(0,c.full_like)(s,0)],0),"attention_mask"in t&&(t.attention_mask=(0,c.cat)([t.attention_mask,(0,c.zeros_like)(t.attention_mask)],0))),t.encoder_outputs=s,t}_prepare_decoder_input_ids_for_generation({batch_size:e,model_input_name:t,model_kwargs:n,decoder_start_token_id:r,bos_token_id:i,generation_config:s}){let o;if(r=r??i,"musicgen"===this.config.model_type)o=new Array(e*this.config.decoder.num_codebooks).fill(r);else if(Array.isArray(r)){if(r.length!==e)throw new Error(`\`decoder_start_token_id\` expcted to have length ${e} but got ${r.length}`);o=r}else o=new Array(e).fill(r);const a=new c.Tensor("int64",o,[o.length,1]);return n.decoder_attention_mask=(0,c.ones_like)(a),{input_ids:a,model_inputs:n}}async generate({inputs:e=null,generation_config:t=null,logits_processor:n=null,stopping_criteria:r=null,streamer:i=null,...s}){this._validate_model_class(),t=this._prepare_generation_config(t,s);let{inputs_tensor:o,model_inputs:a,model_input_name:l}=this._prepare_model_inputs({inputs:e,model_kwargs:s});const d=this.config.is_encoder_decoder;let u;d&&("encoder_outputs"in a||(a=await this._prepare_encoder_decoder_kwargs_for_generation({inputs_tensor:o,model_inputs:a,model_input_name:l,generation_config:t}))),d?({input_ids:u,model_inputs:a}=this._prepare_decoder_input_ids_for_generation({batch_size:a[l].dims.at(0),model_input_name:l,model_kwargs:a,decoder_start_token_id:t.decoder_start_token_id,bos_token_id:t.bos_token_id,generation_config:t})):u=a[l];let p=u.dims.at(-1);null!==t.max_new_tokens&&(t.max_length=p+t.max_new_tokens);const h=this._get_logits_processor(t,p,n),m=this._get_stopping_criteria(t,r),g=a[l].dims.at(0),_=f.LogitsSampler.getSampler(t),w=new Array(g).fill(0),y=u.tolist();for(i&&i.put(y);;){a=this.prepare_inputs_for_generation(y,a,t);const e=await this.forward(a),n=h(y,e.logits.slice(null,-1,null)),r=[];for(let e=0;e<n.dims.at(0);++e){const t=_(n[e]);for(const[n,i]of t){const t=BigInt(n);w[e]+=i,y[e].push(t),r.push(t)}}i&&i.put(y);if(m(y).every((e=>e)))break;a=this._update_model_kwargs_for_generation({generated_input_ids:r,outputs:e,model_inputs:a,is_encoder_decoder:d})}return i&&i.end(),new c.Tensor("int64",y.flat(),[y.length,y[0].length])}addAttentionsToBeam(e,t){if(this.config.is_encoder_decoder){if(!t.cross_attentions||0===t.cross_attentions.length)throw Error("`output_attentions` is true, but the model did not produce cross-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.cross_attentions||(e.cross_attentions=[]),e.cross_attentions.push(t.cross_attentions)}if(!t.decoder_attentions||0===t.decoder_attentions.length)throw Error("`output_attentions` is true, but the model did not produce decoder-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.decoder_attentions||(e.decoder_attentions=[]),e.decoder_attentions.push(t.decoder_attentions)}groupBeams(e){const t=Object.create(null);for(const n of e)void 0===t[n.id]?t[n.id]=[n]:t[n.id].push(n);return Object.values(t)}getPastKeyValues(e,t){const n=Object.create(null);for(const r in e)if(r.startsWith("present")){let i=r.replace("present","past_key_values");t&&r.includes("encoder")?n[i]=t[i]:n[i]=e[r]}return n}getAttentions(e){const t=Object.create(null);for(const n of["cross_attentions","decoder_attentions"]){const r=[];for(const t in e)if(t.startsWith(n)){r[t.split(".").pop()]=e[t]}t[n]=r}return t}addPastKeyValues(e,t){if(t)Object.assign(e,t);else{const t=1,n="float32",r=[];if(this.config.is_encoder_decoder&&(this.add_encoder_pkv??1)){let i=[t,this.num_encoder_heads,0,this.encoder_dim_kv],s=[t,this.num_decoder_heads,0,this.decoder_dim_kv];for(let t=0;t<this.num_decoder_layers;++t)e[`past_key_values.${t}.encoder.key`]=new c.Tensor(n,r,i),e[`past_key_values.${t}.encoder.value`]=new c.Tensor(n,r,i),e[`past_key_values.${t}.decoder.key`]=new c.Tensor(n,r,s),e[`past_key_values.${t}.decoder.value`]=new c.Tensor(n,r,s)}else if("falcon"===this.config.model_type){let i=[t*this.num_heads,0,this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key`]=new c.Tensor(n,r,i),e[`past_key_values.${t}.value`]=new c.Tensor(n,r,i)}else if(this.config.multi_query){let i=[t*this.num_heads,0,2*this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key_value`]=new c.Tensor(n,r,i)}else if("bloom"===this.config.model_type){let i=[t*this.num_heads,this.dim_kv,0],s=[t*this.num_heads,0,this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key`]=new c.Tensor(n,r,i),e[`past_key_values.${t}.value`]=new c.Tensor(n,r,s)}else{let i=[t,this.num_heads,0,this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key`]=new c.Tensor(n,r,i),e[`past_key_values.${t}.value`]=new c.Tensor(n,r,i)}}}}class N{}class V extends N{constructor({last_hidden_state:e,hidden_states:t=null,attentions:n=null}){super(),this.last_hidden_state=e,this.hidden_states=t,this.attentions=n}}class j extends R{}class U extends j{}class G extends j{async _call(e){return new No(await super._call(e))}}class q extends j{async _call(e){return new Lo(await super._call(e))}}class W extends j{async _call(e){return new Ro(await super._call(e))}}class H extends j{async _call(e){return new Vo(await super._call(e))}}class X extends R{}class Q extends X{}class K extends R{}class Y extends K{}class Z extends K{async _call(e){return new No(await super._call(e))}}class J extends K{async _call(e){return new Lo(await super._call(e))}}class ee extends K{async _call(e){return new Ro(await super._call(e))}}class te extends K{async _call(e){return new Vo(await super._call(e))}}class ne extends R{}class re extends ne{}class ie extends ne{async _call(e){return new No(await super._call(e))}}class se extends ne{async _call(e){return new Lo(await super._call(e))}}class oe extends ne{async _call(e){return new Ro(await super._call(e))}}class ae extends ne{async _call(e){return new Vo(await super._call(e))}}class le extends R{}class de extends le{}class ue extends le{async _call(e){return new No(await super._call(e))}}class ce extends le{async _call(e){return new Lo(await super._call(e))}}class pe extends le{async _call(e){return new Ro(await super._call(e))}}class he extends le{async _call(e){return new Vo(await super._call(e))}}class fe extends R{}class me extends fe{}class ge extends fe{async _call(e){return new No(await super._call(e))}}class _e extends fe{async _call(e){return new Lo(await super._call(e))}}class we extends fe{async _call(e){return new Ro(await super._call(e))}}class ye extends fe{async _call(e){return new Vo(await super._call(e))}}class be extends R{}class ve extends be{}class xe extends be{async _call(e){return new No(await super._call(e))}}class Me extends be{async _call(e){return new Lo(await super._call(e))}}class Te extends be{async _call(e){return new Ro(await super._call(e))}}class ke extends be{async _call(e){return new Vo(await super._call(e))}}class $e extends R{}class Se extends $e{}class Ce extends $e{async _call(e){return new No(await super._call(e))}}class Pe extends $e{async _call(e){return new Lo(await super._call(e))}}class Ee extends $e{async _call(e){return new Ro(await super._call(e))}}class Ae extends $e{async _call(e){return new Vo(await super._call(e))}}class Fe extends R{}class Ie extends Fe{}class ze extends Fe{async _call(e){return new Lo(await super._call(e))}}class Be extends Fe{async _call(e){return new Ro(await super._call(e))}}class Oe extends Fe{async _call(e){return new Vo(await super._call(e))}}class Le extends Fe{async _call(e){return new No(await super._call(e))}}class De extends R{}class Re extends De{}class Ne extends De{async _call(e){return new No(await super._call(e))}}class Ve extends De{async _call(e){return new Lo(await super._call(e))}}class je extends De{async _call(e){return new Ro(await super._call(e))}}class Ue extends R{}class Ge extends Ue{}class qe extends Ue{async _call(e){return new No(await super._call(e))}}class We extends Ue{async _call(e){return new Lo(await super._call(e))}}class He extends Ue{async _call(e){return new Vo(await super._call(e))}}class Xe extends R{}class Qe extends Xe{}class Ke extends Xe{async _call(e){return new No(await super._call(e))}}class Ye extends Xe{async _call(e){return new Lo(await super._call(e))}}class Ze extends Xe{async _call(e){return new Ro(await super._call(e))}}class Je extends Xe{async _call(e){return new Vo(await super._call(e))}}class et extends R{}class tt extends et{}class nt extends et{async _call(e){return new No(await super._call(e))}}class rt extends et{async _call(e){return new Lo(await super._call(e))}}class it extends et{async _call(e){return new Vo(await super._call(e))}}class st extends R{}class ot extends st{}class at extends st{async _call(e){return new Lo(await super._call(e))}}class lt extends st{async _call(e){return new Vo(await super._call(e))}}class dt extends st{async _call(e){return new No(await super._call(e))}}class ut extends R{forward_params=["input_ids","attention_mask","encoder_outputs","decoder_input_ids","decoder_attention_mask","past_key_values"];constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}class ct extends ut{}class pt extends ut{}class ht extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}class ft extends ht{}class mt extends ht{}class gt extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}class _t extends gt{}class wt extends gt{}class yt extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class bt extends yt{}class vt extends yt{}class xt extends yt{async _call(e){return new Lo(await super._call(e))}}class Mt extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class Tt extends Mt{}class kt extends Mt{}class $t extends Mt{async _call(e){return new Lo(await super._call(e))}}class St extends Mt{constructor(e,t,n){super(e,t,n),this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class Ct extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class Pt extends Ct{}class Et extends Ct{}class At extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class Ft extends At{}class It extends At{}class zt extends R{}class Bt extends zt{}class Ot extends zt{async _call(e){return new No(await super._call(e))}}class Lt extends zt{async _call(e){return new Lo(await super._call(e))}}class Dt extends zt{async _call(e){return new Ro(await super._call(e))}}class Rt extends zt{async _call(e){return new Vo(await super._call(e))}}class Nt extends R{}class Vt extends Nt{}class jt extends Nt{async _call(e){return new No(await super._call(e))}}class Ut extends Nt{async _call(e){return new Lo(await super._call(e))}}class Gt extends Nt{async _call(e){return new Ro(await super._call(e))}}class qt extends Nt{async _call(e){return new Vo(await super._call(e))}}class Wt extends R{}class Ht extends Wt{}class Xt extends Wt{async _call(e){return new No(await super._call(e))}}class Qt extends Wt{async _call(e){return new Lo(await super._call(e))}}class Kt extends Wt{async _call(e){return new Ro(await super._call(e))}}class Yt extends Wt{async _call(e){return new Vo(await super._call(e))}}class Zt extends R{}class Jt extends Zt{}class en extends Zt{}class tn extends R{requires_attention_mask=!1;main_input_name="input_features";forward_params=["input_features","attention_mask","decoder_input_ids","decoder_attention_mask","past_key_values"];constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class nn extends tn{}class rn extends u.GenerationConfig{return_timestamps=null;return_token_timestamps=null;num_frames=null;alignment_heads=null;task=null;language=null}class sn extends tn{_retrieve_init_tokens(e){e.decoder_start_token_id;throw new Error("Not implemented yet")}async generate({inputs:e=null,generation_config:t=null,logits_processor:n=null,stopping_criteria:r=null,language:i=null,task:s=null,...o}){throw new Error("WhisperForConditionalGeneration.generate is not yet in Transformers.js v3.")}_extract_token_timestamps(e,t,n=null,r=.02){if(!e.cross_attentions)throw new Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`.");let i=this.config.median_filter_width;void 0===i&&(console.warn("Model config has no `median_filter_width`, using default value of 7."),i=7);const s=e.cross_attentions.map((e=>{let r=Array.from({length:this.config.decoder_layers},((t,n)=>(0,c.cat)(e.map((e=>e[n])),2))),s=(0,c.stack)(t.map((([e,t])=>n?r[e].slice(null,t,null,[0,n]):r[e].slice(null,t))));s=s.transpose(1,0,2,3);let[o,a]=(0,c.std_mean)(s,-2,0,!0),l=s.clone();for(let e=0;e<l.dims[0];++e){let t=l[e];for(let n=0;n<t.dims[0];++n){let r=t[n];const s=o[e][n][0],l=a[e][n][0];for(let e=0;e<r.dims[0];++e){let t=r[e];for(let e=0;e<t.data.length;++e)t.data[e]=(t.data[e]-l.data[e])/s.data[e];t.data.set((0,p.medianFilter)(t.data,i))}}}return(0,c.mean)(l,1)})),o=[e.sequences.length,e.sequences[0].length],l=new c.Tensor("float32",new Float32Array(o[0]*o[1]),o);for(let e=0;e<o[0];++e){const t=s[e].neg().squeeze_(0);let[n,i]=(0,c.dynamicTimeWarping)(t),o=Array.from({length:n.length-1},((e,t)=>n[t+1]-n[t])),d=(0,a.mergeArrays)([1],o).map((e=>!!e)),u=[];for(let e=0;e<d.length;++e)d[e]&&u.push(i[e]*r);l[e].data.set(u,1)}return l}}class on extends R{main_input_name="pixel_values";constructor(e,t,n){super(e,t),this.generation_config=n;const r=this.config.encoder,i=this.config.decoder,s=r.model_type;(Fs.get(s)??Is.get(s))||console.warn(`Model type for encoder '${s}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`);const o=Vs.get(i.model_type);if(!o)throw new Error(`Unable to construct \`VisionEncoderDecoder\` due to unsupported decoder: "${this.config.decoder.model_type}"`);const a=new(0,o[1])(i,{},n);this.add_encoder_pkv="num_decoder_layers"in a,this.add_encoder_pkv?(this.num_decoder_layers=a.num_decoder_layers,this.num_decoder_heads=a.num_decoder_heads,this.decoder_dim_kv=a.decoder_dim_kv,this.num_encoder_layers=a.num_encoder_layers,this.num_encoder_heads=a.num_encoder_heads,this.encoder_dim_kv=a.encoder_dim_kv):(this.num_layers=a.num_layers,this.num_heads=a.num_heads,this.dim_kv=a.dim_kv)}}class an extends R{forward_params=["input_ids","past_key_values","pixel_values","attention_mask"];constructor(e,t,n){super(e,t),this.generation_config=n;const r=this.config.text_config;this.config.pad_token_id=r.eos_token_id,this.num_heads=r.num_attention_heads,this.num_layers=r.num_hidden_layers,this.dim_kv=r.hidden_size/this.num_heads}}class ln extends an{async encode_image({pixel_values:e}){return(await A(this.sessions.vision_encoder,{pixel_values:e})).image_features}async encode_text({input_ids:e}){return(await A(this.sessions.embed_tokens,{input_ids:e})).inputs_embeds}_merge_input_ids_with_image_features({inputs_embeds:e,image_features:t,input_ids:n,attention_mask:r}){const i=this.config.image_token_index,s=n.tolist().map((e=>e.findIndex((e=>e==i)))),o=s.every((e=>-1===e)),a=s.every((e=>-1!==e));if(!o&&!a)throw new Error("Every input should contain either 0 or 1 image token.");if(o)return{inputs_embeds:e,attention_mask:r,position_ids:null};let l=[],d=[];for(let n=0;n<s.length;++n){const i=s[n],o=e[n],a=t[n],u=r[n];l.push((0,c.cat)([o.slice([0,i]),a,o.slice([i+1,o.dims[0]])],0)),d.push((0,c.cat)([u.slice([0,i]),(0,c.ones)([a.dims[0]]),u.slice([i+1,u.dims[0]])],0))}return{inputs_embeds:(0,c.stack)(l,0),attention_mask:(0,c.stack)(d,0),position_ids:null}}prepare_inputs_for_generation(e,t,n){return t}async forward({input_ids:e=null,attention_mask:t=null,pixel_values:n=null,position_ids:r=null,inputs_embeds:i=null,past_key_values:s=null,generation_config:o=null,logits_processor:a=null,...l}){if(!i)if(i=await this.encode_text({input_ids:e}),n&&1!==e.dims[1]){const s=await this.encode_image({pixel_values:n});({inputs_embeds:i,inputs_embeds:i,attention_mask:t,position_ids:r}=this._merge_input_ids_with_image_features({image_features:s,inputs_embeds:i,input_ids:e,attention_mask:t}))}else if(s&&n&&1===e.dims[1]){const n=e.dims[1],r=Object.values(s)[0].dims.at(-2);t=(0,c.cat)([(0,c.ones)([e.dims[0],r]),t.slice(null,[t.dims[1]-n,t.dims[1]])],1)}return await O(this,{inputs_embeds:i,past_key_values:s,attention_mask:t,generation_config:o,logits_processor:a},!0)}}class dn extends R{}class un extends dn{}class cn extends dn{static async from_pretrained(e,t={}){return t.model_file_name??="text_model",super.from_pretrained(e,t)}}class pn extends dn{static async from_pretrained(e,t={}){return t.model_file_name??="vision_model",super.from_pretrained(e,t)}}class hn extends R{}class fn extends hn{}class mn extends hn{static async from_pretrained(e,t={}){return t.model_file_name??="text_model",super.from_pretrained(e,t)}}class gn extends dn{static async from_pretrained(e,t={}){return t.model_file_name??="vision_model",super.from_pretrained(e,t)}}class _n extends R{}class wn extends _n{}class yn extends R{}class bn extends yn{}class vn extends yn{}class xn extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class Mn extends xn{}class Tn extends xn{}class kn extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_heads,this.num_layers=this.config.num_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class $n extends kn{}class Sn extends kn{}class Cn extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class Pn extends Cn{}class En extends Cn{}class An extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class Fn extends An{}class In extends An{}class zn extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class Bn extends zn{}class On extends zn{}class Ln extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class Dn extends Ln{}class Rn extends Ln{}class Nn extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_key_value_heads??this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class Vn extends Nn{}class jn extends Nn{}class Un extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_key_value_heads??this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class Gn extends Un{}class qn extends Un{}class Wn extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class Hn extends Wn{}class Xn extends Wn{}class Qn extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.hidden_size/this.num_heads}}class Kn extends Qn{}class Yn extends Qn{}class Zn extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.n_heads,this.num_layers=this.config.n_layers,this.dim_kv=this.config.d_model/this.num_heads}}class Jn extends Zn{}class er extends Zn{}class tr extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class nr extends tr{}class rr extends tr{}class ir extends R{}class sr extends ir{}class or extends ir{async _call(e){return new Lo(await super._call(e))}}class ar extends R{}class lr extends ar{async _call(e){return new Go(await super._call(e))}}class dr extends R{}class ur extends dr{}class cr extends dr{async _call(e){return new Lo(await super._call(e))}}class pr extends R{}class hr extends pr{}class fr extends pr{}class mr extends R{}class gr extends mr{}class _r extends mr{}class wr extends R{}class yr extends wr{}class br extends wr{async _call(e){return new Lo(await super._call(e))}}class vr extends R{}class xr extends vr{}class Mr extends vr{async _call(e){return new kr(await super._call(e))}}class Tr extends vr{async _call(e){return new $r(await super._call(e))}}class kr extends N{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class $r extends N{constructor({logits:e,pred_boxes:t,pred_masks:n}){super(),this.logits=e,this.pred_boxes=t,this.pred_masks=n}}class Sr extends R{}class Cr extends Sr{}class Pr extends Sr{async _call(e){return new Er(await super._call(e))}}class Er extends kr{}class Ar extends R{}class Fr extends Ar{}class Ir extends Ar{async _call(e){return new Lo(await super._call(e))}}class zr extends R{}class Br extends zr{}class Or extends zr{async _call(e){return new Lo(await super._call(e))}}class Lr extends R{}class Dr extends Lr{}class Rr extends Lr{async _call(e){return new Lo(await super._call(e))}}class Nr extends R{}class Vr extends Nr{}class jr extends Nr{}class Ur extends R{}class Gr extends Ur{}class qr extends Ur{}class Wr extends R{}class Hr extends Wr{}class Xr extends R{}class Qr extends Xr{}class Kr extends Xr{}class Yr extends R{}class Zr extends Yr{}class Jr extends R{}class ei extends Jr{}class ti extends Jr{async _call(e){return new Lo(await super._call(e))}}class ni extends R{}class ri extends ni{}class ii extends ni{async _call(e){return new Lo(await super._call(e))}}class si extends R{}class oi extends si{}class ai extends si{async _call(e){return new Lo(await super._call(e))}}class li extends R{}class di extends li{}class ui extends li{async _call(e){return new ci(await super._call(e))}}class ci extends N{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class pi extends R{}class hi extends pi{async get_image_embeddings({pixel_values:e}){return await B(this,{pixel_values:e})}async forward(e){if(e.image_embeddings&&e.image_positional_embeddings||(e={...e,...await this.get_image_embeddings(e)}),!e.input_labels&&e.input_points){const t=e.input_points.dims.slice(0,-1),n=t.reduce(((e,t)=>e*t),1);e.input_labels=new c.Tensor("int64",new BigInt64Array(n).fill(1n),t)}const t={image_embeddings:e.image_embeddings,image_positional_embeddings:e.image_positional_embeddings};return e.input_points&&(t.input_points=e.input_points),e.input_labels&&(t.input_labels=e.input_labels),e.input_boxes&&(t.input_boxes=e.input_boxes),await A(this.sessions.prompt_encoder_mask_decoder,t)}async _call(e){return new fi(await super._call(e))}}class fi extends N{constructor({iou_scores:e,pred_masks:t}){super(),this.iou_scores=e,this.pred_masks=t}}class mi extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class gi extends mi{}class _i extends mi{}class wi extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class yi extends wi{}class bi extends wi{}class vi extends R{}class xi extends vi{}class Mi extends vi{async _call(e){return new jo(await super._call(e))}}class Ti extends vi{async _call(e){return new Lo(await super._call(e))}}class ki extends vi{async _call(e){return new Ro(await super._call(e))}}class $i extends R{}class Si extends $i{}class Ci extends $i{async _call(e){return new jo(await super._call(e))}}class Pi extends $i{async _call(e){return new Lo(await super._call(e))}}class Ei extends R{}class Ai extends Ei{}class Fi extends Ei{async _call(e){return new jo(await super._call(e))}}class Ii extends Ei{async _call(e){return new Lo(await super._call(e))}}class zi extends Ei{async _call(e){return new Ro(await super._call(e))}}class Bi extends R{}class Oi extends Bi{}class Li extends Bi{async _call(e){return new jo(await super._call(e))}}class Di extends Bi{async _call(e){return new Lo(await super._call(e))}}class Ri extends R{}class Ni extends vi{}class Vi extends vi{async _call(e){return new jo(await super._call(e))}}class ji extends vi{async _call(e){return new Lo(await super._call(e))}}class Ui extends R{}class Gi extends Ui{}class qi extends Ui{async _call(e){return new jo(await super._call(e))}}class Wi extends Ui{async _call(e){return new Lo(await super._call(e))}}class Hi extends Ui{async _call(e){return new Do(await super._call(e))}}class Xi extends Ui{async _call(e){return new Ro(await super._call(e))}}class Qi extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.hidden_size/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.hidden_size/this.num_encoder_heads}}class Ki extends Qi{}class Yi extends Qi{}class Zi extends Qi{async generate_speech(e,t,{threshold:n=.5,minlenratio:r=0,maxlenratio:i=20,vocoder:s=null}={}){const o={input_ids:e},{encoder_outputs:a,encoder_attention_mask:l}=await B(this,o),d=a.dims[1]/this.config.reduction_factor,u=Math.floor(d*i),p=Math.floor(d*r),h=this.config.num_mel_bins;let f=[],m=null,g=null,_=0;for(;;){++_;const e=I(!!g);let r;r=g?g.output_sequence_out:new c.Tensor("float32",new Float32Array(h),[1,1,h]);let i={use_cache_branch:e,output_sequence:r,encoder_attention_mask:l,speaker_embeddings:t,encoder_hidden_states:a};this.addPastKeyValues(i,m),g=await A(this.sessions.decoder_model_merged,i),m=this.getPastKeyValues(g,m);const{prob:s,spectrum:o}=g;if(f.push(o),_>=p&&(Array.from(s.data).filter((e=>e>=n)).length>0||_>=u))break}const w=(0,c.cat)(f),{waveform:y}=await A(s.sessions.model,{spectrogram:w});return{spectrogram:w,waveform:y}}}class Ji extends R{main_input_name="spectrogram"}class es extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_encoder_layers=this.num_decoder_layers=this.config.decoder_layers,this.num_encoder_heads=this.num_decoder_heads=this.config.decoder_attention_heads,this.encoder_dim_kv=this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads}}class ts extends es{}class ns extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_key_value_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class rs extends ns{}class is extends ns{}class ss extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_key_value_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class os extends ss{}class as extends ss{}class ls extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class ds extends ls{}class us extends ls{}class cs extends R{}class ps extends cs{}class hs extends cs{static async from_pretrained(e,t={}){return t.model_file_name??="text_model",super.from_pretrained(e,t)}}class fs extends cs{static async from_pretrained(e,t={}){return t.model_file_name??="audio_model",super.from_pretrained(e,t)}}class ms extends R{}class gs extends ms{async _call(e){return new qo(await super._call(e))}}class _s extends R{}class ws extends _s{}class ys extends _s{}class bs extends _s{}class vs extends R{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class xs extends vs{}class Ms extends vs{}class Ts extends R{}class ks extends Ts{}class $s extends Ts{async _call(e){return new Lo(await super._call(e))}}class Ss extends R{}class Cs extends Ss{}class Ps extends Ss{}class Es extends R{forward_params=["input_ids","attention_mask","encoder_outputs","decoder_input_ids","decoder_attention_mask","past_key_values"];constructor(e,t,n){super(e,t),this.generation_config=n;const r=e.decoder;this.num_encoder_layers=this.num_decoder_layers=r.num_hidden_layers,this.num_encoder_heads=this.num_decoder_heads=r.num_attention_heads,this.encoder_dim_kv=this.decoder_dim_kv=r.hidden_size/this.num_decoder_heads}_apply_and_filter_by_delay_pattern_mask(e){const[t,n]=e.dims,r=this.config.decoder.num_codebooks,i=n-r;let s=0;for(let t=0;t<e.size;++t){if(e.data[t]===this.config.decoder.pad_token_id)continue;const o=t%n-Math.floor(t/n)%r;o>0&&o<=i&&(e.data[s++]=e.data[t])}const o=Math.floor(t/r),a=s/(o*r);return new c.Tensor(e.type,e.data.slice(0,s),[o,r,a])}prepare_inputs_for_generation(e,t,n){let r=structuredClone(e);for(let e=0;e<r.length;++e)for(let t=0;t<r[e].length;++t)e%this.config.decoder.num_codebooks>=t&&(r[e][t]=BigInt(this.config.decoder.pad_token_id));null!==n.guidance_scale&&n.guidance_scale>1&&(r=r.concat(r));return super.prepare_inputs_for_generation(r,t,n)}async generate(e){const t=await super.generate(e),n=this._apply_and_filter_by_delay_pattern_mask(t).unsqueeze_(0),{audio_values:r}=await A(this.sessions.encodec_decode,{audio_codes:n});return r}}class As{static MODEL_CLASS_MAPPINGS=null;static BASE_IF_FAIL=!1;static async from_pretrained(e,{progress_callback:t=null,config:n=null,cache_dir:i=null,local_files_only:s=!1,revision:o="main",model_file_name:a=null,subfolder:l="onnx",device:d=null,dtype:u=null,session_options:c={}}={}){let p={progress_callback:t,config:n,cache_dir:i,local_files_only:s,revision:o,model_file_name:a,subfolder:l,device:d,dtype:u,session_options:c};if(n=await r.AutoConfig.from_pretrained(e,p),p.config||(p.config=n),!this.MODEL_CLASS_MAPPINGS)throw new Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: "+this.name);for(let t of this.MODEL_CLASS_MAPPINGS){const r=t.get(n.model_type);if(r)return await r[1].from_pretrained(e,p)}if(this.BASE_IF_FAIL)return console.warn(`Unknown model class "${n.model_type}", attempting to construct from base class.`),await R.from_pretrained(e,p);throw Error(`Unsupported model type: ${n.model_type}`)}}const Fs=new Map([["bert",["BertModel",U]],["nomic_bert",["NomicBertModel",Q]],["roformer",["RoFormerModel",Y]],["electra",["ElectraModel",de]],["esm",["EsmModel",Re]],["convbert",["ConvBertModel",re]],["camembert",["CamembertModel",me]],["deberta",["DebertaModel",ve]],["deberta-v2",["DebertaV2Model",Se]],["mpnet",["MPNetModel",Qe]],["albert",["AlbertModel",ot]],["distilbert",["DistilBertModel",Ie]],["roberta",["RobertaModel",Bt]],["xlm",["XLMModel",Vt]],["xlm-roberta",["XLMRobertaModel",Ht]],["clap",["ClapModel",ps]],["clip",["CLIPModel",un]],["clipseg",["CLIPSegModel",bn]],["chinese_clip",["ChineseCLIPModel",wn]],["siglip",["SiglipModel",fn]],["mobilebert",["MobileBertModel",Ge]],["squeezebert",["SqueezeBertModel",tt]],["wav2vec2",["Wav2Vec2Model",xi]],["wav2vec2-bert",["Wav2Vec2BertModel",Oi]],["unispeech",["UniSpeechModel",Si]],["unispeech-sat",["UniSpeechSatModel",Ai]],["hubert",["HubertModel",Ni]],["wavlm",["WavLMModel",Gi]],["audio-spectrogram-transformer",["ASTModel",Jt]],["vits",["VitsModel",gs]],["detr",["DetrModel",xr]],["table-transformer",["TableTransformerModel",Cr]],["vit",["ViTModel",sr]],["mobilevit",["MobileViTModel",ur]],["owlvit",["OwlViTModel",hr]],["owlv2",["Owlv2Model",gr]],["beit",["BeitModel",yr]],["deit",["DeiTModel",Fr]],["convnext",["ConvNextModel",ei]],["convnextv2",["ConvNextV2Model",ri]],["dinov2",["Dinov2Model",oi]],["resnet",["ResNetModel",Br]],["swin",["SwinModel",Dr]],["swin2sr",["Swin2SRModel",Vr]],["donut-swin",["DonutSwinModel",Zr]],["yolos",["YolosModel",di]],["dpt",["DPTModel",Gr]],["glpn",["GLPNModel",Qr]],["hifigan",["SpeechT5HifiGan",Ji]],["efficientnet",["EfficientNetModel",ks]]]),Is=new Map([["t5",["T5Model",ct]],["longt5",["LongT5Model",ft]],["mt5",["MT5Model",_t]],["bart",["BartModel",bt]],["mbart",["MBartModel",Tt]],["marian",["MarianModel",gi]],["whisper",["WhisperModel",nn]],["m2m_100",["M2M100Model",yi]],["blenderbot",["BlenderbotModel",Pt]],["blenderbot-small",["BlenderbotSmallModel",Ft]]]),zs=new Map([["bloom",["BloomModel",Kn]],["gpt2",["GPT2Model",Mn]],["gptj",["GPTJModel",Fn]],["gpt_bigcode",["GPTBigCodeModel",Bn]],["gpt_neo",["GPTNeoModel",$n]],["gpt_neox",["GPTNeoXModel",Pn]],["codegen",["CodeGenModel",Dn]],["llama",["LlamaModel",Vn]],["qwen2",["Qwen2Model",Gn]],["phi",["PhiModel",Hn]],["mpt",["MptModel",Jn]],["opt",["OPTModel",nr]],["mistral",["MistralModel",rs]],["starcoder2",["Starcoder2Model",os]],["falcon",["FalconModel",ds]]]),Bs=new Map([["speecht5",["SpeechT5ForSpeechToText",Yi]],["whisper",["WhisperForConditionalGeneration",sn]]]),Os=new Map([["speecht5",["SpeechT5ForTextToSpeech",Zi]]]),Ls=new Map([["vits",["VitsModel",gs]],["musicgen",["MusicgenForConditionalGeneration",Es]]]),Ds=new Map([["bert",["BertForSequenceClassification",q]],["roformer",["RoFormerForSequenceClassification",J]],["electra",["ElectraForSequenceClassification",ce]],["esm",["EsmForSequenceClassification",Ve]],["convbert",["ConvBertForSequenceClassification",se]],["camembert",["CamembertForSequenceClassification",_e]],["deberta",["DebertaForSequenceClassification",Me]],["deberta-v2",["DebertaV2ForSequenceClassification",Pe]],["mpnet",["MPNetForSequenceClassification",Ye]],["albert",["AlbertForSequenceClassification",at]],["distilbert",["DistilBertForSequenceClassification",ze]],["roberta",["RobertaForSequenceClassification",Lt]],["xlm",["XLMForSequenceClassification",Ut]],["xlm-roberta",["XLMRobertaForSequenceClassification",Qt]],["bart",["BartForSequenceClassification",xt]],["mbart",["MBartForSequenceClassification",$t]],["mobilebert",["MobileBertForSequenceClassification",We]],["squeezebert",["SqueezeBertForSequenceClassification",rt]]]),Rs=new Map([["bert",["BertForTokenClassification",W]],["roformer",["RoFormerForTokenClassification",ee]],["electra",["ElectraForTokenClassification",pe]],["esm",["EsmForTokenClassification",je]],["convbert",["ConvBertForTokenClassification",oe]],["camembert",["CamembertForTokenClassification",we]],["deberta",["DebertaForTokenClassification",Te]],["deberta-v2",["DebertaV2ForTokenClassification",Ee]],["mpnet",["MPNetForTokenClassification",Ze]],["distilbert",["DistilBertForTokenClassification",Be]],["roberta",["RobertaForTokenClassification",Dt]],["xlm",["XLMForTokenClassification",Gt]],["xlm-roberta",["XLMRobertaForTokenClassification",Kt]]]),Ns=new Map([["t5",["T5ForConditionalGeneration",pt]],["longt5",["LongT5ForConditionalGeneration",mt]],["mt5",["MT5ForConditionalGeneration",wt]],["bart",["BartForConditionalGeneration",vt]],["mbart",["MBartForConditionalGeneration",kt]],["marian",["MarianMTModel",_i]],["m2m_100",["M2M100ForConditionalGeneration",bi]],["blenderbot",["BlenderbotForConditionalGeneration",Et]],["blenderbot-small",["BlenderbotSmallForConditionalGeneration",It]]]),Vs=new Map([["bloom",["BloomForCausalLM",Yn]],["gpt2",["GPT2LMHeadModel",Tn]],["gptj",["GPTJForCausalLM",In]],["gpt_bigcode",["GPTBigCodeForCausalLM",On]],["gpt_neo",["GPTNeoForCausalLM",Sn]],["gpt_neox",["GPTNeoXForCausalLM",En]],["codegen",["CodeGenForCausalLM",Rn]],["llama",["LlamaForCausalLM",jn]],["qwen2",["Qwen2ForCausalLM",qn]],["phi",["PhiForCausalLM",Xn]],["mpt",["MptForCausalLM",er]],["opt",["OPTForCausalLM",rr]],["mbart",["MBartForCausalLM",St]],["mistral",["MistralForCausalLM",is]],["starcoder2",["Starcoder2ForCausalLM",as]],["falcon",["FalconForCausalLM",us]],["trocr",["TrOCRForCausalLM",ts]],["stablelm",["StableLmForCausalLM",Ms]]]),js=new Map([["bert",["BertForMaskedLM",G]],["roformer",["RoFormerForMaskedLM",Z]],["electra",["ElectraForMaskedLM",ue]],["esm",["EsmForMaskedLM",Ne]],["convbert",["ConvBertForMaskedLM",ie]],["camembert",["CamembertForMaskedLM",ge]],["deberta",["DebertaForMaskedLM",xe]],["deberta-v2",["DebertaV2ForMaskedLM",Ce]],["mpnet",["MPNetForMaskedLM",Ke]],["albert",["AlbertForMaskedLM",dt]],["distilbert",["DistilBertForMaskedLM",Le]],["roberta",["RobertaForMaskedLM",Ot]],["xlm",["XLMWithLMHeadModel",jt]],["xlm-roberta",["XLMRobertaForMaskedLM",Xt]],["mobilebert",["MobileBertForMaskedLM",qe]],["squeezebert",["SqueezeBertForMaskedLM",nt]]]),Us=new Map([["bert",["BertForQuestionAnswering",H]],["roformer",["RoFormerForQuestionAnswering",te]],["electra",["ElectraForQuestionAnswering",he]],["convbert",["ConvBertForQuestionAnswering",ae]],["camembert",["CamembertForQuestionAnswering",ye]],["deberta",["DebertaForQuestionAnswering",ke]],["deberta-v2",["DebertaV2ForQuestionAnswering",Ae]],["mpnet",["MPNetForQuestionAnswering",Je]],["albert",["AlbertForQuestionAnswering",lt]],["distilbert",["DistilBertForQuestionAnswering",Oe]],["roberta",["RobertaForQuestionAnswering",Rt]],["xlm",["XLMForQuestionAnswering",qt]],["xlm-roberta",["XLMRobertaForQuestionAnswering",Yt]],["mobilebert",["MobileBertForQuestionAnswering",He]],["squeezebert",["SqueezeBertForQuestionAnswering",it]]]),Gs=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",on]]]),qs=new Map([["llava",["LlavaForConditionalGeneration",ln]]]),Ws=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",on]]]),Hs=new Map([["vit",["ViTForImageClassification",or]],["mobilevit",["MobileViTForImageClassification",cr]],["beit",["BeitForImageClassification",br]],["deit",["DeiTForImageClassification",Ir]],["convnext",["ConvNextForImageClassification",ti]],["convnextv2",["ConvNextV2ForImageClassification",ii]],["dinov2",["Dinov2ForImageClassification",ai]],["resnet",["ResNetForImageClassification",Or]],["swin",["SwinForImageClassification",Rr]],["segformer",["SegformerForImageClassification",ys]],["efficientnet",["EfficientNetForImageClassification",$s]]]),Xs=new Map([["detr",["DetrForObjectDetection",Mr]],["table-transformer",["TableTransformerForObjectDetection",Pr]],["yolos",["YolosForObjectDetection",ui]]]),Qs=new Map([["owlvit",["OwlViTForObjectDetection",fr]],["owlv2",["Owlv2ForObjectDetection",_r]]]),Ks=new Map([["detr",["DetrForSegmentation",Tr]],["clipseg",["CLIPSegForImageSegmentation",vn]]]),Ys=new Map([["segformer",["SegformerForSemanticSegmentation",bs]]]),Zs=new Map([["sam",["SamModel",hi]]]),Js=new Map([["wav2vec2",["Wav2Vec2ForCTC",Mi]],["wav2vec2-bert",["Wav2Vec2BertForCTC",Li]],["unispeech",["UniSpeechForCTC",Ci]],["unispeech-sat",["UniSpeechSatForCTC",Fi]],["wavlm",["WavLMForCTC",qi]],["hubert",["HubertForCTC",Vi]]]),eo=new Map([["wav2vec2",["Wav2Vec2ForSequenceClassification",Ti]],["wav2vec2-bert",["Wav2Vec2BertForSequenceClassification",Di]],["unispeech",["UniSpeechForSequenceClassification",Pi]],["unispeech-sat",["UniSpeechSatForSequenceClassification",Ii]],["wavlm",["WavLMForSequenceClassification",Wi]],["hubert",["HubertForSequenceClassification",ji]],["audio-spectrogram-transformer",["ASTForAudioClassification",en]]]),to=new Map([["wavlm",["WavLMForXVector",Hi]]]),no=new Map([["unispeech-sat",["UniSpeechSatForAudioFrameClassification",zi]],["wavlm",["WavLMForAudioFrameClassification",Xi]],["wav2vec2",["Wav2Vec2ForAudioFrameClassification",ki]]]),ro=new Map([["vitmatte",["VitMatteForImageMatting",lr]]]),io=new Map([["swin2sr",["Swin2SRForImageSuperResolution",jr]]]),so=new Map([["dpt",["DPTForDepthEstimation",qr]],["depth_anything",["DepthAnythingForDepthEstimation",Hr]],["glpn",["GLPNForDepthEstimation",Kr]]]),oo=new Map([["clip",["CLIPVisionModelWithProjection",pn]],["siglip",["SiglipVisionModel",gn]]]),ao=[[Fs,m],[Is,g],[zs,y],[Ds,m],[Rs,m],[Ns,_],[Bs,_],[Vs,y],[js,m],[Us,m],[Gs,w],[qs,v],[Hs,m],[Ks,m],[Ys,m],[ro,m],[io,m],[so,m],[Xs,m],[Qs,m],[Zs,b],[Js,m],[eo,m],[Os,_],[Ls,m],[to,m],[no,m],[oo,m]];for(const[e,t]of ao)for(const[n,r]of e.values())M.set(n,t),k.set(r,n),T.set(n,r);const lo=[["MusicgenForConditionalGeneration",Es,x],["CLIPTextModelWithProjection",cn,m],["SiglipTextModel",mn,m],["ClapTextModelWithProjection",hs,m],["ClapAudioModelWithProjection",fs,m]];for(const[e,t,n]of lo)M.set(e,n),k.set(t,e),T.set(e,t);class uo extends As{static MODEL_CLASS_MAPPINGS=ao.map((e=>e[0]));static BASE_IF_FAIL=!0}class co extends As{static MODEL_CLASS_MAPPINGS=[Ds]}class po extends As{static MODEL_CLASS_MAPPINGS=[Rs]}class ho extends As{static MODEL_CLASS_MAPPINGS=[Ns]}class fo extends As{static MODEL_CLASS_MAPPINGS=[Bs]}class mo extends As{static MODEL_CLASS_MAPPINGS=[Os]}class go extends As{static MODEL_CLASS_MAPPINGS=[Ls]}class _o extends As{static MODEL_CLASS_MAPPINGS=[Vs]}class wo extends As{static MODEL_CLASS_MAPPINGS=[js]}class yo extends As{static MODEL_CLASS_MAPPINGS=[Us]}class bo extends As{static MODEL_CLASS_MAPPINGS=[Gs]}class vo extends As{static MODEL_CLASS_MAPPINGS=[Hs]}class xo extends As{static MODEL_CLASS_MAPPINGS=[Ks]}class Mo extends As{static MODEL_CLASS_MAPPINGS=[Ys]}class To extends As{static MODEL_CLASS_MAPPINGS=[Xs]}class ko extends As{static MODEL_CLASS_MAPPINGS=[Qs]}class $o extends As{static MODEL_CLASS_MAPPINGS=[Zs]}class So extends As{static MODEL_CLASS_MAPPINGS=[Js]}class Co extends As{static MODEL_CLASS_MAPPINGS=[eo]}class Po extends As{static MODEL_CLASS_MAPPINGS=[to]}class Eo extends As{static MODEL_CLASS_MAPPINGS=[no]}class Ao extends As{static MODEL_CLASS_MAPPINGS=[Ws]}class Fo extends As{static MODEL_CLASS_MAPPINGS=[ro]}class Io extends As{static MODEL_CLASS_MAPPINGS=[io]}class zo extends As{static MODEL_CLASS_MAPPINGS=[so]}class Bo extends As{static MODEL_CLASS_MAPPINGS=[oo]}class Oo extends N{constructor({logits:e,past_key_values:t,encoder_outputs:n,decoder_attentions:r=null,cross_attentions:i=null}){super(),this.logits=e,this.past_key_values=t,this.encoder_outputs=n,this.decoder_attentions=r,this.cross_attentions=i}}class Lo extends N{constructor({logits:e}){super(),this.logits=e}}class Do extends N{constructor({logits:e,embeddings:t}){super(),this.logits=e,this.embeddings=t}}class Ro extends N{constructor({logits:e}){super(),this.logits=e}}class No extends N{constructor({logits:e}){super(),this.logits=e}}class Vo extends N{constructor({start_logits:e,end_logits:t}){super(),this.start_logits=e,this.end_logits=t}}class jo extends N{constructor({logits:e}){super(),this.logits=e}}class Uo extends N{constructor({logits:e,past_key_values:t}){super(),this.logits=e,this.past_key_values=t}}class Go extends N{constructor({alphas:e}){super(),this.alphas=e}}class qo extends N{constructor({waveform:e,spectrogram:t}){super(),this.waveform=e,this.spectrogram=t}}},"./src/ops/registry.js":
/*!*****************************!*\
  !*** ./src/ops/registry.js ***!
  \*****************************/(e,t,n)=>{n.r(t),n.d(t,{TensorOpRegistry:()=>o});var r=n(/*! ../backends/onnx.js */"./src/backends/onnx.js"),i=n(/*! ../utils/tensor.js */"./src/utils/tensor.js");const s=async(e,t,n)=>{const s=await(0,r.createInferenceSession)(e,t);return async e=>{const t=Object.fromEntries(Object.entries(e).map((([e,t])=>[e,t.ort_tensor]))),r=await s.run(t);return new i.Tensor(r[n])}};class o{static session_options={};static get bilinear_interpolate_4d(){return this._bilinear_interpolate_4d||(this._bilinear_interpolate_4d=s(new Uint8Array([8,9,18,0,58,128,1,10,40,10,1,120,10,0,10,0,10,1,115,18,1,121,34,6,82,101,115,105,122,101,42,17,10,4,109,111,100,101,34,6,108,105,110,101,97,114,160,1,3,18,1,114,90,31,10,1,120,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,90,15,10,1,115,18,10,10,8,8,7,18,4,10,2,8,4,98,31,10,1,121,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,66,2,16,20]),this.session_options,"y")),this._bilinear_interpolate_4d}static get bicubic_interpolate_4d(){return this._bicubic_interpolate_4d||(this._bicubic_interpolate_4d=s(new Uint8Array([8,9,18,0,58,127,10,39,10,1,120,10,0,10,0,10,1,115,18,1,121,34,6,82,101,115,105,122,101,42,16,10,4,109,111,100,101,34,5,99,117,98,105,99,160,1,3,18,1,114,90,31,10,1,120,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,90,15,10,1,115,18,10,10,8,8,7,18,4,10,2,8,4,98,31,10,1,121,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,66,2,16,20]),this.session_options,"y")),this._bicubic_interpolate_4d}}},"./src/pipelines.js":
/*!**************************!*\
  !*** ./src/pipelines.js ***!
  \**************************/(e,t,n)=>{n.r(t),n.d(t,{AudioClassificationPipeline:()=>S,AutomaticSpeechRecognitionPipeline:()=>P,DepthEstimationPipeline:()=>R,DocumentQuestionAnsweringPipeline:()=>O,FeatureExtractionPipeline:()=>k,FillMaskPipeline:()=>y,ImageClassificationPipeline:()=>A,ImageFeatureExtractionPipeline:()=>$,ImageSegmentationPipeline:()=>F,ImageToImagePipeline:()=>D,ImageToTextPipeline:()=>E,ObjectDetectionPipeline:()=>z,Pipeline:()=>m,QuestionAnsweringPipeline:()=>w,SummarizationPipeline:()=>v,Text2TextGenerationPipeline:()=>b,TextClassificationPipeline:()=>g,TextGenerationPipeline:()=>M,TextToAudioPipeline:()=>L,TokenClassificationPipeline:()=>_,TranslationPipeline:()=>x,ZeroShotAudioClassificationPipeline:()=>C,ZeroShotClassificationPipeline:()=>T,ZeroShotImageClassificationPipeline:()=>I,ZeroShotObjectDetectionPipeline:()=>B,pipeline:()=>j});var r=n(/*! ./tokenizers.js */"./src/tokenizers.js"),i=n(/*! ./models.js */"./src/models.js"),s=n(/*! ./processors.js */"./src/processors.js"),o=n(/*! ./utils/generic.js */"./src/utils/generic.js"),a=n(/*! ./utils/core.js */"./src/utils/core.js"),l=n(/*! ./utils/maths.js */"./src/utils/maths.js"),d=n(/*! ./utils/audio.js */"./src/utils/audio.js"),u=n(/*! ./utils/tensor.js */"./src/utils/tensor.js"),c=n(/*! ./utils/image.js */"./src/utils/image.js");async function p(e){return Array.isArray(e)||(e=[e]),await Promise.all(e.map((e=>c.RawImage.read(e))))}async function h(e,t){return Array.isArray(e)||(e=[e]),await Promise.all(e.map((e=>"string"==typeof e||e instanceof URL?(0,d.read_audio)(e,t):e instanceof Float64Array?new Float32Array(e):e)))}function f(e,t){t&&(e=e.map((e=>0|e)));const[n,r,i,s]=e;return{xmin:n,ymin:r,xmax:i,ymax:s}}class m extends o.Callable{constructor({task:e,model:t,tokenizer:n=null,processor:r=null}){super(),this.task=e,this.model=t,this.tokenizer=n,this.processor=r}async dispose(){await this.model.dispose()}}class g extends m{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const n=this.tokenizer(e,{padding:!0,truncation:!0}),r=await this.model(n),i="multi_label_classification"===this.model.config.problem_type?e=>e.sigmoid().data:e=>(0,l.softmax)(e.data),s=this.model.config.id2label,o=[];for(const e of r.logits){const n=i(e),r=(0,l.getTopItems)(n,t).map((e=>({label:s[e[0]],score:e[1]})));1===t?o.push(...r):o.push(r)}return Array.isArray(e)||1===t?o:o[0]}}class _ extends m{constructor(e){super(e)}async _call(e,{ignore_labels:t=["O"]}={}){const n=Array.isArray(e),r=this.tokenizer(n?e:[e],{padding:!0,truncation:!0}),i=(await this.model(r)).logits,s=this.model.config.id2label,o=[];for(let e=0;e<i.dims[0];++e){const n=r.input_ids[e],a=i[e],d=[];for(let e=0;e<a.dims[0];++e){const r=a[e],i=(0,l.max)(r.data)[1],o=s?s[i]:`LABEL_${i}`;if(t.includes(o))continue;const u=this.tokenizer.decode([n[e].item()],{skip_special_tokens:!0});if(""===u)continue;const c=(0,l.softmax)(r.data);d.push({entity:o,score:c[i],index:e,word:u,start:null,end:null})}o.push(d)}return n?o:o[0]}}class w extends m{constructor(e){super(e)}async _call(e,t,{topk:n=1}={}){const r=this.tokenizer(e,{text_pair:t,padding:!0,truncation:!0}),i=await this.model(r),s=[];for(let e=0;e<i.start_logits.dims[0];++e){const t=r.input_ids[e],o=t.indexOf(this.tokenizer.sep_token_id),d=Array.from((0,l.softmax)(i.start_logits[e].data)).map(((e,t)=>[e,t])).filter((e=>e[1]>o)),u=Array.from((0,l.softmax)(i.end_logits[e].data)).map(((e,t)=>[e,t])).filter((e=>e[1]>o)),c=(0,a.product)(d,u).filter((e=>e[0][1]<=e[1][1])).map((e=>[e[0][1],e[1][1],e[0][0]*e[1][0]])).sort(((e,t)=>t[2]-e[2]));for(let e=0;e<Math.min(c.length,n);++e){const[n,r,i]=c[e],o=[...t].slice(n,r+1),a=this.tokenizer.decode(o,{skip_special_tokens:!0});s.push({answer:a,score:i})}}return 1===n?s[0]:s}}class y extends m{constructor(e){super(e)}async _call(e,{topk:t=5}={}){const n=this.tokenizer(e,{padding:!0,truncation:!0}),r=await this.model(n),i=[];for(let e=0;e<n.input_ids.dims[0];++e){const s=n.input_ids[e],o=s.indexOf(this.tokenizer.mask_token_id);if(-1===o)throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);const a=r.logits[e][o],d=(0,l.getTopItems)((0,l.softmax)(a.data),t);i.push(d.map((e=>{const t=[...s];return t[o]=e[0],{score:e[1],token:e[0],token_str:this.tokenizer.model.vocab[e[0]],sequence:this.tokenizer.decode(t,{skip_special_tokens:!0})}})))}return Array.isArray(e)?i:i[0]}}class b extends m{_key="generated_text";constructor(e){super(e)}async _call(e,t={}){throw new Error("This pipeline is not yet supported in Transformers.js v3.")}}class v extends b{_key="summary_text";constructor(e){super(e)}}class x extends b{_key="translation_text";constructor(e){super(e)}}class M extends m{constructor(e){super(e)}async _call(e,t={}){throw new Error("This pipeline is not yet supported in Transformers.js v3.")}}class T extends m{constructor(e){super(e),this.label2id=Object.fromEntries(Object.entries(this.model.config.label2id).map((([e,t])=>[e.toLowerCase(),t]))),this.entailment_id=this.label2id.entailment,void 0===this.entailment_id&&(console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."),this.entailment_id=2),this.contradiction_id=this.label2id.contradiction??this.label2id.not_entailment,void 0===this.contradiction_id&&(console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."),this.contradiction_id=0)}async _call(e,t,{hypothesis_template:n="This example is {}.",multi_label:r=!1}={}){const i=Array.isArray(e);i||(e=[e]),Array.isArray(t)||(t=[t]);const s=t.map((e=>n.replace("{}",e))),o=r||1===t.length,a=[];for(const n of e){const e=[];for(const t of s){const r=this.tokenizer(n,{text_pair:t,padding:!0,truncation:!0}),i=await this.model(r);o?e.push([i.logits.data[this.contradiction_id],i.logits.data[this.entailment_id]]):e.push(i.logits.data[this.entailment_id])}const r=(o?e.map((e=>(0,l.softmax)(e)[1])):(0,l.softmax)(e)).map(((e,t)=>[e,t])).sort(((e,t)=>t[0]-e[0]));a.push({sequence:n,labels:r.map((e=>t[e[1]])),scores:r.map((e=>e[0]))})}return i?a:a[0]}}class k extends m{constructor(e){super(e)}async _call(e,{pooling:t="none",normalize:n=!1,quantize:r=!1,precision:i="binary"}={}){const s=this.tokenizer(e,{padding:!0,truncation:!0}),o=await this.model(s);let a=o.last_hidden_state??o.logits;if("none"===t);else if("mean"===t)a=(0,u.mean_pooling)(a,s.attention_mask);else{if("cls"!==t)throw Error(`Pooling method '${t}' not supported.`);a=a.slice(null,0)}return n&&(a=a.normalize(2,-1)),r&&(a=(0,u.quantize_embeddings)(a,i)),a}}class $ extends m{constructor(e){super(e)}async _call(e,{pool:t=null}={}){const n=await p(e),{pixel_values:r}=await this.processor(n),i=await this.model({pixel_values:r});let s;if(t){if(!("pooler_output"in i))throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");s=i.pooler_output}else s=i.last_hidden_state??i.logits??i.image_embeds;return s}}class S extends m{constructor(e){super(e)}async _call(e,{topk:t=null}={}){const n=!Array.isArray(e),r=this.processor.feature_extractor.config.sampling_rate,i=await h(e,r),s=this.model.config.id2label,o=[];for(const e of i){const n=await this.processor(e),r=(await this.model(n)).logits[0],i=(0,l.getTopItems)((0,l.softmax)(r.data),t).map((e=>({label:s[e[0]],score:e[1]})));1===t?o.push(...i):o.push(i)}return n&&1!==t?o[0]:o}}class C extends m{constructor(e){super(e)}async _call(e,t,{hypothesis_template:n="This is a sound of {}."}={}){const r=!Array.isArray(e);r&&(e=[e]);const i=t.map((e=>n.replace("{}",e))),s=this.tokenizer(i,{padding:!0,truncation:!0}),o=this.processor.feature_extractor.config.sampling_rate,a=await h(e,o),d=[];for(const e of a){const n=await this.processor(e),r=await this.model({...s,...n}),i=(0,l.softmax)(r.logits_per_audio.data);d.push([...i].map(((e,n)=>({score:e,label:t[n]}))))}return r?d[0]:d}}class P extends m{constructor(e){super(e)}async _call(e,t={}){throw new Error("This pipeline is not yet supported in Transformers.js v3.")}async _call_wav2vec2(e,t={}){t.language&&console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'),t.task&&console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');const n=!Array.isArray(e);n&&(e=[e]);const r=this.processor.feature_extractor.config.sampling_rate,i=await h(e,r),s=[];for(const e of i){const t=await this.processor(e),n=(await this.model(t)).logits[0],r=[];for(const e of n)r.push((0,l.max)(e.data)[1]);const i=this.tokenizer.decode(r);s.push({text:i})}return n?s[0]:s}async _call_whisper(e,t={}){const n=t.return_timestamps??!1,r=t.chunk_length_s??0,i=t.chunk_callback??null,s=t.force_full_sequences??!1;let o=t.stride_length_s??null;"word"===n&&(t.return_token_timestamps=!0);const d=(0,a.pop)(t,"language",null),u=(0,a.pop)(t,"task",null);if(d||u||n){if(t.forced_decoder_ids)throw new Error("Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.");const e=this.tokenizer.get_decoder_prompt_ids({language:d,task:u,no_timestamps:!n});e.length>0&&(t.forced_decoder_ids=e)}const c=!Array.isArray(e);c&&(e=[e]);const p=this.processor.feature_extractor.config.chunk_length/this.model.config.max_source_positions,f=this.processor.feature_extractor.config.hop_length,m=this.processor.feature_extractor.config.sampling_rate,g=await h(e,m),_=[];for(const e of g){let a=[];if(r>0){if(null===o)o=r/6;else if(r<=o)throw Error("`chunk_length_s` must be larger than `stride_length_s`.");const t=m*r,n=m*o,i=t-2*n;let s=0;for(;s<e.length;){const r=e.subarray(s,s+t),o=await this.processor(r),l=0===s,d=s+i>=e.length;a.push({stride:[r.length,l?0:n,d?0:n],input_features:o.input_features,is_last:d}),s+=i}}else a=[{stride:[e.length,0,0],input_features:(await this.processor(e)).input_features,is_last:!0}];for(const e of a){t.num_frames=Math.floor(e.stride[0]/f);const r=await this.model.generate({inputs:e.input_features,...t});"word"===n?(e.tokens=r.sequences[0],e.token_timestamps=r.token_timestamps.tolist()[0].map((e=>(0,l.round)(e,2)))):e.tokens=r[0],e.stride=e.stride.map((e=>e/m)),null!==i&&i(e)}const[d,u]=this.tokenizer._decode_asr(a,{time_precision:p,return_timestamps:n,force_full_sequences:s});_.push({text:d,...u})}return c?_[0]:_}}class E extends m{constructor(e){super(e)}async _call(e,t={}){throw new Error("This pipeline is not yet supported in Transformers.js v3.")}}class A extends m{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const n=Array.isArray(e),r=await p(e),{pixel_values:i}=await this.processor(r),s=await this.model({pixel_values:i}),o=this.model.config.id2label,a=[];for(const e of s.logits){const n=(0,l.getTopItems)((0,l.softmax)(e.data),t).map((e=>({label:o[e[0]],score:e[1]})));1===t?a.push(...n):a.push(n)}return n||1===t?a:a[0]}}class F extends m{constructor(e){super(e),this.subtasks_mapping={panoptic:"post_process_panoptic_segmentation",instance:"post_process_instance_segmentation",semantic:"post_process_semantic_segmentation"}}async _call(e,{threshold:t=.5,mask_threshold:n=.5,overlap_mask_area_threshold:r=.8,label_ids_to_fuse:i=null,target_sizes:s=null,subtask:o=null}={}){if(Array.isArray(e)&&1!==e.length)throw Error("Image segmentation pipeline currently only supports a batch size of 1.");const a=await p(e),l=a.map((e=>[e.height,e.width])),{pixel_values:d,pixel_mask:u}=await this.processor(a),h=await this.model({pixel_values:d,pixel_mask:u});let f=null;if(null!==o)f=this.subtasks_mapping[o];else for(let[e,t]of Object.entries(this.subtasks_mapping))if(t in this.processor.feature_extractor){f=this.processor.feature_extractor[t].bind(this.processor.feature_extractor),o=e;break}const m=this.model.config.id2label,g=[];if("panoptic"===o||"instance"===o){const e=f(h,t,n,r,i,s??l)[0],o=e.segmentation;for(const t of e.segments_info){const e=new Uint8ClampedArray(o.data.length);for(let n=0;n<o.data.length;++n)o.data[n]===t.id&&(e[n]=255);const n=new c.RawImage(e,o.dims[1],o.dims[0],1);g.push({score:t.score,label:m[t.label_id],mask:n})}}else{if("semantic"!==o)throw Error(`Subtask ${o} not supported.`);{const{segmentation:e,labels:t}=f(h,s??l)[0];for(const n of t){const t=new Uint8ClampedArray(e.data.length);for(let r=0;r<e.data.length;++r)e.data[r]===n&&(t[r]=255);const r=new c.RawImage(t,e.dims[1],e.dims[0],1);g.push({score:null,label:m[n],mask:r})}}}return g}}class I extends m{constructor(e){super(e)}async _call(e,t,{hypothesis_template:n="This is a photo of {}"}={}){const r=Array.isArray(e),i=await p(e),s=t.map((e=>n.replace("{}",e))),o=this.tokenizer(s,{padding:"siglip"!==this.model.config.model_type||"max_length",truncation:!0}),{pixel_values:a}=await this.processor(i),d=await this.model({...o,pixel_values:a}),u="siglip"===this.model.config.model_type?e=>e.sigmoid().data:e=>(0,l.softmax)(e.data),c=[];for(const e of d.logits_per_image){const n=[...u(e)].map(((e,n)=>({score:e,label:t[n]})));n.sort(((e,t)=>t.score-e.score)),c.push(n)}return r?c:c[0]}}class z extends m{constructor(e){super(e)}async _call(e,{threshold:t=.9,percentage:n=!1}={}){const r=Array.isArray(e);if(r&&1!==e.length)throw Error("Object detection pipeline currently only supports a batch size of 1.");const i=await p(e),s=n?null:i.map((e=>[e.height,e.width])),{pixel_values:o,pixel_mask:a}=await this.processor(i),l=await this.model({pixel_values:o,pixel_mask:a}),d=this.processor.feature_extractor.post_process_object_detection(l,t,s),u=this.model.config.id2label,c=d.map((e=>e.boxes.map(((t,r)=>({score:e.scores[r],label:u[e.classes[r]],box:f(t,!n)})))));return r?c:c[0]}}class B extends m{constructor(e){super(e)}async _call(e,t,{threshold:n=.1,topk:r=null,percentage:i=!1}={}){const s=Array.isArray(e),o=await p(e),a=this.tokenizer(t,{padding:!0,truncation:!0}),l=await this.processor(o),d=[];for(let e=0;e<o.length;++e){const s=o[e],u=i?null:[[s.height,s.width]],c=l.pixel_values[e].unsqueeze_(0),p=await this.model({...a,pixel_values:c}),h=this.processor.feature_extractor.post_process_object_detection(p,n,u,!0)[0];let m=h.boxes.map(((e,n)=>({score:h.scores[n],label:t[h.classes[n]],box:f(e,!i)}))).sort(((e,t)=>t.score-e.score));null!==r&&(m=m.slice(0,r)),d.push(m)}return s?d:d[0]}}class O extends m{constructor(e){super(e)}async _call(e,t,n={}){throw new Error("This pipeline is not yet supported in Transformers.js v3.")}}class L extends m{DEFAULT_VOCODER_ID="Xenova/speecht5_hifigan";constructor(e){super(e),this.vocoder=e.vocoder??null}async _call(e,{speaker_embeddings:t=null}={}){throw new Error("This pipeline is not yet supported in Transformers.js v3.")}async _call_text_to_waveform(e){const t=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:n}=await this.model(t),r=this.model.config.sampling_rate;return{audio:n.data,sampling_rate:r}}async _call_text_to_spectrogram(e,{speaker_embeddings:t}){if(this.vocoder||(console.log("No vocoder specified, using default HifiGan vocoder."),this.vocoder=await i.AutoModel.from_pretrained(this.DEFAULT_VOCODER_ID,{dtype:"fp32"})),("string"==typeof t||t instanceof URL)&&(t=new Float32Array(await(await fetch(t)).arrayBuffer())),t instanceof Float32Array)t=new u.Tensor("float32",t,[1,t.length]);else if(!(t instanceof u.Tensor))throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");const{input_ids:n}=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:r}=await this.model.generate_speech(n,t,{vocoder:this.vocoder}),s=this.processor.feature_extractor.config.sampling_rate;return{audio:r.data,sampling_rate:s}}}class D extends m{constructor(e){super(e)}async _call(e){const t=await p(e),n=await this.processor(t),r=await this.model(n),i=[];for(const e of r.reconstruction){const t=e.squeeze().clamp_(0,1).mul_(255).round_().to("uint8");i.push(c.RawImage.fromTensor(t))}return i.length>1?i:i[0]}}class R extends m{constructor(e){super(e)}async _call(e){const t=await p(e),n=await this.processor(t),{predicted_depth:r}=await this.model(n),i=[];for(let e=0;e<t.length;++e){const n=(0,u.interpolate)(r[e],t[e].size.reverse(),"bilinear",!1),s=n.mul_(255/(0,l.max)(n.data)[0]).to("uint8");i.push({predicted_depth:r[e],depth:c.RawImage.fromTensor(s)})}return i.length>1?i:i[0]}}const N=Object.freeze({"text-classification":{tokenizer:r.AutoTokenizer,pipeline:g,model:i.AutoModelForSequenceClassification,default:{model:"Xenova/distilbert-base-uncased-finetuned-sst-2-english"},type:"text"},"token-classification":{tokenizer:r.AutoTokenizer,pipeline:_,model:i.AutoModelForTokenClassification,default:{model:"Xenova/bert-base-multilingual-cased-ner-hrl"},type:"text"},"question-answering":{tokenizer:r.AutoTokenizer,pipeline:w,model:i.AutoModelForQuestionAnswering,default:{model:"Xenova/distilbert-base-cased-distilled-squad"},type:"text"},"fill-mask":{tokenizer:r.AutoTokenizer,pipeline:y,model:i.AutoModelForMaskedLM,default:{model:"Xenova/bert-base-uncased"},type:"text"},summarization:{tokenizer:r.AutoTokenizer,pipeline:v,model:i.AutoModelForSeq2SeqLM,default:{model:"Xenova/distilbart-cnn-6-6"},type:"text"},translation:{tokenizer:r.AutoTokenizer,pipeline:x,model:i.AutoModelForSeq2SeqLM,default:{model:"Xenova/t5-small"},type:"text"},"text2text-generation":{tokenizer:r.AutoTokenizer,pipeline:b,model:i.AutoModelForSeq2SeqLM,default:{model:"Xenova/flan-t5-small"},type:"text"},"text-generation":{tokenizer:r.AutoTokenizer,pipeline:M,model:i.AutoModelForCausalLM,default:{model:"Xenova/gpt2"},type:"text"},"zero-shot-classification":{tokenizer:r.AutoTokenizer,pipeline:T,model:i.AutoModelForSequenceClassification,default:{model:"Xenova/distilbert-base-uncased-mnli"},type:"text"},"audio-classification":{pipeline:S,model:i.AutoModelForAudioClassification,processor:s.AutoProcessor,default:{model:"Xenova/wav2vec2-base-superb-ks"},type:"audio"},"zero-shot-audio-classification":{tokenizer:r.AutoTokenizer,pipeline:C,model:i.AutoModel,processor:s.AutoProcessor,default:{model:"Xenova/clap-htsat-unfused"},type:"multimodal"},"automatic-speech-recognition":{tokenizer:r.AutoTokenizer,pipeline:P,model:[i.AutoModelForSpeechSeq2Seq,i.AutoModelForCTC],processor:s.AutoProcessor,default:{model:"Xenova/whisper-tiny.en"},type:"multimodal"},"text-to-audio":{tokenizer:r.AutoTokenizer,pipeline:L,model:[i.AutoModelForTextToWaveform,i.AutoModelForTextToSpectrogram],processor:[s.AutoProcessor,null],default:{model:"Xenova/speecht5_tts"},type:"text"},"image-to-text":{tokenizer:r.AutoTokenizer,pipeline:E,model:i.AutoModelForVision2Seq,processor:s.AutoProcessor,default:{model:"Xenova/vit-gpt2-image-captioning"},type:"multimodal"},"image-classification":{pipeline:A,model:i.AutoModelForImageClassification,processor:s.AutoProcessor,default:{model:"Xenova/vit-base-patch16-224"},type:"multimodal"},"image-segmentation":{pipeline:F,model:[i.AutoModelForImageSegmentation,i.AutoModelForSemanticSegmentation],processor:s.AutoProcessor,default:{model:"Xenova/detr-resnet-50-panoptic"},type:"multimodal"},"zero-shot-image-classification":{tokenizer:r.AutoTokenizer,pipeline:I,model:i.AutoModel,processor:s.AutoProcessor,default:{model:"Xenova/clip-vit-base-patch32"},type:"multimodal"},"object-detection":{pipeline:z,model:i.AutoModelForObjectDetection,processor:s.AutoProcessor,default:{model:"Xenova/detr-resnet-50"},type:"multimodal"},"zero-shot-object-detection":{tokenizer:r.AutoTokenizer,pipeline:B,model:i.AutoModelForZeroShotObjectDetection,processor:s.AutoProcessor,default:{model:"Xenova/owlvit-base-patch32"},type:"multimodal"},"document-question-answering":{tokenizer:r.AutoTokenizer,pipeline:O,model:i.AutoModelForDocumentQuestionAnswering,processor:s.AutoProcessor,default:{model:"Xenova/donut-base-finetuned-docvqa"},type:"multimodal"},"image-to-image":{pipeline:D,model:i.AutoModelForImageToImage,processor:s.AutoProcessor,default:{model:"Xenova/swin2SR-classical-sr-x2-64"},type:"image"},"depth-estimation":{pipeline:R,model:i.AutoModelForDepthEstimation,processor:s.AutoProcessor,default:{model:"Xenova/dpt-large"},type:"image"},"feature-extraction":{tokenizer:r.AutoTokenizer,pipeline:k,model:i.AutoModel,default:{model:"Xenova/all-MiniLM-L6-v2"},type:"text"},"image-feature-extraction":{processor:s.AutoProcessor,pipeline:$,model:[i.AutoModelForImageFeatureExtraction,i.AutoModel],default:{model:"Xenova/vit-base-patch16-224-in21k"},type:"image"}}),V=Object.freeze({"sentiment-analysis":"text-classification",ner:"token-classification",asr:"automatic-speech-recognition","text-to-speech":"text-to-audio",embeddings:"feature-extraction"});async function j(e,t=null,{progress_callback:n=null,config:r=null,cache_dir:i=null,local_files_only:s=!1,revision:o="main",device:l=null,dtype:d=null,model_file_name:u=null,session_options:c={}}={}){e=V[e]??e;const p=N[e.split("_",1)[0]];if(!p)throw Error(`Unsupported pipeline: ${e}. Must be one of [${Object.keys(N)}]`);t||(t=p.default.model,console.log(`No model specified. Using default model: "${t}".`));const h={progress_callback:n,config:r,cache_dir:i,local_files_only:s,revision:o,device:l,dtype:d,model_file_name:u,session_options:c},f=new Map([["tokenizer",p.tokenizer],["model",p.model],["processor",p.processor]]),m=await async function(e,t,n){const r=Object.create(null),i=[];for(let[s,o]of e.entries()){if(!o)continue;let e;e=Array.isArray(o)?new Promise((async(e,r)=>{let i;for(let s of o){if(null===s)return void e(null);try{return void e(await s.from_pretrained(t,n))}catch(e){if(!e.message?.includes("Unsupported model type"))return void r(e);i=e}}r(i)})):o.from_pretrained(t,n),r[s]=e,i.push(e)}await Promise.all(i);for(let[e,t]of Object.entries(r))r[e]=await t;return r}(f,t,h);m.task=e,(0,a.dispatchCallback)(n,{status:"ready",task:e,model:t});return new(0,p.pipeline)(m)}},"./src/processors.js":
/*!***************************!*\
  !*** ./src/processors.js ***!
  \***************************/(e,t,n)=>{n.r(t),n.d(t,{ASTFeatureExtractor:()=>q,AutoProcessor:()=>ee,BeitFeatureExtractor:()=>z,BitImageProcessor:()=>y,CLIPFeatureExtractor:()=>v,CLIPImageProcessor:()=>x,ChineseCLIPFeatureExtractor:()=>M,ClapFeatureExtractor:()=>W,ConvNextFeatureExtractor:()=>k,ConvNextImageProcessor:()=>$,DPTFeatureExtractor:()=>_,DPTImageProcessor:()=>w,DeiTFeatureExtractor:()=>I,DetrFeatureExtractor:()=>L,DonutFeatureExtractor:()=>B,EfficientNetImageProcessor:()=>P,FeatureExtractor:()=>f,GLPNFeatureExtractor:()=>b,ImageFeatureExtractor:()=>m,MobileViTFeatureExtractor:()=>E,NougatImageProcessor:()=>O,OwlViTFeatureExtractor:()=>A,OwlViTProcessor:()=>J,Owlv2ImageProcessor:()=>F,Processor:()=>X,SamImageProcessor:()=>R,SamProcessor:()=>Q,SeamlessM4TFeatureExtractor:()=>G,SegformerFeatureExtractor:()=>g,SiglipImageProcessor:()=>T,SpeechT5FeatureExtractor:()=>H,SpeechT5Processor:()=>Z,Swin2SRImageProcessor:()=>N,ViTFeatureExtractor:()=>S,ViTImageProcessor:()=>C,VitMatteImageProcessor:()=>V,Wav2Vec2FeatureExtractor:()=>U,Wav2Vec2ProcessorWithLM:()=>Y,WhisperFeatureExtractor:()=>j,WhisperProcessor:()=>K,YolosFeatureExtractor:()=>D});var r=n(/*! ./utils/generic.js */"./src/utils/generic.js"),i=n(/*! ./utils/core.js */"./src/utils/core.js"),s=n(/*! ./utils/hub.js */"./src/utils/hub.js"),o=n(/*! ./utils/maths.js */"./src/utils/maths.js"),a=n(/*! ./utils/tensor.js */"./src/utils/tensor.js"),l=(n(/*! ./utils/image.js */"./src/utils/image.js"),n(/*! ./utils/audio.js */"./src/utils/audio.js"));function d([e,t,n,r]){return[e-n/2,t-r/2,e+n/2,t+r/2]}function u(e,t=.5,n=null,r=!1){const i=e.logits,s=e.pred_boxes,[a,l,u]=i.dims;if(null!==n&&n.length!==a)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let c=[];for(let e=0;e<a;++e){let a=null!==n?n[e]:null,p={boxes:[],classes:[],scores:[]},h=i[e],f=s[e];for(let e=0;e<l;++e){let n,i=h[e],s=[];if(r){n=i.sigmoid().data;for(let e=0;e<n.length;++e)n[e]>t&&s.push(e)}else{let e=(0,o.max)(i.data)[1];if(e===u-1)continue;if(n=(0,o.softmax)(i.data),n[e]<t)continue;s.push(e)}for(const t of s){let r=f[e].data;r=d(r),null!==a&&(r=r.map(((e,t)=>e*a[(t+1)%2]))),p.boxes.push(r),p.classes.push(t),p.scores.push(n[t])}}c.push(p)}return c}function c(e,t){if(!(e instanceof Float32Array||e instanceof Float64Array))throw new Error(`${t} expects input to be a Float32Array or a Float64Array, but got ${e?.constructor?.name??typeof e} instead. If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`)}function p(e,t,n=0,r=null){const i=e/t;let s=(0,o.bankers_round)(i)*t;return null!==r&&s>r&&(s=Math.floor(i)*t),s<n&&(s=Math.ceil(i)*t),s}function h([e,t],n){return[Math.max(Math.floor(e/n),1)*n,Math.max(Math.floor(t/n),1)*n]}class f extends r.Callable{constructor(e){super(),this.config=e}}class m extends f{constructor(e){super(e),this.image_mean=this.config.image_mean??this.config.mean,this.image_std=this.config.image_std??this.config.std,this.resample=this.config.resample??2,this.do_rescale=this.config.do_rescale??!0,this.rescale_factor=this.config.rescale_factor??1/255,this.do_normalize=this.config.do_normalize,this.do_resize=this.config.do_resize,this.do_thumbnail=this.config.do_thumbnail,this.size=this.config.size,this.size_divisibility=this.config.size_divisibility??this.config.size_divisor,this.do_center_crop=this.config.do_center_crop,this.crop_size=this.config.crop_size,this.do_convert_rgb=this.config.do_convert_rgb??!0,this.do_crop_margin=this.config.do_crop_margin,this.pad_size=this.config.pad_size,this.do_pad=this.config.do_pad,this.do_pad&&!this.pad_size&&this.size&&void 0!==this.size.width&&void 0!==this.size.height&&(this.pad_size=this.size)}async thumbnail(e,t,n=2){const r=e.height,i=e.width,s=t.height,o=t.width;let a=Math.min(r,s),l=Math.min(i,o);return a===r&&l===i?e:(r>i?l=Math.floor(i*a/r):i>r&&(a=Math.floor(r*l/i)),await e.resize(l,a,{resample:n}))}async crop_margin(e,t=200){const n=e.clone().grayscale(),r=(0,o.min)(n.data)[0],i=(0,o.max)(n.data)[0]-r;if(0===i)return e;const s=t/255;let a=n.width,l=n.height,d=0,u=0;const c=n.data;for(let e=0;e<n.height;++e){const t=e*n.width;for(let o=0;o<n.width;++o)(c[t+o]-r)/i<s&&(a=Math.min(a,o),l=Math.min(l,e),d=Math.max(d,o),u=Math.max(u,e))}return e=await e.crop([a,l,d,u])}pad_image(e,t,n,{mode:r="constant",center:s=!1,constant_values:o=0}={}){const[a,l,d]=t;let u,c;if("number"==typeof n?(u=n,c=n):(u=n.width,c=n.height),u!==l||c!==a){const n=new Float32Array(u*c*d);if(Array.isArray(o))for(let e=0;e<n.length;++e)n[e]=o[e%d];else 0!==o&&n.fill(o);const[p,h]=s?[Math.floor((u-l)/2),Math.floor((c-a)/2)]:[0,0];for(let t=0;t<a;++t){const r=(t+h)*u,i=t*l;for(let t=0;t<l;++t){const s=(r+t+p)*d,o=(i+t)*d;for(let t=0;t<d;++t)n[s+t]=e[o+t]}}if("symmetric"===r){if(s)throw new Error("`center` padding is not supported when `mode` is set to `symmetric`.");const t=a-1,r=l-1;for(let s=0;s<c;++s){const o=s*u,c=(0,i.calculateReflectOffset)(s,t)*l;for(let t=0;t<u;++t){if(s<a&&t<l)continue;const u=(o+t)*d,p=(c+(0,i.calculateReflectOffset)(t,r))*d;for(let t=0;t<d;++t)n[u+t]=e[p+t]}}}e=n,t=[c,u,d]}return[e,t]}rescale(e){for(let t=0;t<e.length;++t)e[t]=this.rescale_factor*e[t]}get_resize_output_image_size(e,t){const[n,r]=e.size;let i,s;if(this.do_thumbnail){const{height:e,width:n}=t;i=Math.min(e,n)}else Number.isInteger(t)?(i=t,s=this.config.max_size??i):void 0!==t&&(i=t.shortest_edge,s=t.longest_edge);if(void 0!==i||void 0!==s){const e=void 0===i?1:Math.max(i/n,i/r),t=n*e,o=r*e,a=void 0===s?1:Math.min(s/t,s/o);let l=Math.floor(Number((t*a).toFixed(2))),d=Math.floor(Number((o*a).toFixed(2)));return void 0!==this.size_divisibility&&([l,d]=h([l,d],this.size_divisibility)),[l,d]}if(void 0!==t&&void 0!==t.width&&void 0!==t.height){let e=t.width,i=t.height;if(this.config.keep_aspect_ratio&&this.config.ensure_multiple_of){let t=i/r,s=e/n;Math.abs(1-s)<Math.abs(1-t)?t=s:s=t,i=p(t*r,this.config.ensure_multiple_of),e=p(s*n,this.config.ensure_multiple_of)}return[e,i]}if(void 0!==this.size_divisibility)return h([n,r],this.size_divisibility);throw new Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(t)}`)}async resize(e){const[t,n]=this.get_resize_output_image_size(e,this.size);return await e.resize(t,n,{resample:this.resample})}async preprocess(e,{do_normalize:t=null,do_pad:n=null,do_convert_rgb:r=null,do_convert_grayscale:i=null}={}){this.do_crop_margin&&(e=await this.crop_margin(e));const[s,o]=e.size;if(r??this.do_convert_rgb?e=e.rgb():i&&(e=e.grayscale()),this.do_resize&&(e=await this.resize(e)),this.do_thumbnail&&(e=await this.thumbnail(e,this.size,this.resample)),this.do_center_crop){let t,n;Number.isInteger(this.crop_size)?(t=this.crop_size,n=this.crop_size):(t=this.crop_size.width,n=this.crop_size.height),e=await e.center_crop(t,n)}const l=[e.height,e.width];let d=Float32Array.from(e.data),u=[e.height,e.width,e.channels];if(this.do_rescale&&this.rescale(d),t??this.do_normalize){let t=this.image_mean;Array.isArray(this.image_mean)||(t=new Array(e.channels).fill(t));let n=this.image_std;if(Array.isArray(this.image_std)||(n=new Array(e.channels).fill(t)),t.length!==e.channels||n.length!==e.channels)throw new Error(`When set to arrays, the length of \`image_mean\` (${t.length}) and \`image_std\` (${n.length}) must match the number of channels in the image (${e.channels}).`);for(let r=0;r<d.length;r+=e.channels)for(let i=0;i<e.channels;++i)d[r+i]=(d[r+i]-t[i])/n[i]}if(n??this.do_pad)if(this.pad_size){const t=this.pad_image(d,[e.height,e.width,e.channels],this.pad_size);[d,u]=t}else if(this.size_divisibility){const[e,t]=h([u[1],u[0]],this.size_divisibility);[d,u]=this.pad_image(d,u,{width:e,height:t})}return{original_size:[o,s],reshaped_input_size:l,pixel_values:new a.Tensor("float32",d,u).permute(2,0,1)}}async _call(e,...t){Array.isArray(e)||(e=[e]);const n=await Promise.all(e.map((e=>this.preprocess(e))));return{pixel_values:(0,a.stack)(n.map((e=>e.pixel_values)),0),original_sizes:n.map((e=>e.original_size)),reshaped_input_sizes:n.map((e=>e.reshaped_input_size))}}}class g extends m{post_process_semantic_segmentation(e,t=null){const n=e.logits,r=n.dims[0];if(null!==t&&t.length!==r)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");const i=[];for(let e=0;e<r;++e){const r=null!==t?t[e]:null;let s=n[e];null!==r&&(s=(0,a.interpolate)(s,r,"bilinear",!1));const[o,l]=r??s.dims.slice(-2),d=new a.Tensor("int32",new Int32Array(o*l),[o,l]),u=s[0].data,c=d.data;for(let e=1;e<s.dims[0];++e){const t=s[e].data;for(let n=0;n<t.length;++n)t[n]>u[n]&&(u[n]=t[n],c[n]=e)}const p=new Array(s.dims[0]),h=d.data;for(let e=0;e<h.length;++e){const t=h[e];p[t]=t}const f=p.filter((e=>void 0!==e));i.push({segmentation:d,labels:f})}return i}}class _ extends m{}class w extends _{}class y extends m{}class b extends m{}class v extends m{}class x extends v{}class M extends m{}class T extends m{}class k extends m{constructor(e){super(e),this.crop_pct=this.config.crop_pct??.875}async resize(e){const t=this.size?.shortest_edge;if(void 0===t)throw new Error("Size dictionary must contain 'shortest_edge' key.");if(t<384){const n=Math.floor(t/this.crop_pct),[r,i]=this.get_resize_output_image_size(e,{shortest_edge:n});e=await e.resize(r,i,{resample:this.resample}),e=await e.center_crop(t,t)}else e=await e.resize(t,t,{resample:this.resample});return e}}class $ extends k{}class S extends m{}class C extends m{}class P extends m{constructor(e){super(e),this.include_top=this.config.include_top??!0,this.include_top&&(this.image_std=this.image_std.map((e=>e*e)))}}class E extends m{}class A extends m{post_process_object_detection(...e){return u(...e)}}class F extends A{}class I extends m{}class z extends m{}class B extends m{pad_image(e,t,n,r={}){const[i,s,o]=t;let a=this.image_mean;Array.isArray(this.image_mean)||(a=new Array(o).fill(a));let l=this.image_std;Array.isArray(l)||(l=new Array(o).fill(a));const d=a.map(((e,t)=>-e/l[t]));return super.pad_image(e,t,n,{center:!0,constant_values:d,...r})}}class O extends B{}class L extends m{async _call(e){const t=await super._call(e),n=[t.pixel_values.dims[0],64,64],r=new a.Tensor("int64",new BigInt64Array(n.reduce(((e,t)=>e*t))).fill(1n),n);return{...t,pixel_mask:r}}post_process_object_detection(...e){return u(...e)}remove_low_and_no_objects(e,t,n,r){let i=[],s=[],a=[];for(let l=0;l<e.dims[0];++l){let d=e[l],u=t[l],c=(0,o.max)(d.data)[1];if(c===r)continue;let p=(0,o.softmax)(d.data)[c];p>n&&(i.push(u),s.push(p),a.push(c))}return[i,s,a]}check_segment_validity(e,t,n,r=.5,i=.8){let s=[],o=0,a=0;const l=t[n].data;for(let t=0;t<e.length;++t)e[t]===n&&(s.push(t),++o),l[t]>=r&&++a;let d=o>0&&a>0;if(d){d=o/a>i}return[d,s]}compute_segments(e,t,n,r,i,s=null,o=null){let[l,d]=o??e[0].dims,u=new a.Tensor("int32",new Int32Array(l*d),[l,d]),c=[];if(null!==o)for(let t=0;t<e.length;++t)e[t]=(0,a.interpolate)(e[t],o,"bilinear",!1);let p=new Int32Array(e[0].data.length),h=new Float32Array(e[0].data.length);for(let n=0;n<e.length;++n){let r=t[n];const i=e[n].data;for(let e=0;e<i.length;++e)i[e]*=r,i[e]>h[e]&&(p[e]=n,h[e]=i[e])}let f=0;const m=u.data;for(let s=0;s<n.length;++s){let o=n[s],[a,l]=this.check_segment_validity(p,e,s,r,i);if(a){++f;for(let e of l)m[e]=f;c.push({id:f,label_id:o,score:t[s]})}}return[u,c]}post_process_panoptic_segmentation(e,t=.5,n=.5,r=.8,i=null,s=null){null===i&&(console.warn("`label_ids_to_fuse` unset. No instance will be fused."),i=new Set);const o=e.logits,l=e.pred_masks.sigmoid();let[d,u,c]=o.dims;if(c-=1,null!==s&&s.length!==d)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let p=[];for(let e=0;e<d;++e){let d=null!==s?s[e]:null,u=o[e],h=l[e],[f,m,g]=this.remove_low_and_no_objects(u,h,t,c);if(0===g.length){let[e,t]=d??h.dims.slice(-2),n=new a.Tensor("int32",new Int32Array(e*t).fill(-1),[e,t]);p.push({segmentation:n,segments_info:[]});continue}let[_,w]=this.compute_segments(f,m,g,n,r,i,d);p.push({segmentation:_,segments_info:w})}return p}post_process_instance_segmentation(){throw Error("Not implemented yet")}}class D extends m{post_process_object_detection(...e){return u(...e)}}class R extends m{reshape_input_points(e,t,n,r=!1){e=structuredClone(e);let s=(0,i.calculateDimensions)(e);if(3===s.length)r||(s=[1,...s]),e=[e];else if(4!==s.length)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");for(let r=0;r<e.length;++r){let i=t[r],s=n[r],o=[s[0]/i[0],s[1]/i[1]];for(let t=0;t<e[r].length;++t)for(let n=0;n<e[r][t].length;++n)for(let i=0;i<e[r][t][n].length;++i)e[r][t][n][i]*=o[i%2]}return new a.Tensor("float32",Float32Array.from(e.flat(1/0)),s)}add_input_labels(e,t){let n=(0,i.calculateDimensions)(e);if(2===n.length)n=[1,...n],e=[e];else if(3!==n.length)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");if(n.some(((e,n)=>e!==t.dims[n])))throw Error(`The first ${n.length} dimensions of 'input_points' and 'input_labels' must be the same.`);return new a.Tensor("int64",e.flat(1/0).map(BigInt),n)}async _call(e,t=null,n=null,r=null){const i=await super._call(e);if(t&&(i.input_points=this.reshape_input_points(t,i.original_sizes,i.reshaped_input_sizes)),n){if(!i.input_points)throw Error("`input_points` must be provided if `input_labels` are provided.");i.input_labels=this.add_input_labels(n,i.input_points)}return r&&(i.input_boxes=this.reshape_input_points(r,i.original_sizes,i.reshaped_input_sizes,!0)),i}async post_process_masks(e,t,n,{mask_threshold:r=0,binarize:i=!0,pad_size:s=null}={}){const o=[],l=[(s=s??this.pad_size).height,s.width];for(let s=0;s<t.length;++s){const d=t[s],u=n[s];let c=await(0,a.interpolate_4d)(e[s],{mode:"bilinear",size:l});if(c=c.slice(null,null,[0,u[0]],[0,u[1]]),c=await(0,a.interpolate_4d)(c,{mode:"bilinear",size:d}),i){const e=c.data,t=new Uint8Array(e.length);for(let n=0;n<e.length;++n)e[n]>r&&(t[n]=1);c=new a.Tensor("bool",t,c.dims)}o.push(c)}return o}generate_crop_boxes(e,t,{crop_n_layers:n=0,overlap_ratio:r=512/1500,points_per_crop:i=32,crop_n_points_downscale_factor:s=1}={}){}}class N extends m{pad_image(e,t,n,r={}){const[i,s,o]=t;return super.pad_image(e,t,{width:s+(n-s%n)%n,height:i+(n-i%n)%n},{mode:"symmetric",center:!1,constant_values:-1,...r})}}class V extends m{async _call(e,t){Array.isArray(e)||(e=[e]),Array.isArray(t)||(t=[t]);const n=await Promise.all(e.map((e=>this.preprocess(e)))),r=await Promise.all(t.map((e=>this.preprocess(e,{do_normalize:!1,do_convert_rgb:!1,do_convert_grayscale:!0}))));return{pixel_values:(0,a.stack)(n.map(((e,t)=>(0,a.cat)([e.pixel_values,r[t].pixel_values],0))),0),original_sizes:n.map((e=>e.original_size)),reshaped_input_sizes:n.map((e=>e.reshaped_input_size))}}}class j extends f{constructor(e){super(e),this.config.mel_filters??=(0,l.mel_filter_bank)(Math.floor(1+this.config.n_fft/2),this.config.feature_size,0,8e3,this.config.sampling_rate,"slaney","slaney"),this.window=(0,l.window_function)(this.config.n_fft,"hann")}_extract_fbank_features(e){const{data:t,dims:n}=(0,l.spectrogram)(e,this.window,this.config.n_fft,this.config.hop_length,{power:2,mel_filters:this.config.mel_filters,log_mel:"log10",max_num_frames:this.config.nb_max_frames}),r=(0,o.max)(t)[0];for(let e=0;e<t.length;++e)t[e]=(Math.max(t[e],r-8)+4)/4;return{data:t,dims:n}}async _call(e){let t;c(e,"WhisperFeatureExtractor"),e.length>this.config.n_samples?(console.warn("Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."),t=e.slice(0,this.config.n_samples)):(t=new Float32Array(this.config.n_samples),t.set(e));const{data:n,dims:r}=this._extract_fbank_features(t);return{input_features:new a.Tensor("float32",n,[1,...r])}}}class U extends f{_zero_mean_unit_var_norm(e){const t=e.reduce(((e,t)=>e+t),0)/e.length,n=e.reduce(((e,n)=>e+(n-t)**2),0)/e.length;return e.map((e=>(e-t)/Math.sqrt(n+1e-7)))}async _call(e){c(e,"Wav2Vec2FeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=e;this.config.do_normalize&&(t=this._zero_mean_unit_var_norm(t));const n=[1,t.length];return{input_values:new a.Tensor("float32",t,n),attention_mask:new a.Tensor("int64",new BigInt64Array(t.length).fill(1n),n)}}}class G extends f{constructor(e){super(e);const t=this.config.sampling_rate,n=(0,l.mel_filter_bank)(256,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);for(let e=0;e<n.length;++e)n[e].push(0);this.mel_filters=n,this.window=(0,l.window_function)(400,"povey",{periodic:!1})}_extract_fbank_features(e,t){return e=e.map((e=>32768*e)),(0,l.spectrogram)(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1.192092955078125e-7,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e,{padding:t=!0,pad_to_multiple_of:n=2,do_normalize_per_mel_bins:r=!0,return_attention_mask:i=!0}={}){c(e,"SeamlessM4TFeatureExtractor");let s=this._extract_fbank_features(e,this.config.max_length);const o=s.data;if(r){const[e,t]=s.dims;for(let n=0;n<t;++n){let r=0;for(let i=0;i<e;++i)r+=o[i*t+n];const i=r/e;let s=0;for(let r=0;r<e;++r)s+=(o[r*t+n]-i)**2;s/=e-1;const a=Math.sqrt(s+1e-7);for(let r=0;r<e;++r){const e=r*t+n;o[e]=(o[e]-i)/a}}}let l;if(t){const[e,t]=s.dims,r=e%n;if(r>0){const n=new Float32Array(t*(e+r));n.set(o),n.fill(this.config.padding_value,o.length);const d=e+r;s={data:n,dims:[d,t]},i&&(l=new a.Tensor("int64",new BigInt64Array(d),[1,d]),l.data.fill(1n,0,e))}}const[d,u]=s.dims,p=this.config.stride;if(0!==d%p)throw new Error(`The number of frames (${d}) must be a multiple of the stride (${p}).`);const h=new a.Tensor("float32",o,s.dims).view(1,Math.floor(d/p),u*p),f={input_features:h};if(i){const e=h.dims[1],t=new BigInt64Array(e);if(l){const e=l.data;for(let n=1,r=0;n<d;n+=p,++r)t[r]=e[n]}else t.fill(1n);f.attention_mask=new a.Tensor("int64",t,[1,e])}return f}}class q extends f{constructor(e){super(e);const t=this.config.sampling_rate,n=(0,l.mel_filter_bank)(256,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);for(let e=0;e<n.length;++e)n[e].push(0);this.mel_filters=n,this.window=(0,l.window_function)(400,"hann",{periodic:!1}),this.mean=this.config.mean,this.std=this.config.std}_extract_fbank_features(e,t){return(0,l.spectrogram)(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1.192092955078125e-7,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e){c(e,"ASTFeatureExtractor");const t=this._extract_fbank_features(e,this.config.max_length);if(this.config.do_normalize){const e=2*this.std,n=t.data;for(let t=0;t<n.length;++t)n[t]=(n[t]-this.mean)/e}return{input_values:new a.Tensor("float32",t.data,[1,...t.dims])}}}class W extends f{constructor(e){super(e),this.mel_filters=(0,l.mel_filter_bank)(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,null,"htk"),this.mel_filters_slaney=(0,l.mel_filter_bank)(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,"slaney","slaney"),this.window=(0,l.window_function)(this.config.fft_window_size,"hann")}_get_input_mel(e,t,n,r){let i,s=!1;const o=e.length-t;if(o>0){if("rand_trunc"!==n)throw new Error(`Truncation strategy "${n}" not implemented`);{s=!0;const n=Math.floor(Math.random()*(o+1));e=e.subarray(n,n+t),i=this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples),i.dims=[1,...i.dims]}}else{if(o<0){let n=new Float64Array(t);if(n.set(e),"repeat"===r)for(let r=e.length;r<t;r+=e.length)n.set(e.subarray(0,Math.min(e.length,t-r)),r);else if("repeatpad"===r)for(let t=e.length;t<-o;t+=e.length)n.set(e,t);e=n}if("fusion"===n)throw new Error(`Truncation strategy "${n}" not implemented`);i=this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples),i.dims=[1,...i.dims]}return{...i,longer:s}}_extract_fbank_features(e,t,n=null){return(0,l.spectrogram)(e,this.window,this.config.fft_window_size,this.config.hop_length,{power:2,mel_filters:t,log_mel:"dB",max_num_frames:n,do_pad:!1,transpose:!0})}async _call(e,{max_length:t=null}={}){c(e,"ClapFeatureExtractor");const n=this._get_input_mel(e,t??this.config.nb_max_samples,this.config.truncation,this.config.padding);return{input_features:new a.Tensor("float32",n.data,[1,...n.dims])}}}class H extends f{}class X extends r.Callable{constructor(e){super(),this.feature_extractor=e}async _call(e,...t){return await this.feature_extractor(e,...t)}}class Q extends X{async _call(...e){return await this.feature_extractor(...e)}post_process_masks(...e){return this.feature_extractor.post_process_masks(...e)}reshape_input_points(...e){return this.feature_extractor.reshape_input_points(...e)}}class K extends X{async _call(e){return await this.feature_extractor(e)}}class Y extends X{async _call(e){return await this.feature_extractor(e)}}class Z extends X{async _call(e){return await this.feature_extractor(e)}}class J extends X{}class ee{static FEATURE_EXTRACTOR_CLASS_MAPPING={ImageFeatureExtractor:m,WhisperFeatureExtractor:j,ViTFeatureExtractor:S,MobileViTFeatureExtractor:E,OwlViTFeatureExtractor:A,Owlv2ImageProcessor:F,CLIPFeatureExtractor:v,CLIPImageProcessor:x,ChineseCLIPFeatureExtractor:M,SiglipImageProcessor:T,ConvNextFeatureExtractor:k,ConvNextImageProcessor:$,SegformerFeatureExtractor:g,BitImageProcessor:y,DPTImageProcessor:w,DPTFeatureExtractor:_,GLPNFeatureExtractor:b,BeitFeatureExtractor:z,DeiTFeatureExtractor:I,DetrFeatureExtractor:L,YolosFeatureExtractor:D,DonutFeatureExtractor:B,NougatImageProcessor:O,EfficientNetImageProcessor:P,ViTImageProcessor:C,VitMatteImageProcessor:V,SamImageProcessor:R,Swin2SRImageProcessor:N,Wav2Vec2FeatureExtractor:U,SeamlessM4TFeatureExtractor:G,SpeechT5FeatureExtractor:H,ASTFeatureExtractor:q,ClapFeatureExtractor:W};static PROCESSOR_CLASS_MAPPING={WhisperProcessor:K,Wav2Vec2ProcessorWithLM:Y,SamProcessor:Q,SpeechT5Processor:Z,OwlViTProcessor:J};static async from_pretrained(e,{progress_callback:t=null,config:n=null,cache_dir:r=null,local_files_only:i=!1,revision:o="main"}={}){let a=n??await(0,s.getModelJSON)(e,"preprocessor_config.json",!0,{progress_callback:t,config:n,cache_dir:r,local_files_only:i,revision:o}),l=a.feature_extractor_type??a.image_processor_type,d=this.FEATURE_EXTRACTOR_CLASS_MAPPING[l];if(!d){if(void 0===a.size)throw new Error(`Unknown Feature Extractor type: ${l}`);console.warn(`Feature extractor type "${l}" not found, assuming ImageFeatureExtractor due to size parameter in config.`),d=m}return new(this.PROCESSOR_CLASS_MAPPING[a.processor_class]??X)(new d(a))}}},"./src/tokenizers.js":
/*!***************************!*\
  !*** ./src/tokenizers.js ***!
  \***************************/(e,t,n)=>{n.r(t),n.d(t,{AlbertTokenizer:()=>_e,AutoTokenizer:()=>ct,BartTokenizer:()=>Ae,BertTokenizer:()=>ge,BlenderbotSmallTokenizer:()=>ot,BlenderbotTokenizer:()=>st,BloomTokenizer:()=>Be,CLIPTokenizer:()=>tt,CamembertTokenizer:()=>$e,CodeGenTokenizer:()=>et,CodeLlamaTokenizer:()=>De,CohereTokenizer:()=>ut,ConvBertTokenizer:()=>Me,DebertaTokenizer:()=>be,DebertaV2Tokenizer:()=>ve,DistilBertTokenizer:()=>ke,ElectraTokenizer:()=>Ce,EsmTokenizer:()=>Ue,FalconTokenizer:()=>Ve,GPT2Tokenizer:()=>Ee,GPTNeoXTokenizer:()=>je,GemmaTokenizer:()=>qe,Grok1Tokenizer:()=>We,HerbertTokenizer:()=>xe,LlamaTokenizer:()=>Le,M2M100Tokenizer:()=>Qe,MBart50Tokenizer:()=>Ie,MBartTokenizer:()=>Fe,MPNetTokenizer:()=>Ne,MarianTokenizer:()=>rt,MobileBertTokenizer:()=>we,NllbTokenizer:()=>Xe,NougatTokenizer:()=>lt,PreTrainedTokenizer:()=>me,Qwen2Tokenizer:()=>Ge,RoFormerTokenizer:()=>Te,RobertaTokenizer:()=>ze,SiglipTokenizer:()=>nt,SpeechT5Tokenizer:()=>at,SqueezeBertTokenizer:()=>ye,T5Tokenizer:()=>Pe,TokenizerModel:()=>y,VitsTokenizer:()=>dt,Wav2Vec2CTCTokenizer:()=>it,WhisperTokenizer:()=>Je,XLMRobertaTokenizer:()=>Re,XLMTokenizer:()=>Se});var r=n(/*! ./utils/generic.js */"./src/utils/generic.js"),i=n(/*! ./utils/core.js */"./src/utils/core.js"),s=n(/*! ./utils/hub.js */"./src/utils/hub.js"),o=n(/*! ./utils/maths.js */"./src/utils/maths.js"),a=n(/*! ./utils/tensor.js */"./src/utils/tensor.js"),l=n(/*! ./utils/data-structures.js */"./src/utils/data-structures.js"),d=n(/*! @huggingface/jinja */"./node_modules/@huggingface/jinja/dist/index.js");async function u(e,t){const n=await Promise.all([(0,s.getModelJSON)(e,"tokenizer.json",!0,t),(0,s.getModelJSON)(e,"tokenizer_config.json",!0,t)]);return null!==t.legacy&&(n[1].legacy=t.legacy),n}function c(e,t=!0){if(void 0!==e.Regex){let t=e.Regex.replace(/\\([#&~])/g,"$1");for(const[e,n]of _)t=t.replaceAll(e,n);return new RegExp(t,"gu")}if(void 0!==e.String){const n=(0,i.escapeRegExp)(e.String);return new RegExp(t?n:`(${n})`,"gu")}return console.warn("Unknown pattern type:",e),null}function p(e){return new Map(Object.entries(e))}function h(e){const t=e.dims;switch(t.length){case 1:return e.tolist();case 2:if(1!==t[0])throw new Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.");return e.tolist()[0];default:throw new Error(`Expected tensor to have 1-2 dimensions, got ${t.length}.`)}}function f(e){return e.replace(/ \./g,".").replace(/ \?/g,"?").replace(/ \!/g,"!").replace(/ ,/g,",").replace(/ \' /g,"'").replace(/ n\'t/g,"n't").replace(/ \'m/g,"'m").replace(/ \'s/g,"'s").replace(/ \'ve/g,"'ve").replace(/ \'re/g,"'re")}function m(e){return e.replace(/[\u0300-\u036f]/g,"")}const g="\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E",_=new Map([["(?i:'s|'t|'re|'ve|'m|'ll|'d)","(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))"]]);class w{constructor(e){this.content=e.content,this.id=e.id,this.single_word=e.single_word??!1,this.lstrip=e.lstrip??!1,this.rstrip=e.rstrip??!1,this.special=e.special??!1,this.normalized=e.normalized??null}}class y extends r.Callable{constructor(e){super(),this.config=e,this.vocab=[],this.tokens_to_ids=new Map,this.unk_token_id=void 0,this.unk_token=void 0,this.end_of_word_suffix=void 0,this.fuse_unk=this.config.fuse_unk??!1}static fromConfig(e,...t){switch(e.type){case"WordPiece":return new b(e);case"Unigram":return new v(e,...t);case"BPE":return new T(e);default:if(e.vocab)return new k(e,...t);throw new Error(`Unknown TokenizerModel type: ${e.type}`)}}_call(e){let t=this.encode(e);return this.fuse_unk&&(t=function(e,t,n){const r=[];let i=0;for(;i<e.length;)if(r.push(e[i]),(n.get(e[i])??t)===t)for(;i<e.length&&(n.get(e[i])??t)===t;)++i;else++i;return r}(t,this.unk_token_id,this.tokens_to_ids)),t}encode(e){throw Error("encode should be implemented in subclass.")}convert_tokens_to_ids(e){return e.map((e=>this.tokens_to_ids.get(e)??this.unk_token_id))}convert_ids_to_tokens(e){return e.map((e=>this.vocab[e]??this.unk_token))}}class b extends y{constructor(e){super(e),this.tokens_to_ids=p(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.max_input_chars_per_word=e.max_input_chars_per_word??100,this.vocab=new Array(this.tokens_to_ids.size);for(const[e,t]of this.tokens_to_ids)this.vocab[t]=e}encode(e){const t=[];for(const n of e){const e=[...n];if(e.length>this.max_input_chars_per_word){t.push(this.unk_token);continue}let r=!1,i=0;const s=[];for(;i<e.length;){let t=e.length,n=null;for(;i<t;){let r=e.slice(i,t).join("");if(i>0&&(r=this.config.continuing_subword_prefix+r),this.tokens_to_ids.has(r)){n=r;break}--t}if(null===n){r=!0;break}s.push(n),i=t}r?t.push(this.unk_token):t.push(...s)}return t}}class v extends y{constructor(e,t){super(e);const n=e.vocab.length;this.vocab=new Array(n),this.scores=new Array(n);for(let t=0;t<n;++t){const n=e.vocab[t];this.vocab[t]=n[0],this.scores[t]=n[1]}this.unk_token_id=e.unk_id,this.unk_token=this.vocab[e.unk_id],this.tokens_to_ids=new Map(this.vocab.map(((e,t)=>[e,t]))),this.bosToken=" ",this.bosTokenId=this.tokens_to_ids.get(this.bosToken),this.eosToken=t.eos_token,this.eosTokenId=this.tokens_to_ids.get(this.eosToken),this.unkToken=this.vocab[this.unk_token_id],this.minScore=(0,o.min)(this.scores)[0],this.unkScore=this.minScore-10,this.scores[this.unk_token_id]=this.unkScore,this.trie=new l.CharTrie,this.trie.extend(this.vocab),this.fuse_unk=!0}populateNodes(e){const t=e.sentence,n=t.length;let r=0;for(;r<n;){const n=1;let i=!1;const s=[];for(let o of this.trie.commonPrefixSearch(t.slice(r))){s.push(o);const t=this.tokens_to_ids.get(o),a=this.scores[t],l=o.length;e.insert(r,l,a,t),i||l!==n||(i=!0)}i||e.insert(r,n,this.unkScore,this.unk_token_id),r+=n}}tokenize(e){const t=new l.TokenLattice(e,this.bosTokenId,this.eosTokenId);return this.populateNodes(t),t.tokens()}encode(e){const t=[];for(const n of e){const e=this.tokenize(n);t.push(...e)}return t}}const x=(()=>{const e=[...Array.from({length:"~".charCodeAt(0)-"!".charCodeAt(0)+1},((e,t)=>t+"!".charCodeAt(0))),...Array.from({length:"¬".charCodeAt(0)-"¡".charCodeAt(0)+1},((e,t)=>t+"¡".charCodeAt(0))),...Array.from({length:"ÿ".charCodeAt(0)-"®".charCodeAt(0)+1},((e,t)=>t+"®".charCodeAt(0)))],t=e.slice();let n=0;for(let r=0;r<256;++r)e.includes(r)||(e.push(r),t.push(256+n),n+=1);const r=t.map((e=>String.fromCharCode(e)));return Object.fromEntries(e.map(((e,t)=>[e,r[t]])))})(),M=(0,i.reverseDictionary)(x);class T extends y{constructor(e){super(e),this.BPE_SPLIT_TOKEN=" ",this.tokens_to_ids=p(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.vocab=new Array(this.tokens_to_ids.size);for(const[e,t]of this.tokens_to_ids)this.vocab[t]=e;this.bpe_ranks=new Map(e.merges.map(((e,t)=>[e,t]))),this.merges=e.merges.map((e=>e.split(this.BPE_SPLIT_TOKEN))),this.end_of_word_suffix=e.end_of_word_suffix,this.continuing_subword_suffix=e.continuing_subword_suffix??null,this.byte_fallback=this.config.byte_fallback??!1,this.byte_fallback&&(this.text_encoder=new TextEncoder),this.cache=new Map}bpe(e){if(0===e.length)return[];const t=this.cache.get(e);if(void 0!==t)return t;const n=Array.from(e);this.end_of_word_suffix&&(n[n.length-1]+=this.end_of_word_suffix);let r=[];if(n.length>1){const e=new l.PriorityQueue(((e,t)=>e.score<t.score));let t={token:n[0],bias:0,prev:null,next:null},i=t;for(let t=1;t<n.length;++t){const r={bias:t/n.length,token:n[t],prev:i,next:null};i.next=r,this._add_node(e,i),i=r}for(;!e.isEmpty();){const n=e.pop();if(n.deleted||!n.next||n.next.deleted)continue;if(n.deleted=!0,n.next.deleted=!0,n.prev){const e={...n.prev};n.prev.deleted=!0,n.prev=e,e.prev?e.prev.next=e:t=e}const r={token:n.token+n.next.token,bias:n.bias,prev:n.prev,next:n.next.next};r.prev?(r.prev.next=r,this._add_node(e,r.prev)):t=r,r.next&&(r.next.prev=r,this._add_node(e,r))}for(let e=t;null!==e;e=e.next)r.push(e.token)}else r=n;if(this.continuing_subword_suffix)for(let e=0;e<r.length-1;++e)r[e]+=this.continuing_subword_suffix;return this.cache.set(e,r),r}_add_node(e,t){const n=this.bpe_ranks.get(t.token+this.BPE_SPLIT_TOKEN+t.next.token);void 0!==n&&(t.score=n+t.bias,e.push(t))}encode(e){const t=[];for(const n of e){const e=this.bpe(n);for(const n of e)this.tokens_to_ids.has(n)?t.push(n):this.byte_fallback?t.push(...Array.from(this.text_encoder.encode(n)).map((e=>`<0x${e.toString(16).toUpperCase().padStart(2,"0")}>`))):t.push(this.unk_token)}return t}}class k extends y{constructor(e,t){super(e),this.tokens_to_ids=p(t.target_lang?e.vocab[t.target_lang]:e.vocab),this.bos_token=t.bos_token,this.bos_token_id=this.tokens_to_ids.get(this.bos_token),this.eos_token=t.eos_token,this.eos_token_id=this.tokens_to_ids.get(this.eos_token),this.pad_token=t.pad_token,this.pad_token_id=this.tokens_to_ids.get(this.pad_token),this.unk_token=t.unk_token,this.unk_token_id=this.tokens_to_ids.get(this.unk_token),this.vocab=new Array(this.tokens_to_ids.size);for(const[e,t]of this.tokens_to_ids)this.vocab[t]=e}encode(e){return e}}class $ extends r.Callable{constructor(e){super(),this.config=e}static fromConfig(e){if(null===e)return null;switch(e.type){case"BertNormalizer":return new O(e);case"Precompiled":return new ae(e);case"Sequence":return new B(e);case"Replace":return new S(e);case"NFC":return new C(e);case"NFKC":return new P(e);case"NFKD":return new E(e);case"Strip":return new A(e);case"StripAccents":return new F(e);case"Lowercase":return new I(e);case"Prepend":return new z(e);default:throw new Error(`Unknown Normalizer type: ${e.type}`)}}normalize(e){throw Error("normalize should be implemented in subclass.")}_call(e){return this.normalize(e)}}class S extends ${normalize(e){const t=c(this.config.pattern);return null===t?e:e.replaceAll(t,this.config.content)}}class C extends ${normalize(e){return e=e.normalize("NFC")}}class P extends ${normalize(e){return e=e.normalize("NFKC")}}class E extends ${normalize(e){return e=e.normalize("NFKD")}}class A extends ${normalize(e){return this.config.strip_left&&this.config.strip_right?e=e.trim():(this.config.strip_left&&(e=e.trimStart()),this.config.strip_right&&(e=e.trimEnd())),e}}class F extends ${normalize(e){return e=m(e)}}class I extends ${normalize(e){return e=e.toLowerCase()}}class z extends ${normalize(e){return e=this.config.prepend+e}}class B extends ${constructor(e){super(e),this.normalizers=e.normalizers.map((e=>$.fromConfig(e)))}normalize(e){return this.normalizers.reduce(((e,t)=>t.normalize(e)),e)}}class O extends ${_tokenize_chinese_chars(e){const t=[];for(let n=0;n<e.length;++n){const r=e[n],i=r.charCodeAt(0);this._is_chinese_char(i)?(t.push(" "),t.push(r),t.push(" ")):t.push(r)}return t.join("")}_is_chinese_char(e){return e>=19968&&e<=40959||e>=13312&&e<=19903||e>=131072&&e<=173791||e>=173824&&e<=177983||e>=177984&&e<=178207||e>=178208&&e<=183983||e>=63744&&e<=64255||e>=194560&&e<=195103}stripAccents(e){return e.normalize("NFD").replace(/[\u0300-\u036f]/g,"")}_is_control(e){switch(e){case"\t":case"\n":case"\r":return!1;default:return/^\p{Cc}|\p{Cf}|\p{Co}|\p{Cs}$/u.test(e)}}_clean_text(e){const t=[];for(const n of e){const e=n.charCodeAt(0);0===e||65533===e||this._is_control(n)||(/^\s$/.test(n)?t.push(" "):t.push(n))}return t.join("")}normalize(e){return this.config.clean_text&&(e=this._clean_text(e)),this.config.handle_chinese_chars&&(e=this._tokenize_chinese_chars(e)),this.config.lowercase?(e=e.toLowerCase(),!1!==this.config.strip_accents&&(e=this.stripAccents(e))):this.config.strip_accents&&(e=this.stripAccents(e)),e}}class L extends r.Callable{static fromConfig(e){if(null===e)return null;switch(e.type){case"BertPreTokenizer":return new D(e);case"Sequence":return new le(e);case"Whitespace":return new de(e);case"WhitespaceSplit":return new ue(e);case"Metaspace":return new se(e);case"ByteLevel":return new R(e);case"Split":return new N(e);case"Punctuation":return new V(e);case"Digits":return new j(e);case"Replace":return new ce(e);default:throw new Error(`Unknown PreTokenizer type: ${e.type}`)}}pre_tokenize_text(e,t){throw Error("pre_tokenize_text should be implemented in subclass.")}pre_tokenize(e,t){return(Array.isArray(e)?e.map((e=>this.pre_tokenize_text(e,t))):this.pre_tokenize_text(e,t)).flat()}_call(e,t){return this.pre_tokenize(e,t)}}class D extends L{constructor(e){super(),this.pattern=new RegExp(`[^\\s${g}]+|[${g}]`,"gu")}pre_tokenize_text(e,t){return e.trim().match(this.pattern)||[]}}class R extends L{constructor(e){super(),this.config=e,this.add_prefix_space=this.config.add_prefix_space,this.trim_offsets=this.config.trim_offsets,this.use_regex=this.config.use_regex??!0,this.pattern=/'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+/gu,this.byte_encoder=x,this.text_encoder=new TextEncoder}pre_tokenize_text(e,t){this.add_prefix_space&&!e.startsWith(" ")&&(e=" "+e);return(this.use_regex?e.match(this.pattern)||[]:[e]).map((e=>Array.from(this.text_encoder.encode(e),(e=>this.byte_encoder[e])).join("")))}}class N extends L{constructor(e){super(),this.config=e,this.pattern=c(this.config.pattern,this.config.invert)}pre_tokenize_text(e,t){return null===this.pattern?[]:this.config.invert?e.match(this.pattern)||[]:function(e,t){const n=[];let r=0;for(const i of e.matchAll(t)){const t=i[0];r<i.index&&n.push(e.slice(r,i.index)),t.length>0&&n.push(t),r=i.index+t.length}return r<e.length&&n.push(e.slice(r)),n}(e,this.pattern)}}class V extends L{constructor(e){super(),this.config=e,this.pattern=new RegExp(`[^${g}]+|[${g}]+`,"gu")}pre_tokenize_text(e,t){return e.match(this.pattern)||[]}}class j extends L{constructor(e){super(),this.config=e;const t="[^\\d]+|\\d"+(this.config.individual_digits?"":"+");this.pattern=new RegExp(t,"gu")}pre_tokenize_text(e,t){return e.match(this.pattern)||[]}}class U extends r.Callable{constructor(e){super(),this.config=e}static fromConfig(e){if(null===e)return null;switch(e.type){case"TemplateProcessing":return new W(e);case"ByteLevel":return new H(e);case"RobertaProcessing":return new q(e);case"BertProcessing":return new G(e);default:throw new Error(`Unknown PostProcessor type: ${e.type}`)}}post_process(e,...t){throw Error("post_process should be implemented in subclass.")}_call(e,...t){return this.post_process(e,...t)}}class G extends U{constructor(e){super(e),this.cls=e.cls[0],this.sep=e.sep[0]}post_process(e,t=null,{add_special_tokens:n=!0}={}){n&&(e=(0,i.mergeArrays)([this.cls],e,[this.sep]));let r=new Array(e.length).fill(0);if(null!==t){const s=n&&this instanceof q?[this.sep]:[],o=n?[this.sep]:[];e=(0,i.mergeArrays)(e,s,t,o),r=(0,i.mergeArrays)(r,new Array(t.length+s.length+o.length).fill(1))}return{tokens:e,token_type_ids:r}}}class q extends G{}class W extends U{constructor(e){super(e),this.single=e.single,this.pair=e.pair}post_process(e,t=null,{add_special_tokens:n=!0}={}){const r=null===t?this.single:this.pair;let s=[],o=[];for(const a of r)"SpecialToken"in a?n&&(s.push(a.SpecialToken.id),o.push(a.SpecialToken.type_id)):"Sequence"in a&&("A"===a.Sequence.id?(s=(0,i.mergeArrays)(s,e),o=(0,i.mergeArrays)(o,new Array(e.length).fill(a.Sequence.type_id))):"B"===a.Sequence.id&&(s=(0,i.mergeArrays)(s,t),o=(0,i.mergeArrays)(o,new Array(t.length).fill(a.Sequence.type_id))));return{tokens:s,token_type_ids:o}}}class H extends U{post_process(e,t=null){return t&&(e=(0,i.mergeArrays)(e,t)),{tokens:e}}}class X extends r.Callable{constructor(e){super(),this.config=e,this.added_tokens=[],this.end_of_word_suffix=null,this.trim_offsets=e.trim_offsets}static fromConfig(e){if(null===e)return null;switch(e.type){case"WordPiece":return new J(e);case"Metaspace":return new oe(e);case"ByteLevel":return new ee(e);case"Replace":return new Q(e);case"ByteFallback":return new K(e);case"Fuse":return new Y(e);case"Strip":return new Z(e);case"Sequence":return new ne(e);case"CTC":return new te(e);case"BPEDecoder":return new re(e);default:throw new Error(`Unknown Decoder type: ${e.type}`)}}_call(e){return this.decode(e)}decode(e){return this.decode_chain(e).join("")}decode_chain(e){throw Error("`decode_chain` should be implemented in subclass.")}}class Q extends X{decode_chain(e){const t=c(this.config.pattern);return null===t?e:e.map((e=>e.replaceAll(t,this.config.content)))}}class K extends X{constructor(e){super(e),this.text_decoder=new TextDecoder}decode_chain(e){const t=[];let n=[];for(const r of e){let e=null;if(6===r.length&&r.startsWith("<0x")&&r.endsWith(">")){const t=parseInt(r.slice(3,5),16);isNaN(t)||(e=t)}if(null!==e)n.push(e);else{if(n.length>0){const e=this.text_decoder.decode(Uint8Array.from(n));t.push(e),n=[]}t.push(r)}}if(n.length>0){const e=this.text_decoder.decode(Uint8Array.from(n));t.push(e),n=[]}return t}}class Y extends X{decode_chain(e){return[e.join("")]}}class Z extends X{constructor(e){super(e),this.content=this.config.content,this.start=this.config.start,this.stop=this.config.stop}decode_chain(e){return e.map((e=>{let t=0;for(let n=0;n<this.start&&e[n]===this.content;++n)t=n+1;let n=e.length;for(let t=0;t<this.stop;++t){const r=e.length-t-1;if(e[r]!==this.content)break;n=r}return e.slice(t,n)}))}}class J extends X{constructor(e){super(e),this.cleanup=e.cleanup}decode_chain(e){return e.map(((e,t)=>(0!==t&&(e=e.startsWith(this.config.prefix)?e.replace(this.config.prefix,""):" "+e),this.cleanup&&(e=f(e)),e)))}}class ee extends X{constructor(e){super(e),this.byte_decoder=M,this.text_decoder=new TextDecoder("utf-8",{fatal:!1,ignoreBOM:!0}),this.end_of_word_suffix=null}convert_tokens_to_string(e){const t=e.join(""),n=new Uint8Array([...t].map((e=>this.byte_decoder[e])));return this.text_decoder.decode(n)}decode_chain(e){const t=[];let n=[];for(const r of e)void 0!==this.added_tokens.find((e=>e.content===r))?(n.length>0&&(t.push(this.convert_tokens_to_string(n)),n=[]),t.push(r)):n.push(r);return n.length>0&&t.push(this.convert_tokens_to_string(n)),t}}class te extends X{constructor(e){super(e),this.pad_token=this.config.pad_token,this.word_delimiter_token=this.config.word_delimiter_token,this.cleanup=this.config.cleanup}convert_tokens_to_string(e){if(0===e.length)return"";const t=[e[0]];for(let n=1;n<e.length;++n)e[n]!==t.at(-1)&&t.push(e[n]);let n=t.filter((e=>e!==this.pad_token)).join("");return this.cleanup&&(n=f(n).replaceAll(this.word_delimiter_token," ").trim()),n}decode_chain(e){return[this.convert_tokens_to_string(e)]}}class ne extends X{constructor(e){super(e),this.decoders=e.decoders.map((e=>X.fromConfig(e)))}decode_chain(e){return this.decoders.reduce(((e,t)=>t.decode_chain(e)),e)}}class re extends X{constructor(e){super(e),this.suffix=this.config.suffix}decode_chain(e){return e.map(((t,n)=>t.replaceAll(this.suffix,n===e.length-1?"":" ")))}}class ie extends X{decode_chain(e){let t="";for(let n=1;n<e.length;n+=2)t+=e[n];return[t]}}class se extends L{constructor(e){super(),this.addPrefixSpace=e.add_prefix_space,this.replacement=e.replacement,this.strRep=e.str_rep||this.replacement,this.prepend_scheme=e.prepend_scheme??"always"}pre_tokenize_text(e,{section_index:t}={}){let n=e.replaceAll(" ",this.strRep);return this.addPrefixSpace&&!n.startsWith(this.replacement)&&("always"===this.prepend_scheme||"first"===this.prepend_scheme&&0===t)&&(n=this.strRep+n),[n]}}class oe extends X{constructor(e){super(e),this.addPrefixSpace=e.add_prefix_space,this.replacement=e.replacement}decode_chain(e){const t=[];for(let n=0;n<e.length;++n){let r=e[n].replaceAll(this.replacement," ");this.addPrefixSpace&&0==n&&r.startsWith(" ")&&(r=r.substring(1)),t.push(r)}return t}}class ae extends ${constructor(e){super(e),this.charsmap=e.precompiled_charsmap}normalize(e){if((e=(e=e.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm,"")).replace(/[\u0009\u000A\u000C\u000D\u1680\u200B\u200C\u200E\u200F\u2028\u2029\u2581\uFEFF\uFFFD]/gm," ")).includes("～")){const t=e.split("～");e=t.map((e=>e.normalize("NFKC"))).join("～")}else e=e.normalize("NFKC");return e}}class le extends L{constructor(e){super(),this.tokenizers=e.pretokenizers.map((e=>L.fromConfig(e)))}pre_tokenize_text(e,t){return this.tokenizers.reduce(((e,n)=>n.pre_tokenize(e,t)),[e])}}class de extends L{constructor(e){super()}pre_tokenize_text(e,t){return e.match(/\w+|[^\w\s]+/g)||[]}}class ue extends L{constructor(e){super()}pre_tokenize_text(e,t){return function(e){return e.match(/\S+/g)||[]}(e)}}class ce extends L{constructor(e){super(),this.config=e,this.pattern=c(this.config.pattern),this.content=this.config.content}pre_tokenize_text(e,t){return null===this.pattern?[e]:[e.replaceAll(this.pattern,this.config.content)]}}const pe=["bos_token","eos_token","unk_token","sep_token","pad_token","cls_token","mask_token"];function he(e,t,n,r){for(const s of Object.keys(e)){const o=t-e[s].length,a=n(s),l=new Array(o).fill(a);e[s]="right"===r?(0,i.mergeArrays)(e[s],l):(0,i.mergeArrays)(l,e[s])}}function fe(e,t){for(const n of Object.keys(e))e[n].length=t}class me extends r.Callable{return_token_type_ids=!1;_default_chat_template="{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}";padding_side="right";constructor(e,t){super(),this._tokenizer_config=t,this.normalizer=$.fromConfig(e.normalizer),this.pre_tokenizer=L.fromConfig(e.pre_tokenizer),this.model=y.fromConfig(e.model,t),this.post_processor=U.fromConfig(e.post_processor),this.decoder=X.fromConfig(e.decoder),this.special_tokens=[],this.all_special_ids=[],this.added_tokens=[];for(const t of e.added_tokens){const e=new w(t);this.added_tokens.push(e),this.model.tokens_to_ids.set(e.content,e.id),this.model.vocab[e.id]=e.content,e.special&&(this.special_tokens.push(e.content),this.all_special_ids.push(e.id))}if(this.additional_special_tokens=t.additional_special_tokens??[],this.special_tokens.push(...this.additional_special_tokens),this.special_tokens=[...new Set(this.special_tokens)],this.decoder&&(this.decoder.added_tokens=this.added_tokens,this.decoder.end_of_word_suffix=this.model.end_of_word_suffix),this.added_tokens_regex=this.added_tokens.length>0?new RegExp(this.added_tokens.map((e=>`${e.lstrip?"\\s*":""}(${(0,i.escapeRegExp)(e.content)})${e.rstrip?"\\s*":""}`)).join("|")):null,this.mask_token=this.getToken("mask_token"),this.mask_token_id=this.model.tokens_to_ids.get(this.mask_token),this.pad_token=this.getToken("pad_token","eos_token"),this.pad_token_id=this.model.tokens_to_ids.get(this.pad_token),this.sep_token=this.getToken("sep_token"),this.sep_token_id=this.model.tokens_to_ids.get(this.sep_token),this.unk_token=this.getToken("unk_token"),this.unk_token_id=this.model.tokens_to_ids.get(this.unk_token),this.model_max_length=t.model_max_length,this.remove_space=t.remove_space,this.clean_up_tokenization_spaces=t.clean_up_tokenization_spaces??!0,this.do_lowercase_and_remove_accent=t.do_lowercase_and_remove_accent??!1,t.padding_side&&(this.padding_side=t.padding_side),this.legacy=!1,this.chat_template=t.chat_template??null,Array.isArray(this.chat_template)){const e=Object.create(null);for(const{name:t,template:n}of this.chat_template){if("string"!=typeof t||"string"!=typeof n)throw new Error('Chat template must be a list of objects with "name" and "template" properties');e[t]=n}this.chat_template=e}this._compiled_template_cache=new Map}getToken(...e){for(const t of e){const e=this._tokenizer_config[t];if(e){if("object"==typeof e){if("AddedToken"===e.__type)return e.content;throw Error(`Unknown token: ${e}`)}return e}}return null}static async from_pretrained(e,{progress_callback:t=null,config:n=null,cache_dir:r=null,local_files_only:i=!1,revision:s="main",legacy:o=null}={}){return new this(...await u(e,{progress_callback:t,config:n,cache_dir:r,local_files_only:i,revision:s,legacy:o}))}_call(e,{text_pair:t=null,add_special_tokens:n=!0,padding:r=!1,truncation:i=null,max_length:s=null,return_tensor:l=!0}={}){const d=Array.isArray(e);let u;if(d){if(0===e.length)throw Error("text array must be non-empty");if(null!==t){if(!Array.isArray(t))throw Error("text_pair must also be an array");if(e.length!==t.length)throw Error("text and text_pair must have the same length");u=e.map(((e,r)=>this._encode_plus(e,{text_pair:t[r],add_special_tokens:n})))}else u=e.map((e=>this._encode_plus(e,{add_special_tokens:n})))}else{if(null==e)throw Error("text may not be null or undefined");if(Array.isArray(t))throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).");u=[this._encode_plus(e,{text_pair:t,add_special_tokens:n})]}if(null===s?s="max_length"===r?this.model_max_length:(0,o.max)(u.map((e=>e.input_ids.length)))[0]:i||console.warn("Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=true` to explicitly truncate examples to max length."),s=Math.min(s,this.model_max_length),r||i)for(let e=0;e<u.length;++e)u[e].input_ids.length!==s&&(u[e].input_ids.length>s?i&&fe(u[e],s):r&&he(u[e],s,(e=>"input_ids"===e?this.pad_token_id:0),this.padding_side));const c={};if(l){if((!r||!i)&&u.some((e=>{for(const t of Object.keys(e))if(e[t].length!==u[0][t]?.length)return!0;return!1})))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length.");const e=[u.length,u[0].input_ids.length];for(const t of Object.keys(u[0]))c[t]=new a.Tensor("int64",BigInt64Array.from(u.flatMap((e=>e[t])).map(BigInt)),e)}else{for(const e of Object.keys(u[0]))c[e]=u.map((t=>t[e]));if(!d)for(const e of Object.keys(c))c[e]=c[e][0]}return c}_encode_text(e){if(null===e)return null;const t=(this.added_tokens_regex?e.split(this.added_tokens_regex).filter((e=>e)):[e]).map(((e,t)=>{if(void 0!==this.added_tokens.find((t=>t.content===e)))return e;{if(!0===this.remove_space&&(e=e.trim().split(/\s+/).join(" ")),this.do_lowercase_and_remove_accent&&(e=function(e){return m(e.toLowerCase())}(e)),null!==this.normalizer&&(e=this.normalizer(e)),0===e.length)return[];const n=null!==this.pre_tokenizer?this.pre_tokenizer(e,{section_index:t}):[e];return this.model(n)}})).flat();return t}_encode_plus(e,{text_pair:t=null,add_special_tokens:n=!0}={}){const{tokens:r,token_type_ids:i}=this._tokenize_helper(e,{pair:t,add_special_tokens:n}),s=this.model.convert_tokens_to_ids(r),o={input_ids:s,attention_mask:new Array(s.length).fill(1)};return this.return_token_type_ids&&i&&(o.token_type_ids=i),o}_tokenize_helper(e,{pair:t=null,add_special_tokens:n=!1}={}){const r=this._encode_text(e),s=this._encode_text(t);return this.post_processor?this.post_processor(r,s,{add_special_tokens:n}):{tokens:(0,i.mergeArrays)(r??[],s??[])}}tokenize(e,{pair:t=null,add_special_tokens:n=!1}={}){return this._tokenize_helper(e,{pair:t,add_special_tokens:n}).tokens}encode(e,{text_pair:t=null,add_special_tokens:n=!0}={}){return this._encode_plus(e,{text_pair:t,add_special_tokens:n}).input_ids}batch_decode(e,t={}){return e instanceof a.Tensor&&(e=e.tolist()),e.map((e=>this.decode(e,t)))}decode(e,t={}){if(e instanceof a.Tensor&&(e=h(e)),!Array.isArray(e)||0===e.length||!(0,i.isIntegralNumber)(e[0]))throw Error("token_ids must be a non-empty array of integers.");return this.decode_single(e,t)}decode_single(e,{skip_special_tokens:t=!1,clean_up_tokenization_spaces:n=null}){let r=this.model.convert_ids_to_tokens(e);t&&(r=r.filter((e=>!this.special_tokens.includes(e))));let i=this.decoder?this.decoder(r):r.join(" ");return this.decoder&&this.decoder.end_of_word_suffix&&(i=i.replaceAll(this.decoder.end_of_word_suffix," "),t&&(i=i.trim())),(n??this.clean_up_tokenization_spaces)&&(i=f(i)),i}get default_chat_template(){return this._warned_about_chat_template||(console.warn("No chat template is defined for this tokenizer - using a default chat template that implements the ChatML format. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information."),this._warned_about_chat_template=!0),this._default_chat_template}apply_chat_template(e,{chat_template:t=null,add_generation_prompt:n=!1,tokenize:r=!0,padding:i=!1,truncation:s=!1,max_length:o=null,return_tensor:a=!0,tokenizer_kwargs:l={},...u}={}){if(this.chat_template&&"object"==typeof this.chat_template||null===this.chat_template&&this.default_chat_template&&"object"==typeof this.default_chat_template){const e=this.chat_template??this.default_chat_template;if(null!==t&&Object.hasOwn(e,t))t=e[t];else if(null===t&&"default"in e)t=e.default;else if(null===t)throw Error(`This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the 'chat_template' argument. Available template names are ${Object.keys(e).sort()}.`)}else t??=this.chat_template??this.default_chat_template;if("string"!=typeof t)throw Error("chat_template must be a string, but got "+typeof t);let c=this._compiled_template_cache.get(t);void 0===c&&(c=new d.Template(t),this._compiled_template_cache.set(t,c));const p=Object.create(null);for(const e of pe){const t=this.getToken(e);t&&(p[e]=t)}const h=c.render({messages:e,add_generation_prompt:n,...p,...u});return r?this._call(h,{add_special_tokens:!1,padding:i,truncation:s,max_length:o,return_tensor:a,...l}).input_ids:h}}class ge extends me{return_token_type_ids=!0}class _e extends me{return_token_type_ids=!0}class we extends me{return_token_type_ids=!0}class ye extends me{return_token_type_ids=!0}class be extends me{return_token_type_ids=!0}class ve extends me{return_token_type_ids=!0}class xe extends me{return_token_type_ids=!0}class Me extends me{return_token_type_ids=!0}class Te extends me{return_token_type_ids=!0}class ke extends me{}class $e extends me{}class Se extends me{return_token_type_ids=!0;constructor(e,t){super(e,t),console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}}class Ce extends me{return_token_type_ids=!0}class Pe extends me{}class Ee extends me{_default_chat_template='{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}'}class Ae extends me{}class Fe extends me{constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{2}_[A-Z]{2}$/,this.language_codes=this.special_tokens.filter((e=>this.languageRegex.test(e))),this.lang_to_token=e=>e}_build_translation_inputs(e,t,n){return He(this,e,t,n)}}class Ie extends Fe{}class ze extends me{}class Be extends Ee{constructor(e,t){const n=".,!?…。，、।۔،",r=e.pre_tokenizer?.pretokenizers[0]?.pattern;r&&r.Regex===` ?[^(\\s|[${n}])]+`&&(r.Regex=` ?[^\\s${n}]+`),super(e,t)}}const Oe="▁";class Le extends me{_default_chat_template="{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif USE_DEFAULT_PROMPT == true and not '<<SYS>>' in messages[0]['content'] %}{% set loop_messages = messages %}{% set system_message = 'DEFAULT_SYSTEM_MESSAGE' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\n' + content.strip() + '\n<</SYS>>\n\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}";DEFAULT_SYSTEM_PROMPT="You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.";padding_side="left";constructor(e,t){super(e,t),this.use_default_system_prompt=t.use_default_system_prompt??!1,this.legacy=t.legacy??!0,this.legacy||(this.normalizer=null,this.pre_tokenizer=new se({replacement:Oe,add_prefix_space:!0,prepend_scheme:"first"}))}_encode_text(e){if(null===e)return null;if(this.legacy||0===e.length)return super._encode_text(e);let t=super._encode_text(Oe+e.replaceAll(Oe," "));return t.length>1&&t[0]===Oe&&this.special_tokens.includes(t[1])&&(t=t.slice(1)),t}get default_chat_template(){return super.default_chat_template.replaceAll("USE_DEFAULT_PROMPT",this.use_default_system_prompt?"true":"false").replaceAll("DEFAULT_SYSTEM_MESSAGE",this.DEFAULT_SYSTEM_PROMPT.replaceAll("\n","\\n").replaceAll("'","\\'"))}}class De extends Le{}class Re extends me{}class Ne extends me{}class Ve extends me{}class je extends me{}class Ue extends me{}class Ge extends me{}class qe extends me{_default_chat_template="{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"}class We extends me{}function He(e,t,n,r){if(!("language_codes"in e)||!Array.isArray(e.language_codes))throw new Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids.");if(!("languageRegex"in e&&e.languageRegex instanceof RegExp))throw new Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression.");if(!("lang_to_token"in e)||"function"!=typeof e.lang_to_token)throw new Error("Tokenizer must have `lang_to_token` attribute set and it should be a function.");const i=r.src_lang,s=r.tgt_lang;if(!e.language_codes.includes(s))throw new Error(`Target language code "${s}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`);if(void 0!==i){if(!e.language_codes.includes(i))throw new Error(`Source language code "${i}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`);for(const t of e.post_processor.config.single)if("SpecialToken"in t&&e.languageRegex.test(t.SpecialToken.id)){t.SpecialToken.id=e.lang_to_token(i);break}}return r.forced_bos_token_id=e.model.convert_tokens_to_ids([e.lang_to_token(s)])[0],e._call(t,n)}class Xe extends me{constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{3}_[A-Z][a-z]{3}$/,this.language_codes=this.special_tokens.filter((e=>this.languageRegex.test(e))),this.lang_to_token=e=>e}_build_translation_inputs(e,t,n){return He(this,e,t,n)}}class Qe extends me{constructor(e,t){super(e,t),this.languageRegex=/^__[a-z]{2,3}__$/,this.language_codes=this.special_tokens.filter((e=>this.languageRegex.test(e))).map((e=>e.slice(2,-2))),this.lang_to_token=e=>`__${e}__`}_build_translation_inputs(e,t,n){return He(this,e,t,n)}}const Ke=[["en","english"],["zh","chinese"],["de","german"],["es","spanish"],["ru","russian"],["ko","korean"],["fr","french"],["ja","japanese"],["pt","portuguese"],["tr","turkish"],["pl","polish"],["ca","catalan"],["nl","dutch"],["ar","arabic"],["sv","swedish"],["it","italian"],["id","indonesian"],["hi","hindi"],["fi","finnish"],["vi","vietnamese"],["he","hebrew"],["uk","ukrainian"],["el","greek"],["ms","malay"],["cs","czech"],["ro","romanian"],["da","danish"],["hu","hungarian"],["ta","tamil"],["no","norwegian"],["th","thai"],["ur","urdu"],["hr","croatian"],["bg","bulgarian"],["lt","lithuanian"],["la","latin"],["mi","maori"],["ml","malayalam"],["cy","welsh"],["sk","slovak"],["te","telugu"],["fa","persian"],["lv","latvian"],["bn","bengali"],["sr","serbian"],["az","azerbaijani"],["sl","slovenian"],["kn","kannada"],["et","estonian"],["mk","macedonian"],["br","breton"],["eu","basque"],["is","icelandic"],["hy","armenian"],["ne","nepali"],["mn","mongolian"],["bs","bosnian"],["kk","kazakh"],["sq","albanian"],["sw","swahili"],["gl","galician"],["mr","marathi"],["pa","punjabi"],["si","sinhala"],["km","khmer"],["sn","shona"],["yo","yoruba"],["so","somali"],["af","afrikaans"],["oc","occitan"],["ka","georgian"],["be","belarusian"],["tg","tajik"],["sd","sindhi"],["gu","gujarati"],["am","amharic"],["yi","yiddish"],["lo","lao"],["uz","uzbek"],["fo","faroese"],["ht","haitian creole"],["ps","pashto"],["tk","turkmen"],["nn","nynorsk"],["mt","maltese"],["sa","sanskrit"],["lb","luxembourgish"],["my","myanmar"],["bo","tibetan"],["tl","tagalog"],["mg","malagasy"],["as","assamese"],["tt","tatar"],["haw","hawaiian"],["ln","lingala"],["ha","hausa"],["ba","bashkir"],["jw","javanese"],["su","sundanese"]],Ye=new Map(Ke),Ze=new Map([...Ke.map((([e,t])=>[t,e])),["burmese","my"],["valencian","ca"],["flemish","nl"],["haitian","ht"],["letzeburgesch","lb"],["pushto","ps"],["panjabi","pa"],["moldavian","ro"],["moldovan","ro"],["sinhalese","si"],["castilian","es"]]);class Je extends me{_default_chat_template='{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}';_decode_asr(e,{return_timestamps:t=!1,return_language:n=!1,time_precision:r=null,force_full_sequences:i=!0}={}){if(null===r)throw Error("Must specify time_precision");let s=null;const a="word"===t;function l(){return{language:s,timestamp:[null,null],text:""}}const d=[];let u=l(),c=0;const p=this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0]+1;let h=[],f=[],m=!1,g=null;const _=new Set(this.all_special_ids);for(const n of e){const e=n.tokens,i=a?n.token_timestamps:null;let w=null,y=p;if("stride"in n){const[t,i,s]=n.stride;if(c-=i,g=t-s,i&&(y=i/r+p),s)for(let t=e.length-1;t>=0;--t){const n=e[t];if(n>=p){if(null!==w&&(n-p)*r<g)break;w=n}}}let b=[],v=[];for(let n=0;n<e.length;++n){const g=e[n];if(_.has(g)){const e=this.decode([g]),n=Ye.get(e.slice(2,-2));if(void 0!==n){if(null!==s&&n!==s&&!t){h.push(b);const e=this.findLongestCommonSequence(h)[0],t=this.decode(e);u.text=t,d.push(u),h=[],b=[],u=l()}s=u.language=n}}else if(g>=p){const e=(g-p)*r+c,t=(0,o.round)(e,2);if(null!==w&&g>=w)m=!0;else if(m||h.length>0&&g<y)m=!1;else if(null===u.timestamp[0])u.timestamp[0]=t;else if(t===u.timestamp[0]);else{u.timestamp[1]=t,h.push(b),a&&f.push(v);const[e,n]=this.findLongestCommonSequence(h,f),r=this.decode(e);u.text=r,a&&(u.words=this.collateWordTimestamps(e,n,s)),d.push(u),h=[],b=[],f=[],v=[],u=l()}}else if(b.push(g),a){let e,t=(0,o.round)(i[n]+c,2);e=n+1<i.length?(0,o.round)(i[n+1]+c,2):null,v.push([t,e])}}if("stride"in n){const[e,t,r]=n.stride;c+=e-r}b.length>0?(h.push(b),a&&f.push(v)):h.every((e=>0===e.length))&&(u=l(),h=[],b=[],f=[],v=[])}if(h.length>0){if(i&&t)throw new Error("Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.");const[e,n]=this.findLongestCommonSequence(h,f),r=this.decode(e);u.text=r,a&&(u.words=this.collateWordTimestamps(e,n,s)),d.push(u)}let w=Object.create(null);const y=d.map((e=>e.text)).join("");if(t||n){for(let e=0;e<d.length;++e){const r=d[e];t||delete r.timestamp,n||delete r.language}if(a){const e=[];for(const t of d)for(const n of t.words)e.push(n);w={chunks:e}}else w={chunks:d}}return[y,w]}findLongestCommonSequence(e,t=null){let n=e[0],r=n.length,i=[];const s=Array.isArray(t)&&t.length>0;let o=s?[]:null,a=s?t[0]:null;for(let l=1;l<e.length;++l){const d=e[l];let u=0,c=[r,r,0,0];const p=d.length;for(let e=1;e<r+p;++e){const t=e/1e4,i=Math.max(0,r-e),s=Math.min(r,r+p-e),o=n.slice(i,s),a=Math.max(0,e-r),l=Math.min(p,e),h=d.slice(a,l);if(o.length!==h.length)throw new Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.");const f=o.filter(((e,t)=>e===h[t])).length,m=f/e+t;f>1&&m>u&&(u=m,c=[i,s,a,l])}const[h,f,m,g]=c,_=Math.floor((f+h)/2),w=Math.floor((g+m)/2);i.push(...n.slice(0,_)),n=d.slice(w),r=n.length,s&&(o.push(...a.slice(0,_)),a=t[l].slice(w))}return i.push(...n),s?(o.push(...a),[i,o]):[i,[]]}collateWordTimestamps(e,t,n){const[r,i,s]=this.combineTokensIntoWords(e,n),o=[];for(let e=0;e<r.length;++e){const n=s[e];o.push({text:r[e],timestamp:[t[n.at(0)][0],t[n.at(-1)][1]]})}return o}combineTokensIntoWords(e,t,n="\"'“¡¿([{-",r="\"'.。,，!！?？:：”)]}、"){let i,s,o;return["chinese","japanese","thai","lao","myanmar"].includes(t=t??"english")?[i,s,o]=this.splitTokensOnUnicode(e):[i,s,o]=this.splitTokensOnSpaces(e),this.mergePunctuations(i,s,o,n,r)}decode(e,t){let n;return t&&t.decode_with_timestamps?(e instanceof a.Tensor&&(e=h(e)),n=this.decodeWithTimestamps(e,t)):n=super.decode(e,t),n}decodeWithTimestamps(e,t){const n=t?.time_precision??.02,r=Array.from(this.all_special_ids).at(-1)+1;let i=[[]];for(const t of e)if(t>=r){const e=(0,o.round)((t-r)*n,2);i.push(`<|${e}|>`),i.push([])}else i[i.length-1].push(t);return i=i.map((e=>"string"==typeof e?e:super.decode(e,t))),i.join("")}splitTokensOnUnicode(e){const t=this.decode(e,{decode_with_timestamps:!0}),n=[],r=[],i=[];let s=[],o=[],a=0;for(let l=0;l<e.length;++l){const d=e[l];s.push(d),o.push(l);const u=this.decode(s,{decode_with_timestamps:!0});u.includes("�")&&"�"!==t[a+u.indexOf("�")]||(n.push(u),r.push(s),i.push(o),s=[],o=[],a+=u.length)}return[n,r,i]}splitTokensOnSpaces(e){const[t,n,r]=this.splitTokensOnUnicode(e),i=[],s=[],o=[],a=new RegExp(`^[${g}]$`,"gu");for(let e=0;e<t.length;++e){const l=t[e],d=n[e],u=r[e],c=d[0]>=this.model.tokens_to_ids.get("<|endoftext|>"),p=l.startsWith(" "),h=l.trim(),f=a.test(h);if(c||p||f||0===i.length)i.push(l),s.push(d),o.push(u);else{const e=i.length-1;i[e]+=l,s[e].push(...d),o[e].push(...u)}}return[i,s,o]}mergePunctuations(e,t,n,r,s){const o=structuredClone(e),a=structuredClone(t),l=structuredClone(n);let d=o.length-2,u=o.length-1;for(;d>=0;)o[d].startsWith(" ")&&r.includes(o[d].trim())?(o[u]=o[d]+o[u],a[u]=(0,i.mergeArrays)(a[d],a[u]),l[u]=(0,i.mergeArrays)(l[d],l[u]),o[d]="",a[d]=[],l[d]=[]):u=d,--d;for(d=0,u=1;u<o.length;)!o[d].endsWith(" ")&&s.includes(o[u])?(o[d]+=o[u],a[d]=(0,i.mergeArrays)(a[d],a[u]),l[d]=(0,i.mergeArrays)(l[d],l[u]),o[u]="",a[u]=[],l[u]=[]):d=u,++u;return[o.filter((e=>e)),a.filter((e=>e.length>0)),l.filter((e=>e.length>0))]}get_decoder_prompt_ids({language:e=null,task:t=null,no_timestamps:n=!0}={}){const r=[];if(e){e=e.toLowerCase();let t=Ze.get(e);if(void 0===t){if(!Ye.has(e)){const t=2===e.length?Ye.keys():Ye.values();throw new Error(`Language "${e}" is not supported. Must be one of: ${JSON.stringify(t)}`)}t=e}const n=this.model.tokens_to_ids.get(`<|${t}|>`);if(void 0===n)throw new Error(`Unable to find language "${t}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`);r.push(n)}else r.push(null);if(t){if("transcribe"!==(t=t.toLowerCase())&&"translate"!==t)throw new Error(`Task "${t}" is not supported. Must be one of: ["transcribe", "translate"]`);const e=this.model.tokens_to_ids.get(`<|${t}|>`);if(void 0===e)throw new Error(`Unable to find task "${t}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`);r.push(e)}else r.push(null);if(n){const e=this.model.tokens_to_ids.get("<|notimestamps|>");if(void 0===e)throw new Error('Unable to find "<|notimestamps|>" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.');r.push(e)}return r.map(((e,t)=>[t+1,e])).filter((e=>null!==e[1]))}}class et extends me{}class tt extends me{}class nt extends me{}class rt extends me{constructor(e,t){super(e,t),this.languageRegex=/^(>>\w+<<)\s*/g,this.supported_language_codes=this.model.vocab.filter((e=>this.languageRegex.test(e))),console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}_encode_text(e){if(null===e)return null;const[t,...n]=e.trim().split(this.languageRegex);if(0===n.length)return super._encode_text(t);if(2===n.length){const[e,t]=n;return this.supported_language_codes.includes(e)||console.warn(`Unsupported language code "${e}" detected, which may lead to unexpected behavior. Should be one of: ${JSON.stringify(this.supported_language_codes)}`),(0,i.mergeArrays)([e],super._encode_text(t))}}}class it extends me{}class st extends me{_default_chat_template="{% for message in messages %}{% if message['role'] == 'user' %}{{ ' ' }}{% endif %}{{ message['content'] }}{% if not loop.last %}{{ '  ' }}{% endif %}{% endfor %}{{ eos_token }}"}class ot extends st{}class at extends me{}class lt extends me{}class dt extends me{constructor(e,t){super(e,t),this.decoder=new ie({})}}class ut extends me{}class ct{static TOKENIZER_CLASS_MAPPING={T5Tokenizer:Pe,DistilBertTokenizer:ke,CamembertTokenizer:$e,DebertaTokenizer:be,DebertaV2Tokenizer:ve,BertTokenizer:ge,HerbertTokenizer:xe,ConvBertTokenizer:Me,RoFormerTokenizer:Te,XLMTokenizer:Se,ElectraTokenizer:Ce,MobileBertTokenizer:we,SqueezeBertTokenizer:ye,AlbertTokenizer:_e,GPT2Tokenizer:Ee,BartTokenizer:Ae,MBartTokenizer:Fe,MBart50Tokenizer:Ie,RobertaTokenizer:ze,WhisperTokenizer:Je,CodeGenTokenizer:et,CLIPTokenizer:tt,SiglipTokenizer:nt,MarianTokenizer:rt,BloomTokenizer:Be,NllbTokenizer:Xe,M2M100Tokenizer:Qe,LlamaTokenizer:Le,CodeLlamaTokenizer:De,XLMRobertaTokenizer:Re,MPNetTokenizer:Ne,FalconTokenizer:Ve,GPTNeoXTokenizer:je,EsmTokenizer:Ue,Wav2Vec2CTCTokenizer:it,BlenderbotTokenizer:st,BlenderbotSmallTokenizer:ot,SpeechT5Tokenizer:at,NougatTokenizer:lt,VitsTokenizer:dt,Qwen2Tokenizer:Ge,GemmaTokenizer:qe,Grok1Tokenizer:We,CohereTokenizer:ut,PreTrainedTokenizer:me};static async from_pretrained(e,{progress_callback:t=null,config:n=null,cache_dir:r=null,local_files_only:i=!1,revision:s="main",legacy:o=null}={}){const[a,l]=await u(e,{progress_callback:t,config:n,cache_dir:r,local_files_only:i,revision:s,legacy:o}),d=l.tokenizer_class?.replace(/Fast$/,"")??"PreTrainedTokenizer";let c=this.TOKENIZER_CLASS_MAPPING[d];return c||(console.warn(`Unknown tokenizer class "${d}", attempting to construct from base class.`),c=me),new c(a,l)}}},"./src/utils/audio.js":
/*!****************************!*\
  !*** ./src/utils/audio.js ***!
  \****************************/(e,t,n)=>{n.r(t),n.d(t,{hanning:()=>a,mel_filter_bank:()=>p,read_audio:()=>o,spectrogram:()=>f,window_function:()=>m});var r=n(/*! ./hub.js */"./src/utils/hub.js"),i=n(/*! ./maths.js */"./src/utils/maths.js"),s=n(/*! ./core.js */"./src/utils/core.js");async function o(e,t){if("undefined"==typeof AudioContext)throw Error("Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing.");const n=await(await(0,r.getFile)(e)).arrayBuffer(),i=new AudioContext({sampleRate:t});void 0===t&&console.warn(`No sampling rate provided, using default of ${i.sampleRate}Hz.`);const s=await i.decodeAudioData(n);let o;if(2===s.numberOfChannels){const e=Math.sqrt(2),t=s.getChannelData(0),n=s.getChannelData(1);o=new Float32Array(t.length);for(let r=0;r<s.length;++r)o[r]=e*(t[r]+n[r])/2}else o=s.getChannelData(0);return o}function a(e){if(e<1)return new Float64Array;if(1===e)return new Float64Array([1]);const t=e-1,n=Math.PI/t,r=new Float64Array(e);for(let i=0;i<e;++i){const e=2*i-t;r[i]=.5+.5*Math.cos(n*e)}return r}const l={htk:e=>2595*Math.log10(1+e/700),kaldi:e=>1127*Math.log(1+e/700),slaney:(e,t=1e3,n=15,r=27/Math.log(6.4))=>e>=t?n+Math.log(e/t)*r:3*e/200};function d(e,t="htk"){const n=l[t];if(!n)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return"number"==typeof e?n(e):e.map((e=>n(e)))}const u={htk:e=>700*(10**(e/2595)-1),kaldi:e=>700*(Math.exp(e/1127)-1),slaney:(e,t=1e3,n=15,r=Math.log(6.4)/27)=>e>=n?t*Math.exp(r*(e-n)):200*e/3};function c(e,t,n){const r=(t-e)/(n-1);return Float64Array.from({length:n},((t,n)=>e+r*n))}function p(e,t,n,r,i,s=null,o="htk",a=!1){if(null!==s&&"slaney"!==s)throw new Error('norm must be one of null or "slaney"');const l=c(d(n,o),d(r,o),t+2);let p,h=function(e,t="htk"){const n=u[t];if(!n)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return"number"==typeof e?n(e):e.map((e=>n(e)))}(l,o);if(a){const t=i/(2*e);p=d(Float64Array.from({length:e},((e,n)=>n*t)),o),h=l}else p=c(0,Math.floor(i/2),e);const f=function(e,t){const n=Float64Array.from({length:t.length-1},((e,n)=>t[n+1]-t[n])),r=Array.from({length:e.length},(()=>new Array(t.length)));for(let n=0;n<e.length;++n){const i=r[n];for(let r=0;r<t.length;++r)i[r]=t[r]-e[n]}const i=t.length-2,s=Array.from({length:i},(()=>new Array(e.length)));for(let t=0;t<e.length;++t){const e=r[t];for(let r=0;r<i;++r){const i=-e[r]/n[r],o=e[r+2]/n[r+1];s[r][t]=Math.max(0,Math.min(i,o))}}return s}(p,h);if(null!==s&&"slaney"===s)for(let n=0;n<t;++n){const t=f[n],r=2/(h[n+2]-h[n]);for(let n=0;n<e;++n)t[n]*=r}return f}function h(e,t,n,r,s){if(n<=0)throw new Error("reference must be greater than zero");if(r<=0)throw new Error("min_value must be greater than zero");n=Math.max(r,n);const o=Math.log10(n);for(let n=0;n<e.length;++n)e[n]=t*Math.log10(Math.max(r,e[n])-o);if(null!==s){if(s<=0)throw new Error("db_range must be greater than zero");const t=(0,i.max)(e)[0]-s;for(let n=0;n<e.length;++n)e[n]=Math.max(e[n],t)}return e}function f(e,t,n,r,{fft_length:o=null,power:a=1,center:l=!0,pad_mode:d="reflect",onesided:u=!0,preemphasis:c=null,mel_filters:p=null,mel_floor:f=1e-10,log_mel:m=null,reference:g=1,min_value:_=1e-10,db_range:w=null,remove_dc_offset:y=null,max_num_frames:b=null,do_pad:v=!0,transpose:x=!1}={}){const M=t.length;if(null===o&&(o=n),n>o)throw Error(`frame_length (${n}) may not be larger than fft_length (${o})`);if(M!==n)throw new Error(`Length of the window (${M}) must equal frame_length (${n})`);if(r<=0)throw new Error("hop_length must be greater than zero");if(l){if("reflect"!==d)throw new Error(`pad_mode="${d}" not implemented yet.`);const t=Math.floor((o-1)/2)+1;e=function(e,t,n){const r=new e.constructor(e.length+t+n),i=e.length-1;for(let n=0;n<e.length;++n)r[t+n]=e[n];for(let n=1;n<=t;++n)r[t-n]=e[(0,s.calculateReflectOffset)(n,i)];for(let o=1;o<=n;++o)r[i+t+o]=e[(0,s.calculateReflectOffset)(i-o,i)];return r}(e,t,t)}const T=Math.floor(1+Math.floor((e.length-n)/r)),k=u?Math.floor(o/2)+1:o;let $=T,S=T;null!==b&&(b>T?v&&(S=b):S=$=b);const C=new i.FFT(o),P=new Float64Array(o),E=new Float64Array(C.outputBufferSize),A=new Array($);for(let i=0;i<$;++i){const s=i*r;for(let t=0;t<n;++t)P[t]=e[s+t];if(y){let e=0;for(let t=0;t<n;++t)e+=P[t];const t=e/n;for(let e=0;e<n;++e)P[e]-=t}if(null!==c){for(let e=n-1;e>=1;--e)P[e]-=c*P[e-1];P[0]*=1-c}for(let e=0;e<t.length;++e)P[e]*=t[e];C.realTransform(E,P);const o=new Array(k);for(let e=0;e<o.length;++e){const t=e<<1;o[e]=E[t]**2+E[t+1]**2}A[i]=o}if(null!==a&&2!==a){const e=2/a;for(let t=0;t<A.length;++t){const n=A[t];for(let t=0;t<n.length;++t)n[t]**=e}}const F=p.length,I=new Float32Array(F*S),z=x?[S,F]:[F,S];for(let e=0;e<F;++e){const t=p[e];for(let n=0;n<$;++n){const r=A[n];let i=0;for(let e=0;e<k;++e)i+=t[e]*r[e];I[x?n*F+e:e*$+n]=Math.max(f,i)}}if(null!==a&&null!==m){const e=Math.min(I.length,$*F);switch(m){case"log":for(let t=0;t<e;++t)I[t]=Math.log(I[t]);break;case"log10":for(let t=0;t<e;++t)I[t]=Math.log10(I[t]);break;case"dB":if(1===a)!function(e,t=1,n=1e-5,r=null){h(e,20,t,n,r)}(I,g,_,w);else{if(2!==a)throw new Error(`Cannot use log_mel option '${m}' with power ${a}`);!function(e,t=1,n=1e-10,r=null){h(e,10,t,n,r)}(I,g,_,w)}break;default:throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${m}'`)}}return{data:I,dims:z}}function m(e,t,{periodic:n=!0,frame_length:r=null,center:i=!0}={}){const s=n?e+1:e;let o;switch(t){case"boxcar":o=new Float64Array(s).fill(1);break;case"hann":case"hann_window":o=a(s);break;case"povey":o=a(s).map((e=>Math.pow(e,.85)));break;default:throw new Error(`Unknown window type ${t}.`)}if(n&&(o=o.subarray(0,e)),null===r)return o;if(e>r)throw new Error(`Length of the window (${e}) may not be larger than frame_length (${r})`);return o}},"./src/utils/core.js":
/*!***************************!*\
  !*** ./src/utils/core.js ***!
  \***************************/(e,t,n)=>{function r(e,t){e&&e(t)}function i(e){return Object.fromEntries(Object.entries(e).map((([e,t])=>[t,e])))}function s(e){return e.replace(/[.*+?^${}()|[\]\\]/g,"\\$&")}function o(e){return"TypedArray"===e?.prototype?.__proto__?.constructor?.name}function a(e){return Number.isInteger(e)||"bigint"==typeof e}function l(e){const t=[];let n=e;for(;Array.isArray(n);)t.push(n.length),n=n[0];return t}function d(e,t,n=void 0){const r=e[t];if(void 0!==r)return delete e[t],r;if(void 0===n)throw Error(`Key ${t} does not exist in object.`);return n}function u(...e){return Array.prototype.concat.apply([],e)}function c(...e){return e.reduce(((e,t)=>e.flatMap((e=>t.map((t=>[e,t]))))))}function p(e,t){return Math.abs((e+t)%(2*t)-t)}function h(e,t){return Object.assign({},...t.map((t=>{if(void 0!==e[t])return{[t]:e[t]}})))}n.r(t),n.d(t,{calculateDimensions:()=>l,calculateReflectOffset:()=>p,dispatchCallback:()=>r,escapeRegExp:()=>s,isIntegralNumber:()=>a,isTypedArray:()=>o,mergeArrays:()=>u,pick:()=>h,pop:()=>d,product:()=>c,reverseDictionary:()=>i})},"./src/utils/data-structures.js":
/*!**************************************!*\
  !*** ./src/utils/data-structures.js ***!
  \**************************************/(e,t,n)=>{n.r(t),n.d(t,{CharTrie:()=>i,PriorityQueue:()=>r,TokenLattice:()=>o});class r{constructor(e=((e,t)=>e>t)){this._heap=[],this._comparator=e}get size(){return this._heap.length}isEmpty(){return 0===this.size}peek(){return this._heap[0]}push(...e){return this.extend(e)}extend(e){for(const t of e)this._heap.push(t),this._siftUp();return this.size}pop(){const e=this.peek(),t=this.size-1;return t>0&&this._swap(0,t),this._heap.pop(),this._siftDown(),e}replace(e){const t=this.peek();return this._heap[0]=e,this._siftDown(),t}_parent(e){return(e+1>>>1)-1}_left(e){return 1+(e<<1)}_right(e){return e+1<<1}_greater(e,t){return this._comparator(this._heap[e],this._heap[t])}_swap(e,t){const n=this._heap[e];this._heap[e]=this._heap[t],this._heap[t]=n}_siftUp(){let e=this.size-1;for(;e>0&&this._greater(e,this._parent(e));)this._swap(e,this._parent(e)),e=this._parent(e)}_siftDown(){let e=0;for(;this._left(e)<this.size&&this._greater(this._left(e),e)||this._right(e)<this.size&&this._greater(this._right(e),e);){const t=this._right(e)<this.size&&this._greater(this._right(e),this._left(e))?this._right(e):this._left(e);this._swap(e,t),e=t}}}class i{constructor(){this.root=s.default()}extend(e){for(let t of e)this.push(t)}push(e){let t=this.root;for(let n of e){let e=t.children.get(n);void 0===e&&(e=s.default(),t.children.set(n,e)),t=e}t.isLeaf=!0}*commonPrefixSearch(e){let t=this.root,n="";for(let r=0;r<e.length&&void 0!==t;++r){const i=e[r];n+=i,t=t.children.get(i),void 0!==t&&t.isLeaf&&(yield n)}}}class s{constructor(e,t){this.isLeaf=e,this.children=t}static default(){return new s(!1,new Map)}}class o{constructor(e,t,n){this.sentence=e,this.len=e.length,this.bosTokenId=t,this.eosTokenId=n,this.nodes=[],this.beginNodes=Array.from({length:this.len+1},(()=>[])),this.endNodes=Array.from({length:this.len+1},(()=>[]));const r=new a(this.bosTokenId,0,0,0,0),i=new a(this.eosTokenId,1,this.len,0,0);this.nodes.push(r.clone()),this.nodes.push(i.clone()),this.beginNodes[this.len].push(i),this.endNodes[0].push(r)}insert(e,t,n,r){const i=this.nodes.length,s=new a(r,i,e,t,n);this.beginNodes[e].push(s),this.endNodes[e+t].push(s),this.nodes.push(s)}viterbi(){const e=this.len;let t=0;for(;t<=e;){if(0==this.beginNodes[t].length)return[];for(let e of this.beginNodes[t]){e.prev=null;let n=0,r=null;for(let i of this.endNodes[t]){const t=i.backtraceScore+e.score;(null===r||t>n)&&(r=i.clone(),n=t)}if(null===r)return[];e.prev=r,e.backtraceScore=n}++t}const n=[],r=this.beginNodes[e][0].prev;if(null===r)return[];let i=r.clone();for(;null!==i.prev;){n.push(i.clone());const e=i.clone();i=e.prev.clone()}return n.reverse(),n}piece(e){return this.sentence.slice(e.pos,e.pos+e.length)}tokens(){return this.viterbi().map((e=>this.piece(e)))}tokenIds(){return this.viterbi().map((e=>e.tokenId))}}class a{constructor(e,t,n,r,i){this.tokenId=e,this.nodeId=t,this.pos=n,this.length=r,this.score=i,this.prev=null,this.backtraceScore=0}clone(){const e=new a(this.tokenId,this.nodeId,this.pos,this.length,this.score);return e.prev=this.prev,e.backtraceScore=this.backtraceScore,e}}},"./src/utils/devices.js":
/*!******************************!*\
  !*** ./src/utils/devices.js ***!
  \******************************/(e,t,n)=>{n.r(t),n.d(t,{DEVICE_TYPES:()=>r});const r=Object.freeze({cpu:"cpu",gpu:"gpu",wasm:"wasm",webgpu:"webgpu",webnn:"webnn"})},"./src/utils/dtypes.js":
/*!*****************************!*\
  !*** ./src/utils/dtypes.js ***!
  \*****************************/(e,t,n)=>{n.r(t),n.d(t,{DATA_TYPES:()=>o,DEFAULT_DEVICE_DTYPE_MAPPING:()=>a,DEFAULT_DTYPE_SUFFIX_MAPPING:()=>l,isFp16Supported:()=>s});var r=n(/*! ../env.js */"./src/env.js"),i=n(/*! ./devices.js */"./src/utils/devices.js");const s=function(){let e;return async function(){if(void 0===e)if(r.apis.IS_NODE_ENV)e=!0;else if(r.apis.IS_WEBGPU_AVAILABLE)try{const t=await navigator.gpu.requestAdapter();e=t.features.has("shader-f16")}catch(t){e=!1}else e=!1;return e}}(),o=Object.freeze({fp32:"fp32",fp16:"fp16",q8:"q8",int8:"int8",uint8:"uint8"}),a=Object.freeze({[i.DEVICE_TYPES.cpu]:o.q8,[i.DEVICE_TYPES.gpu]:o.fp32,[i.DEVICE_TYPES.wasm]:o.q8,[i.DEVICE_TYPES.webgpu]:o.fp32,[i.DEVICE_TYPES.webnn]:o.fp32}),l=Object.freeze({[o.fp32]:"",[o.fp16]:"_fp16",[o.int8]:"_int8",[o.uint8]:"_uint8",[o.q8]:"_quantized"})},"./src/utils/generic.js":
/*!******************************!*\
  !*** ./src/utils/generic.js ***!
  \******************************/(e,t,n)=>{n.r(t),n.d(t,{Callable:()=>r});const r=class{constructor(){let e=function(...t){return e._call(...t)};return Object.setPrototypeOf(e,new.target.prototype)}_call(...e){throw Error("Must implement _call method in subclass")}}},"./src/utils/hub.js":
/*!**************************!*\
  !*** ./src/utils/hub.js ***!
  \**************************/(e,t,n)=>{n.r(t),n.d(t,{getFile:()=>d,getModelFile:()=>p,getModelJSON:()=>h});var r=n(/*! fs */"?7a2c"),i=n(/*! path */"?a42a"),s=n(/*! ../env.js */"./src/env.js"),o=n(/*! ./core.js */"./src/utils/core.js");class a{_CONTENT_TYPE_MAP={txt:"text/plain",html:"text/html",css:"text/css",js:"text/javascript",json:"application/json",png:"image/png",jpg:"image/jpeg",jpeg:"image/jpeg",gif:"image/gif"};constructor(e){if(this.filePath=e,this.headers=new Headers,this.exists=r.existsSync(e),this.exists){this.status=200,this.statusText="OK";let t=r.statSync(e);this.headers.set("content-length",t.size.toString()),this.updateContentType();let n=this;this.body=new ReadableStream({start(e){n.arrayBuffer().then((t=>{e.enqueue(new Uint8Array(t)),e.close()}))}})}else this.status=404,this.statusText="Not Found",this.body=null}updateContentType(){const e=this.filePath.toString().split(".").pop().toLowerCase();this.headers.set("content-type",this._CONTENT_TYPE_MAP[e]??"application/octet-stream")}clone(){let e=new a(this.filePath);return e.exists=this.exists,e.status=this.status,e.statusText=this.statusText,e.headers=new Headers(this.headers),e}async arrayBuffer(){return(await r.promises.readFile(this.filePath)).buffer}async blob(){const e=await r.promises.readFile(this.filePath);return new Blob([e],{type:this.headers.get("content-type")})}async text(){return await r.promises.readFile(this.filePath,"utf8")}async json(){return JSON.parse(await this.text())}}function l(e,t=null){let n;try{n=new URL(e)}catch(e){return!1}return!(t&&!t.includes(n.hostname))&&("http:"===n.protocol||"https:"===n.protocol)}async function d(e){if(s.env.useFS&&!l(e))return new a(e);if("undefined"!=typeof process&&"node"===process?.release?.name){const t=!!process.env?.TESTING_REMOTELY,n=s.env.version,r=new Headers;r.set("User-Agent",`transformers.js/${n}; is_ci/${t};`);if(l(e,["huggingface.co","hf.co"])){const e=process.env?.HF_TOKEN??process.env?.HF_ACCESS_TOKEN;e&&r.set("Authorization",`Bearer ${e}`)}return fetch(e,{headers:r})}return fetch(e)}const u={400:"Bad request error occurred while trying to load file",401:"Unauthorized access to file",403:"Forbidden access to file",404:"Could not locate file",408:"Request timeout error occurred while trying to load file",500:"Internal server error error occurred while trying to load file",502:"Bad gateway error occurred while trying to load file",503:"Service unavailable error occurred while trying to load file",504:"Gateway timeout error occurred while trying to load file"};class c{constructor(e){this.path=e}async match(e){let t=i.join(this.path,e),n=new a(t);return n.exists?n:void 0}async put(e,t){const n=Buffer.from(await t.arrayBuffer());let s=i.join(this.path,e);try{await r.promises.mkdir(i.dirname(s),{recursive:!0}),await r.promises.writeFile(s,n)}catch(e){console.warn("An error occurred while writing the file to cache:",e)}}}async function p(e,t,n=!0,r={}){if(!s.env.allowLocalModels){if(r.local_files_only)throw Error("Invalid configuration detected: local models are disabled (`env.allowLocalModels=false`) but you have requested to only use local models (`local_files_only=true`).");if(!s.env.allowRemoteModels)throw Error("Invalid configuration detected: both local and remote models are disabled. Fix by setting `env.allowLocalModels` or `env.allowRemoteModels` to `true`.")}let i;if((0,o.dispatchCallback)(r.progress_callback,{status:"initiate",name:e,file:t}),!i&&s.env.useBrowserCache){if("undefined"==typeof caches)throw Error("Browser cache is not available in this environment.");try{i=await caches.open("transformers-cache")}catch(e){console.warn("An error occurred while opening the browser cache:",e)}}if(!i&&s.env.useFSCache&&(i=new c(r.cache_dir??s.env.cacheDir)),!i&&s.env.useCustomCache){if(!s.env.customCache)throw Error("`env.useCustomCache=true`, but `env.customCache` is not defined.");if(!s.env.customCache.match||!s.env.customCache.put)throw new Error("`env.customCache` must be an object which implements the `match` and `put` functions of the Web Cache API. For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache");i=s.env.customCache}const a=r.revision??"main";let p,h,m=f(e,t),g=f(s.env.localModelPath,m),_=f(s.env.remoteHost,s.env.remotePathTemplate.replaceAll("{model}",e).replaceAll("{revision}",encodeURIComponent(a)),t),w="main"===a?m:f(e,a,t),y=i instanceof c?w:_,b=!1;i&&(h=await async function(e,...t){for(let n of t)try{let t=await e.match(n);if(t)return t}catch(e){continue}}(i,g,y));const v=void 0!==h;if(void 0===h){if(s.env.allowLocalModels){if(l(m)){if(r.local_files_only)throw new Error(`\`local_files_only=true\`, but attempted to load a remote file from: ${m}.`);if(!s.env.allowRemoteModels)throw new Error(`\`env.allowRemoteModels=false\`, but attempted to load a remote file from: ${m}.`)}else try{h=await d(g),p=g}catch(e){console.warn(`Unable to load from local path "${g}": "${e}"`)}}if(void 0===h||404===h.status){if(r.local_files_only||!s.env.allowRemoteModels){if(n)throw Error(`\`local_files_only=true\` or \`env.allowRemoteModels=false\` and file was not found locally at "${g}".`);return null}if(h=await d(_),200!==h.status)return function(e,t,n){if(!n)return null;const r=u[e]??`Error (${e}) occurred while trying to load file`;throw Error(`${r}: "${t}".`)}(h.status,_,n);p=y}b=i&&"undefined"!=typeof Response&&h instanceof Response&&200===h.status}(0,o.dispatchCallback)(r.progress_callback,{status:"download",name:e,file:t});const x={status:"progress",name:e,file:t};let M;return r.progress_callback?v&&"undefined"!=typeof navigator&&/firefox/i.test(navigator.userAgent)?(M=new Uint8Array(await h.arrayBuffer()),(0,o.dispatchCallback)(r.progress_callback,{...x,progress:100,loaded:M.length,total:M.length})):M=await async function(e,t){const n=e.headers.get("Content-Length");null===n&&console.warn("Unable to determine content-length from response headers. Will expand buffer when needed.");let r=parseInt(n??"0"),i=new Uint8Array(r),s=0;const o=e.body.getReader();async function a(){const{done:e,value:n}=await o.read();if(e)return;let l=s+n.length;if(l>r){r=l;let e=new Uint8Array(r);e.set(i),i=e}i.set(n,s),s=l;return t({progress:s/r*100,loaded:s,total:r}),a()}return await a(),i}(h,(e=>{(0,o.dispatchCallback)(r.progress_callback,{...x,...e})})):M=new Uint8Array(await h.arrayBuffer()),b&&p&&void 0===await i.match(p)&&await i.put(p,new Response(M,{headers:h.headers})).catch((e=>{console.warn(`Unable to add response to browser cache: ${e}.`)})),(0,o.dispatchCallback)(r.progress_callback,{status:"done",name:e,file:t}),M}async function h(e,t,n=!0,r={}){let i=await p(e,t,n,r);if(null===i)return{};let s=new TextDecoder("utf-8").decode(i);return JSON.parse(s)}function f(...e){return(e=e.map(((t,n)=>(n&&(t=t.replace(new RegExp("^/"),"")),n!==e.length-1&&(t=t.replace(new RegExp("/$"),"")),t)))).join("/")}},"./src/utils/image.js":
/*!****************************!*\
  !*** ./src/utils/image.js ***!
  \****************************/(e,t,n)=>{n.r(t),n.d(t,{RawImage:()=>f});var r=n(/*! ./hub.js */"./src/utils/hub.js"),i=n(/*! ../env.js */"./src/env.js"),s=n(/*! ./tensor.js */"./src/utils/tensor.js"),o=n(/*! sharp */"?2b25");const a="undefined"!=typeof self,l=a&&"DedicatedWorkerGlobalScope"===self.constructor.name;let d,u,c;if(a)d=(e,t)=>{if(!self.OffscreenCanvas)throw new Error("OffscreenCanvas not supported by this browser.");return new self.OffscreenCanvas(e,t)},c=self.createImageBitmap,u=self.ImageData;else{if(!o)throw new Error("Unable to load image processing library.");c=async e=>{const t=(await e.metadata()).channels,{data:n,info:r}=await e.raw().toBuffer({resolveWithObject:!0}),i=new f(new Uint8ClampedArray(n),r.width,r.height,r.channels);return void 0!==t&&t!==r.channels&&i.convert(t),i}}const p={0:"nearest",1:"lanczos",2:"bilinear",3:"bicubic",4:"box",5:"hamming"},h=new Map([["png","image/png"],["jpg","image/jpeg"],["jpeg","image/jpeg"],["gif","image/gif"]]);class f{constructor(e,t,n,r){this.data=e,this.width=t,this.height=n,this.channels=r}get size(){return[this.width,this.height]}static async read(e){if(e instanceof f)return e;if("string"==typeof e||e instanceof URL)return await this.fromURL(e);throw new Error("Unsupported input type: "+typeof e)}static fromCanvas(e){if(!a)throw new Error("fromCanvas() is only supported in browser environments.");const t=e.getContext("2d").getImageData(0,0,e.width,e.height).data;return new f(t,e.width,e.height,4)}static async fromURL(e){const t=await(0,r.getFile)(e);if(200!==t.status)throw new Error(`Unable to read image from "${e}" (${t.status} ${t.statusText})`);const n=await t.blob();return this.fromBlob(n)}static async fromBlob(e){if(a){const t=await c(e),n=d(t.width,t.height).getContext("2d");return n.drawImage(t,0,0),new this(n.getImageData(0,0,t.width,t.height).data,t.width,t.height,4)}{const t=o(await e.arrayBuffer());return await c(t)}}static fromTensor(e,t="CHW"){if(3!==e.dims.length)throw new Error(`Tensor should have 3 dimensions, but has ${e.dims.length} dimensions.`);if("CHW"===t)e=e.transpose(1,2,0);else if("HWC"!==t)throw new Error(`Unsupported channel format: ${t}`);if(!(e.data instanceof Uint8ClampedArray||e.data instanceof Uint8Array))throw new Error(`Unsupported tensor type: ${e.type}`);switch(e.dims[2]){case 1:case 2:case 3:case 4:return new f(e.data,e.dims[1],e.dims[0],e.dims[2]);default:throw new Error(`Unsupported number of channels: ${e.dims[2]}`)}}grayscale(){if(1===this.channels)return this;const e=new Uint8ClampedArray(this.width*this.height*1);switch(this.channels){case 3:case 4:for(let t=0,n=0;t<this.data.length;t+=this.channels){const r=this.data[t],i=this.data[t+1],s=this.data[t+2];e[n++]=Math.round(.2989*r+.587*i+.114*s)}break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,1)}rgb(){if(3===this.channels)return this;const e=new Uint8ClampedArray(this.width*this.height*3);switch(this.channels){case 1:for(let t=0,n=0;t<this.data.length;++t)e[n++]=this.data[t],e[n++]=this.data[t],e[n++]=this.data[t];break;case 4:for(let t=0,n=0;t<this.data.length;t+=4)e[n++]=this.data[t],e[n++]=this.data[t+1],e[n++]=this.data[t+2];break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,3)}rgba(){if(4===this.channels)return this;const e=new Uint8ClampedArray(this.width*this.height*4);switch(this.channels){case 1:for(let t=0,n=0;t<this.data.length;++t)e[n++]=this.data[t],e[n++]=this.data[t],e[n++]=this.data[t],e[n++]=255;break;case 3:for(let t=0,n=0;t<this.data.length;t+=3)e[n++]=this.data[t],e[n++]=this.data[t+1],e[n++]=this.data[t+2],e[n++]=255;break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,4)}async resize(e,t,{resample:n=2}={}){let r=p[n]??n;if(a){const n=this.channels,r=this.toCanvas(),i=d(e,t).getContext("2d");i.drawImage(r,0,0,e,t);return new f(i.getImageData(0,0,e,t).data,e,t,4).convert(n)}{let n=this.toSharp();switch(r){case"box":case"hamming":"box"!==r&&"hamming"!==r||(console.warn(`Resampling method ${r} is not yet supported. Using bilinear instead.`),r="bilinear");case"nearest":case"bilinear":case"bicubic":n=n.affine([e/this.width,0,0,t/this.height],{interpolator:r});break;case"lanczos":n=n.resize({width:e,height:t,fit:"fill",kernel:"lanczos3"});break;default:throw new Error(`Resampling method ${r} is not supported.`)}return await c(n)}}async pad([e,t,n,r]){if(e=Math.max(e,0),t=Math.max(t,0),n=Math.max(n,0),r=Math.max(r,0),0===e&&0===t&&0===n&&0===r)return this;if(a){const i=this.channels,s=this.toCanvas(),o=this.width+e+t,a=this.height+n+r,l=d(o,a).getContext("2d");l.drawImage(s,0,0,this.width,this.height,e,n,o,a);return new f(l.getImageData(0,0,o,a).data,o,a,4).convert(i)}{const i=this.toSharp().extend({left:e,right:t,top:n,bottom:r});return await c(i)}}async crop([e,t,n,r]){if(e=Math.max(e,0),t=Math.max(t,0),n=Math.min(n,this.width-1),r=Math.min(r,this.height-1),0===e&&0===t&&n===this.width-1&&r===this.height-1)return this;const i=n-e+1,s=r-t+1;if(a){const n=this.channels,r=this.toCanvas(),o=d(i,s).getContext("2d");o.drawImage(r,e,t,i,s,0,0,i,s);return new f(o.getImageData(0,0,i,s).data,i,s,4).convert(n)}{const n=this.toSharp().extract({left:e,top:t,width:i,height:s});return await c(n)}}async center_crop(e,t){if(this.width===e&&this.height===t)return this;const n=(this.width-e)/2,r=(this.height-t)/2;if(a){const i=this.channels,s=this.toCanvas(),o=d(e,t).getContext("2d");let a=0,l=0,u=0,c=0;n>=0?a=n:u=-n,r>=0?l=r:c=-r,o.drawImage(s,a,l,e,t,u,c,e,t);return new f(o.getImageData(0,0,e,t).data,e,t,4).convert(i)}{let i=this.toSharp();if(n>=0&&r>=0)i=i.extract({left:Math.floor(n),top:Math.floor(r),width:e,height:t});else if(n<=0&&r<=0){const s=Math.floor(-r),o=Math.floor(-n);i=i.extend({top:s,left:o,right:e-this.width-o,bottom:t-this.height-s})}else{let s=[0,0],o=0;r<0?(s[0]=Math.floor(-r),s[1]=t-this.height-s[0]):o=Math.floor(r);let a=[0,0],l=0;n<0?(a[0]=Math.floor(-n),a[1]=e-this.width-a[0]):l=Math.floor(n),i=i.extend({top:s[0],bottom:s[1],left:a[0],right:a[1]}).extract({left:l,top:o,width:e,height:t})}return await c(i)}}async toBlob(e="image/png",t=1){if(!a)throw new Error("toBlob() is only supported in browser environments.");const n=this.toCanvas();return await n.convertToBlob({type:e,quality:t})}toTensor(e="CHW"){let t=new s.Tensor("uint8",new Uint8Array(this.data),[this.height,this.width,this.channels]);if("HWC"===e);else{if("CHW"!==e)throw new Error(`Unsupported channel format: ${e}`);t=t.permute(2,0,1)}return t}toCanvas(){if(!a)throw new Error("toCanvas() is only supported in browser environments.");const e=this.clone().rgba(),t=d(e.width,e.height),n=new u(e.data,e.width,e.height);return t.getContext("2d").putImageData(n,0,0),t}_update(e,t,n,r=null){return this.data=e,this.width=t,this.height=n,null!==r&&(this.channels=r),this}clone(){return new f(this.data.slice(),this.width,this.height,this.channels)}convert(e){if(this.channels===e)return this;switch(e){case 1:this.grayscale();break;case 3:this.rgb();break;case 4:this.rgba();break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this}async save(e){if(!a){if(i.env.useFS){const t=this.toSharp();return await t.toFile(e)}throw new Error("Unable to save the image because filesystem is disabled in this environment.")}{if(l)throw new Error("Unable to save an image from a Web Worker.");const t=e.split(".").pop().toLowerCase(),n=h.get(t)??"image/png",r=await this.toBlob(n),i=URL.createObjectURL(r),s=document.createElement("a");s.href=i,s.download=e,s.click(),s.remove()}}toSharp(){if(a)throw new Error("toSharp() is only supported in server-side environments.");return o(this.data,{raw:{width:this.width,height:this.height,channels:this.channels}})}}},"./src/utils/maths.js":
/*!****************************!*\
  !*** ./src/utils/maths.js ***!
  \****************************/(e,t,n)=>{function r(e,[t,n,r],[i,s],o="bilinear",a=!1){const l=s/r,d=i/n,u=new e.constructor(i*s*t),c=n*r,p=i*s;for(let o=0;o<i;++o)for(let i=0;i<s;++i){const a=o*s+i,h=(i+.5)/l-.5,f=(o+.5)/d-.5;let m=Math.floor(h),g=Math.floor(f);const _=Math.min(m+1,r-1),w=Math.min(g+1,n-1);m=Math.max(m,0),g=Math.max(g,0);const y=h-m,b=f-g,v=(1-y)*(1-b),x=y*(1-b),M=(1-y)*b,T=y*b,k=g*r,$=w*r,S=k+m,C=k+_,P=$+m,E=$+_;for(let n=0;n<t;++n){const t=n*c;u[n*p+a]=v*e[t+S]+x*e[t+C]+M*e[t+P]+T*e[t+E]}}return u}function i(e,t,n){const r=new Array(n.length),i=new Array(n.length);for(let e=n.length-1,s=1;e>=0;--e)i[e]=s,r[e]=t[n[e]],s*=r[e];const s=n.map(((e,t)=>i[n.indexOf(t)])),o=new e.constructor(e.length);for(let n=0;n<e.length;++n){let r=0;for(let e=t.length-1,i=n;e>=0;--e)r+=i%t[e]*s[e],i=Math.floor(i/t[e]);o[r]=e[n]}return[o,r]}function s(e){const t=p(e)[0],n=e.map((e=>Math.exp(e-t))),r=n.reduce(((e,t)=>e+t),0);return n.map((e=>e/r))}function o(e){return s(e).map((e=>Math.log(e)))}function a(e,t){let n=0;for(let r=0;r<e.length;++r)n+=e[r]*t[r];return n}function l(e,t=0){return e=Array.from(e).map(((e,t)=>[t,e])).sort(((e,t)=>t[1]-e[1])),null!==t&&t>0&&(e=e.slice(0,t)),e}function d(e,t){return a(e,t)/(u(e)*u(t))}function u(e){return Math.sqrt(e.reduce(((e,t)=>e+t*t),0))}function c(e){if(0===e.length)throw Error("Array must not be empty");let t=e[0],n=0;for(let r=1;r<e.length;++r)e[r]<t&&(t=e[r],n=r);return[t,n]}function p(e){if(0===e.length)throw Error("Array must not be empty");let t=e[0],n=0;for(let r=1;r<e.length;++r)e[r]>t&&(t=e[r],n=r);return[Number(t),n]}function h(e){return e>0&&0==(e&e-1)}n.r(t),n.d(t,{FFT:()=>g,bankers_round:()=>y,cos_sim:()=>d,dot:()=>a,getTopItems:()=>l,interpolate_data:()=>r,log_softmax:()=>o,magnitude:()=>u,max:()=>p,medianFilter:()=>_,min:()=>c,permute_data:()=>i,round:()=>w,softmax:()=>s});class f{constructor(e){if(this.size=0|e,this.size<=1||!h(this.size))throw new Error("FFT size must be a power of two larger than 1");this._csize=e<<1,this.table=new Float64Array(2*this.size);for(let e=0;e<this.table.length;e+=2){const t=Math.PI*e/this.size;this.table[e]=Math.cos(t),this.table[e+1]=-Math.sin(t)}let t=0;for(let e=1;this.size>e;e<<=1)++t;this._width=t%2==0?t-1:t,this._bitrev=new Int32Array(1<<this._width);for(let e=0;e<this._bitrev.length;++e){this._bitrev[e]=0;for(let t=0;t<this._width;t+=2){const n=this._width-t-2;this._bitrev[e]|=(e>>>t&3)<<n}}}createComplexArray(){return new Float64Array(this._csize)}fromComplexArray(e,t){const n=t||new Array(e.length>>>1);for(let t=0;t<e.length;t+=2)n[t>>>1]=e[t];return n}toComplexArray(e,t){const n=t||this.createComplexArray();for(let t=0;t<n.length;t+=2)n[t]=e[t>>>1],n[t+1]=0;return n}completeSpectrum(e){const t=this._csize,n=t>>>1;for(let r=2;r<n;r+=2)e[t-r]=e[r],e[t-r+1]=-e[r+1]}transform(e,t){if(e===t)throw new Error("Input and output buffers must be different");this._transform4(e,t,1)}realTransform(e,t){if(e===t)throw new Error("Input and output buffers must be different");this._realTransform4(e,t,1)}inverseTransform(e,t){if(e===t)throw new Error("Input and output buffers must be different");this._transform4(e,t,-1);for(let t=0;t<e.length;++t)e[t]/=this.size}_transform4(e,t,n){const r=this._csize;let i,s,o=1<<this._width,a=r/o<<1;const l=this._bitrev;if(4===a)for(i=0,s=0;i<r;i+=a,++s){const n=l[s];this._singleTransform2(t,e,i,n,o)}else for(i=0,s=0;i<r;i+=a,++s){const r=l[s];this._singleTransform4(t,e,i,r,o,n)}for(o>>=2;o>=2;o>>=2){a=r/o<<1;const t=a>>>2;for(i=0;i<r;i+=a){const r=i+t-1;for(let s=i,a=0;s<r;s+=2,a+=o){const r=s,i=r+t,o=i+t,l=o+t,d=e[r],u=e[r+1],c=e[i],p=e[i+1],h=e[o],f=e[o+1],m=e[l],g=e[l+1],_=this.table[a],w=n*this.table[a+1],y=c*_-p*w,b=c*w+p*_,v=this.table[2*a],x=n*this.table[2*a+1],M=h*v-f*x,T=h*x+f*v,k=this.table[3*a],$=n*this.table[3*a+1],S=m*k-g*$,C=m*$+g*k,P=d+M,E=u+T,A=d-M,F=u-T,I=y+S,z=b+C,B=n*(y-S),O=n*(b-C);e[r]=P+I,e[r+1]=E+z,e[i]=A+O,e[i+1]=F-B,e[o]=P-I,e[o+1]=E-z,e[l]=A-O,e[l+1]=F+B}}}}_singleTransform2(e,t,n,r,i){const s=e[r],o=e[r+1],a=e[r+i],l=e[r+i+1];t[n]=s+a,t[n+1]=o+l,t[n+2]=s-a,t[n+3]=o-l}_singleTransform4(e,t,n,r,i,s){const o=2*i,a=3*i,l=e[r],d=e[r+1],u=e[r+i],c=e[r+i+1],p=e[r+o],h=e[r+o+1],f=e[r+a],m=e[r+a+1],g=l+p,_=d+h,w=l-p,y=d-h,b=u+f,v=c+m,x=s*(u-f),M=s*(c-m);t[n]=g+b,t[n+1]=_+v,t[n+2]=w+M,t[n+3]=y-x,t[n+4]=g-b,t[n+5]=_-v,t[n+6]=w-M,t[n+7]=y+x}_realTransform4(e,t,n){const r=this._csize;let i,s,o=1<<this._width,a=r/o<<1;const l=this._bitrev;if(4===a)for(i=0,s=0;i<r;i+=a,++s){const n=l[s];this._singleRealTransform2(t,e,i,n>>>1,o>>>1)}else for(i=0,s=0;i<r;i+=a,++s){const r=l[s];this._singleRealTransform4(t,e,i,r>>>1,o>>>1,n)}for(o>>=2;o>=2;o>>=2){a=r/o<<1;const t=a>>>2;for(i=0;i<r;i+=a){const r=i+t-1;for(let s=i,a=0;s<r;s+=2,a+=o){const r=s,i=r+t,o=i+t,l=o+t,d=e[r],u=e[r+1],c=e[i],p=e[i+1],h=e[o],f=e[o+1],m=e[l],g=e[l+1],_=this.table[a],w=n*this.table[a+1],y=c*_-p*w,b=c*w+p*_,v=this.table[2*a],x=n*this.table[2*a+1],M=h*v-f*x,T=h*x+f*v,k=this.table[3*a],$=n*this.table[3*a+1],S=m*k-g*$,C=m*$+g*k,P=d+M,E=u+T,A=d-M,F=u-T,I=y+S,z=b+C,B=n*(y-S),O=n*(b-C);e[r]=P+I,e[r+1]=E+z,e[i]=A+O,e[i+1]=F-B,e[o]=P-I,e[o+1]=E-z,e[l]=A-O,e[l+1]=F+B}}}}_singleRealTransform2(e,t,n,r,i){const s=e[r],o=e[r+i];t[n]=s+o,t[n+1]=0,t[n+2]=s-o,t[n+3]=0}_singleRealTransform4(e,t,n,r,i,s){const o=2*i,a=3*i,l=e[r],d=e[r+i],u=e[r+o],c=e[r+a],p=l+u,h=l-u,f=d+c,m=s*(d-c);t[n]=p+f,t[n+1]=0,t[n+2]=h,t[n+3]=-m,t[n+4]=p-f,t[n+5]=0,t[n+6]=h,t[n+7]=m}}class m{constructor(e){const t=2*(e-1),n=2*(2*e-1),r=2**Math.ceil(Math.log2(n));this.bufferSize=r,this._a=t;const i=new Float64Array(n),s=new Float64Array(r);this._chirpBuffer=new Float64Array(r),this._buffer1=new Float64Array(r),this._buffer2=new Float64Array(r),this._outBuffer1=new Float64Array(r),this._outBuffer2=new Float64Array(r);const o=-2*Math.PI/e,a=Math.cos(o),l=Math.sin(o);for(let t=0;t<n>>1;++t){const n=(t+1-e)**2/2,r=Math.sqrt(a**2+l**2)**n,o=n*Math.atan2(l,a),d=2*t;i[d]=r*Math.cos(o),i[d+1]=r*Math.sin(o),s[d]=i[d],s[d+1]=-i[d+1]}this._slicedChirpBuffer=i.subarray(t,n),this._f=new f(r>>1),this._f.transform(this._chirpBuffer,s)}_transform(e,t,n){const r=this._buffer1,i=this._buffer2,s=this._outBuffer1,o=this._outBuffer2,a=this._chirpBuffer,l=this._slicedChirpBuffer,d=this._a;if(n)for(let e=0;e<l.length;e+=2){const n=e+1,i=t[e>>1];r[e]=i*l[e],r[n]=i*l[n]}else for(let e=0;e<l.length;e+=2){const n=e+1;r[e]=t[e]*l[e]-t[n]*l[n],r[n]=t[e]*l[n]+t[n]*l[e]}this._f.transform(s,r);for(let e=0;e<a.length;e+=2){const t=e+1;i[e]=s[e]*a[e]-s[t]*a[t],i[t]=s[e]*a[t]+s[t]*a[e]}this._f.inverseTransform(o,i);for(let t=0;t<o.length;t+=2){const n=o[t+d],r=o[t+d+1],i=l[t],s=l[t+1];e[t]=n*i-r*s,e[t+1]=n*s+r*i}}transform(e,t){this._transform(e,t,!1)}realTransform(e,t){this._transform(e,t,!0)}}class g{constructor(e){this.fft_length=e,this.isPowerOfTwo=h(e),this.isPowerOfTwo?(this.fft=new f(e),this.outputBufferSize=2*e):(this.fft=new m(e),this.outputBufferSize=this.fft.bufferSize)}realTransform(e,t){this.fft.realTransform(e,t)}transform(e,t){this.fft.transform(e,t)}}function _(e,t){if(t%2==0||t<=0)throw new Error("Window size must be a positive odd number");const n=new e.constructor(e.length),r=new e.constructor(t),i=Math.floor(t/2);for(let t=0;t<e.length;++t){let s=0;for(let n=-i;n<=i;++n){let i=t+n;i<0?i=Math.abs(i):i>=e.length&&(i=2*(e.length-1)-i),r[s++]=e[i]}r.sort(),n[t]=r[i]}return n}function w(e,t){const n=Math.pow(10,t);return Math.round(e*n)/n}function y(e){const t=Math.round(e);return Math.abs(e)%1==.5?t%2==0?t:t-1:t}},"./src/utils/tensor.js":
/*!*****************************!*\
  !*** ./src/utils/tensor.js ***!
  \*****************************/(e,t,n)=>{n.r(t),n.d(t,{Tensor:()=>a,cat:()=>g,dynamicTimeWarping:()=>b,full:()=>x,full_like:()=>M,interpolate:()=>d,interpolate_4d:()=>u,layer_norm:()=>p,mean:()=>y,mean_pooling:()=>c,ones:()=>T,ones_like:()=>k,permute:()=>l,quantize_embeddings:()=>C,stack:()=>_,std_mean:()=>w,zeros:()=>$,zeros_like:()=>S});var r=n(/*! ./maths.js */"./src/utils/maths.js"),i=n(/*! ../backends/onnx.js */"./src/backends/onnx.js"),s=n(/*! ../ops/registry.js */"./src/ops/registry.js");const o=Object.freeze({float32:Float32Array,float16:Uint16Array,float64:Float64Array,string:Array,int8:Int8Array,uint8:Uint8Array,int16:Int16Array,uint16:Uint16Array,int32:Int32Array,uint32:Uint32Array,int64:BigInt64Array,uint64:BigUint64Array,bool:Uint8Array});class a{get dims(){return this.ort_tensor.dims}set dims(e){this.ort_tensor.dims=e}get type(){return this.ort_tensor.type}get data(){return this.ort_tensor.data}get size(){return this.ort_tensor.size}ort_tensor;constructor(...e){return(0,i.isONNXTensor)(e[0])?this.ort_tensor=e[0]:this.ort_tensor=new i.Tensor(e[0],e[1],e[2]),new Proxy(this,{get:(e,t)=>{if("string"==typeof t){let n=Number(t);if(Number.isInteger(n))return e._getitem(n)}return e[t]},set:(e,t,n)=>e[t]=n})}dispose(){this.ort_tensor.dispose()}*[Symbol.iterator](){const[e,...t]=this.dims;if(t.length>0){const n=t.reduce(((e,t)=>e*t));for(let r=0;r<e;++r)yield this._subarray(r,n,t)}else yield*this.data}_getitem(e){const[t,...n]=this.dims;if(e=m(e,t),n.length>0){const t=n.reduce(((e,t)=>e*t));return this._subarray(e,t,n)}return new a(this.type,[this.data[e]],n)}indexOf(e){const t=this.data;for(let n=0;n<t.length;++n)if(t[n]==e)return n;return-1}_subarray(e,t,n){const r=e*t,i=(e+1)*t,s="subarray"in this.data?this.data.subarray(r,i):this.data.slice(r,i);return new a(this.type,s,n)}item(){const e=this.data;if(1!==e.length)throw new Error(`a Tensor with ${e.length} elements cannot be converted to Scalar`);return e[0]}tolist(){return function(e,t){const n=e.length,r=t.reduce(((e,t)=>e*t));if(n!==r)throw Error(`cannot reshape array of size ${n} into shape (${t})`);let i=e;for(let e=t.length-1;e>=0;e--)i=i.reduce(((n,r)=>{let i=n[n.length-1];return i.length<t[e]?i.push(r):n.push([r]),n}),[[]]);return i[0]}(this.data,this.dims)}sigmoid(){return this.clone().sigmoid_()}sigmoid_(){const e=this.data;for(let t=0;t<e.length;++t)e[t]=1/(1+Math.exp(-e[t]));return this}mul(e){return this.clone().mul_(e)}mul_(e){const t=this.data;for(let n=0;n<t.length;++n)t[n]*=e;return this}add(e){return this.clone().add_(e)}add_(e){const t=this.data;for(let n=0;n<t.length;++n)t[n]+=e;return this}clone(){return new a(this.type,this.data.slice(),this.dims.slice())}slice(...e){let t=[],n=[];for(let r=0;r<this.dims.length;++r){let i=e[r];if(null==i)n.push([0,this.dims[r]]),t.push(this.dims[r]);else if("number"==typeof i)i=m(i,this.dims[r],r),n.push([i,i+1]);else{if(!Array.isArray(i)||2!==i.length)throw new Error(`Invalid slice: ${i}`);{if(i[0]>i[1])throw new Error(`Invalid slice: ${i}`);let e=[Math.max(i[0],0),Math.min(i[1],this.dims[r])];n.push(e),t.push(e[1]-e[0])}}}let r=n.map((([e,t])=>t-e)),i=r.reduce(((e,t)=>e*t));const s=this.data;let o=new s.constructor(i);const l=this.stride();for(let e=0;e<i;++e){let t=0;for(let i=r.length-1,s=e;i>=0;--i){const e=r[i];t+=(s%e+n[i][0])*l[i],s=Math.floor(s/e)}o[e]=s[t]}return new a(this.type,o,t)}permute(...e){return l(this,e)}transpose(...e){return this.permute(...e)}sum(e=null,t=!1){return this.norm(1,e,t)}norm(e="fro",t=null,n=!1){if("fro"===e)e=2;else if("string"==typeof e)throw Error(`Unsupported norm: ${e}`);const r=this.data;if(null===t){let t=r.reduce(((t,n)=>t+n**e),0)**(1/e);return new a(this.type,[t],[])}t=m(t,this.dims.length);const i=this.dims.slice();i[t]=1;const s=new r.constructor(r.length/this.dims[t]);for(let n=0;n<r.length;++n){let o=0;for(let e=this.dims.length-1,r=n,s=1;e>=0;--e){const n=this.dims[e];if(e!==t){o+=r%n*s,s*=i[e]}r=Math.floor(r/n)}s[o]+=r[n]**e}if(1!==e)for(let t=0;t<s.length;++t)s[t]=s[t]**(1/e);return n||i.splice(t,1),new a(this.type,s,i)}normalize_(e=2,t=1){t=m(t,this.dims.length);const n=this.norm(e,t,!0),r=this.data;for(let e=0;e<r.length;++e){let i=0;for(let n=this.dims.length-1,r=e,s=1;n>=0;--n){const e=this.dims[n];if(n!==t){i+=r%e*s,s*=this.dims[n]}r=Math.floor(r/e)}r[e]/=n.data[i]}return this}normalize(e=2,t=1){return this.clone().normalize_(e,t)}stride(){return function(e){const t=new Array(e.length);for(let n=e.length-1,r=1;n>=0;--n)t[n]=r,r*=e[n];return t}(this.dims)}squeeze(e=null){return new a(this.type,this.data,h(this.dims,e))}squeeze_(e=null){return this.dims=h(this.dims,e),this}unsqueeze(e=null){return new a(this.type,this.data,f(this.dims,e))}unsqueeze_(e=null){return this.dims=f(this.dims,e),this}flatten_(e=0,t=-1){t=(t+this.dims.length)%this.dims.length;let n=this.dims.slice(0,e),r=this.dims.slice(e,t+1),i=this.dims.slice(t+1);return this.dims=[...n,r.reduce(((e,t)=>e*t),1),...i],this}flatten(e=0,t=-1){return this.clone().flatten_(e,t)}view(...e){let t=-1;for(let n=0;n<e.length;++n)if(-1===e[n]){if(-1!==t)throw new Error("Only one dimension can be inferred");t=n}if(-1!==t){const n=e.reduce(((e,n,r)=>r!==t?e*n:e),1);e[t]=this.data.length/n}return new a(this.type,this.data,e)}neg_(){const e=this.data;for(let t=0;t<e.length;++t)e[t]=-e[t];return this}neg(){return this.clone().neg_()}clamp_(e,t){const n=this.data;for(let r=0;r<n.length;++r)n[r]=Math.min(Math.max(n[r],e),t);return this}clamp(e,t){return this.clone().clamp_(e,t)}round_(){const e=this.data;for(let t=0;t<e.length;++t)e[t]=Math.round(e[t]);return this}round(){return this.clone().round_()}mean(e=null,t=!1){return y(this,e,t)}to(e){if(this.type===e)return this;if(!o.hasOwnProperty(e))throw new Error(`Unsupported type: ${e}`);return new a(e,o[e].from(this.data),this.dims)}}function l(e,t){const[n,i]=(0,r.permute_data)(e.data,e.dims,t);return new a(e.type,n,i)}function d(e,[t,n],i="bilinear",s=!1){const o=e.dims.at(-3)??1,l=e.dims.at(-2),d=e.dims.at(-1);let u=(0,r.interpolate_data)(e.data,[o,l,d],[t,n],i,s);return new a(e.type,u,[o,t,n])}async function u(e,{size:t=null,mode:n="bilinear"}={}){if(4!==e.dims.length)throw new Error("`interpolate_4d` currently only supports 4D input.");if(!t)throw new Error("`interpolate_4d` requires a `size` argument.");let r,i;if(2===t.length)r=[...e.dims.slice(0,2),...t];else if(3===t.length)r=[e.dims[0],...t];else{if(4!==t.length)throw new Error("`size` must be of length 2, 3, or 4.");r=t}if("bilinear"===n)i=await s.TensorOpRegistry.bilinear_interpolate_4d;else{if("bicubic"!==n)throw new Error(`Unsupported mode: ${n}`);i=await s.TensorOpRegistry.bicubic_interpolate_4d}const o=new a("int64",new BigInt64Array(r.map(BigInt)),[r.length]);return await i({x:e,s:o})}function c(e,t){let n=[e.dims[0],e.dims[2]],r=new e.data.constructor(n[0]*n[1]),[i,s,o]=e.dims,l=0;for(let n=0;n<i;++n){let i=n*o*s;for(let a=0;a<o;++a){let d=0,u=0,c=n*s,p=i+a;for(let n=0;n<s;++n){let r=Number(t.data[c+n]);u+=r,d+=e.data[p+n*o]*r}let h=d/u;r[l++]=h}}return new a(e.type,r,n)}function p(e,t,{eps:n=1e-5}={}){if(2!==e.dims.length)throw new Error("`layer_norm` currently only supports 2D input.");const[r,i]=e.dims;if(1!==t.length&&t[0]!==i)throw new Error("`normalized_shape` must be a 1D array with shape `[input.dims[1]]`.");const[s,o]=w(e,1,0,!0),l=new e.data.constructor(e.data.length);for(let t=0;t<r;++t){const r=t*i;for(let a=0;a<i;++a){const i=r+a;l[i]=(e.data[i]-o.data[t])/(s.data[t]+n)}}return new a(e.type,l,e.dims)}function h(e,t){return e=e.slice(),null===t?e=e.filter((e=>1!==e)):"number"==typeof t?1===e[t]&&e.splice(t,1):Array.isArray(t)&&(e=e.filter(((e,n)=>1!==e||!t.includes(n)))),e}function f(e,t){return t=m(t,e.length+1),(e=e.slice()).splice(t,0,1),e}function m(e,t,n=null){if(e<-t||e>=t)throw new Error(`IndexError: index ${e} is out of bounds for dimension${null===n?"":" "+n} with size ${t}`);return e<0&&(e=(e%t+t)%t),e}function g(e,t=0){t=m(t,e[0].dims.length);const n=e[0].dims.slice();n[t]=e.reduce(((e,n)=>e+n.dims[t]),0);const r=n.reduce(((e,t)=>e*t),1),i=new e[0].data.constructor(r),s=e[0].type;if(0===t){let t=0;for(let n of e)i.set(n.data,t),t+=n.data.length}else{let r=0;for(let s=0;s<e.length;++s){let o=e[s];for(let e=0;e<o.data.length;++e){let s=0;for(let i=o.dims.length-1,a=e,l=1;i>=0;--i){const e=o.dims[i];let d=a%e;i===t&&(d+=r),s+=d*l,l*=n[i],a=Math.floor(a/e)}i[s]=o.data[e]}r+=o.dims[t]}}return new a(s,i,n)}function _(e,t=0){return g(e.map((e=>e.unsqueeze(t))),t)}function w(e,t=null,n=1,r=!1){if(null===t){const t=e.data.reduce(((e,t)=>e+t),0)/e.data.length,r=Math.sqrt(e.data.reduce(((e,n)=>e+(n-t)**2),0)/(e.data.length-n)),i=new a(e.type,[t],[]);return[new a(e.type,[r],[]),i]}const i=y(e,t=m(t,e.dims.length),r),s=e.dims.slice();s[t]=1;const o=new e.data.constructor(e.data.length/e.dims[t]);for(let n=0;n<e.data.length;++n){let r=0;for(let i=e.dims.length-1,o=n,a=1;i>=0;--i){const n=e.dims[i];if(i!==t){r+=o%n*a,a*=s[i]}o=Math.floor(o/n)}o[r]+=(e.data[n]-i.data[r])**2}for(let r=0;r<o.length;++r)o[r]=Math.sqrt(o[r]/(e.dims[t]-n));r||s.splice(t,1);return[new a(e.type,o,s),i]}function y(e,t=null,n=!1){if(null===t){let t=e.data.reduce(((e,t)=>e+t),0);return new a(e.type,[t/e.data.length],[])}t=m(t,e.dims.length);const r=e.dims.slice();r[t]=1;const i=new e.data.constructor(e.data.length/e.dims[t]);for(let n=0;n<e.data.length;++n){let s=0;for(let i=e.dims.length-1,o=n,a=1;i>=0;--i){const n=e.dims[i];if(i!==t){s+=o%n*a,a*=r[i]}o=Math.floor(o/n)}i[s]+=e.data[n]}if(1!==e.dims[t])for(let n=0;n<i.length;++n)i[n]=i[n]/e.dims[t];return n||r.splice(t,1),new a(e.type,i,r)}function b(e){const[t,n]=e.dims,r=[t+1,n+1],i=new a("float32",new Float32Array(r[0]*r[1]).fill(1/0),r),s=new a("float32",new Float32Array(r[0]*r[1]).fill(-1),r);i[0].data[0]=0;for(let r=1;r<n+1;++r)for(let n=1;n<t+1;++n){const t=i[n-1][r-1].item(),o=i[n-1][r].item(),a=i[n][r-1].item();let l,d;t<o&&t<a?(l=t,d=0):o<t&&o<a?(l=o,d=1):(l=a,d=2),i[n].data[r]=e[n-1][r-1].item()+l,s[n].data[r]=d}let o=t,l=n;s.data.fill(2,0,r[1]);for(let e=0;e<r[0];++e)s[e].data[0]=1;let d=[],u=[];for(;o>0||l>0;){d.push(o-1),u.push(l-1);switch(s[o][l].item()){case 0:--o,--l;break;case 1:--o;break;case 2:--l;break;default:throw new Error(`Internal error in dynamic time warping. Unexpected trace[${o}, ${l}]. Please file a bug report.`)}}return d.reverse(),u.reverse(),[d,u]}function v(e,t,n,r){const i=e.reduce(((e,t)=>e*t),1);return new a(n,new r(i).fill(t),e)}function x(e,t){let n,r;if("number"==typeof t)n="float32",r=Float32Array;else{if("bigint"!=typeof t)throw new Error("Unsupported data type: "+typeof t);n="int64",r=BigInt64Array}return v(e,t,n,r)}function M(e,t){return x(e.dims,t)}function T(e){return v(e,1n,"int64",BigInt64Array)}function k(e){return T(e.dims)}function $(e){return v(e,0n,"int64",BigInt64Array)}function S(e){return $(e.dims)}function C(e,t){if(2!==e.dims.length)throw new Error("The tensor must have 2 dimensions");if(e.dims.at(-1)%8!=0)throw new Error("The last dimension of the tensor must be a multiple of 8");if(!["binary","ubinary"].includes(t))throw new Error("The precision must be either 'binary' or 'ubinary'");const n="binary"===t,r=n?"int8":"uint8",i=n?Int8Array:Uint8Array,s=e.data,o=new i(s.length/8);for(let e=0;e<s.length;++e){const t=s[e]>0?1:0,r=Math.floor(e/8),i=e%8;o[r]|=t<<7-i,n&&0===i&&(o[r]-=128)}return new a(r,o,[e.dims[0],e.dims[1]/8])}}},r={};function i(e){var t=r[e];if(void 0!==t)return t.exports;var s=r[e]={exports:{}};return n[e](s,s.exports,i),s.exports}t=Object.getPrototypeOf?e=>Object.getPrototypeOf(e):e=>e.__proto__,i.t=function(n,r){if(1&r&&(n=this(n)),8&r)return n;if("object"==typeof n&&n){if(4&r&&n.__esModule)return n;if(16&r&&"function"==typeof n.then)return n}var s=Object.create(null);i.r(s);var o={};e=e||[null,t({}),t([]),t(t)];for(var a=2&r&&n;"object"==typeof a&&!~e.indexOf(a);a=t(a))Object.getOwnPropertyNames(a).forEach((e=>o[e]=()=>n[e]));return o.default=()=>n,i.d(s,o),s},i.d=(e,t)=>{for(var n in t)i.o(t,n)&&!i.o(e,n)&&Object.defineProperty(e,n,{enumerable:!0,get:t[n]})},i.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),i.r=e=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})};var s={};(()=>{
/*!*****************************!*\
  !*** ./src/transformers.js ***!
  \*****************************/
i.r(s),i.d(s,{ASTFeatureExtractor:()=>o.ASTFeatureExtractor,ASTForAudioClassification:()=>n.ASTForAudioClassification,ASTModel:()=>n.ASTModel,ASTPreTrainedModel:()=>n.ASTPreTrainedModel,AlbertForMaskedLM:()=>n.AlbertForMaskedLM,AlbertForQuestionAnswering:()=>n.AlbertForQuestionAnswering,AlbertForSequenceClassification:()=>n.AlbertForSequenceClassification,AlbertModel:()=>n.AlbertModel,AlbertPreTrainedModel:()=>n.AlbertPreTrainedModel,AlbertTokenizer:()=>r.AlbertTokenizer,AudioClassificationPipeline:()=>t.AudioClassificationPipeline,AutoConfig:()=>a.AutoConfig,AutoModel:()=>n.AutoModel,AutoModelForAudioClassification:()=>n.AutoModelForAudioClassification,AutoModelForAudioFrameClassification:()=>n.AutoModelForAudioFrameClassification,AutoModelForCTC:()=>n.AutoModelForCTC,AutoModelForCausalLM:()=>n.AutoModelForCausalLM,AutoModelForDepthEstimation:()=>n.AutoModelForDepthEstimation,AutoModelForDocumentQuestionAnswering:()=>n.AutoModelForDocumentQuestionAnswering,AutoModelForImageClassification:()=>n.AutoModelForImageClassification,AutoModelForImageFeatureExtraction:()=>n.AutoModelForImageFeatureExtraction,AutoModelForImageMatting:()=>n.AutoModelForImageMatting,AutoModelForImageSegmentation:()=>n.AutoModelForImageSegmentation,AutoModelForImageToImage:()=>n.AutoModelForImageToImage,AutoModelForMaskGeneration:()=>n.AutoModelForMaskGeneration,AutoModelForMaskedLM:()=>n.AutoModelForMaskedLM,AutoModelForObjectDetection:()=>n.AutoModelForObjectDetection,AutoModelForQuestionAnswering:()=>n.AutoModelForQuestionAnswering,AutoModelForSemanticSegmentation:()=>n.AutoModelForSemanticSegmentation,AutoModelForSeq2SeqLM:()=>n.AutoModelForSeq2SeqLM,AutoModelForSequenceClassification:()=>n.AutoModelForSequenceClassification,AutoModelForSpeechSeq2Seq:()=>n.AutoModelForSpeechSeq2Seq,AutoModelForTextToSpectrogram:()=>n.AutoModelForTextToSpectrogram,AutoModelForTextToWaveform:()=>n.AutoModelForTextToWaveform,AutoModelForTokenClassification:()=>n.AutoModelForTokenClassification,AutoModelForVision2Seq:()=>n.AutoModelForVision2Seq,AutoModelForXVector:()=>n.AutoModelForXVector,AutoModelForZeroShotObjectDetection:()=>n.AutoModelForZeroShotObjectDetection,AutoProcessor:()=>o.AutoProcessor,AutoTokenizer:()=>r.AutoTokenizer,AutomaticSpeechRecognitionPipeline:()=>t.AutomaticSpeechRecognitionPipeline,BartForConditionalGeneration:()=>n.BartForConditionalGeneration,BartForSequenceClassification:()=>n.BartForSequenceClassification,BartModel:()=>n.BartModel,BartPretrainedModel:()=>n.BartPretrainedModel,BartTokenizer:()=>r.BartTokenizer,BaseModelOutput:()=>n.BaseModelOutput,BaseStreamer:()=>p.BaseStreamer,BeitFeatureExtractor:()=>o.BeitFeatureExtractor,BeitForImageClassification:()=>n.BeitForImageClassification,BeitModel:()=>n.BeitModel,BeitPreTrainedModel:()=>n.BeitPreTrainedModel,BertForMaskedLM:()=>n.BertForMaskedLM,BertForQuestionAnswering:()=>n.BertForQuestionAnswering,BertForSequenceClassification:()=>n.BertForSequenceClassification,BertForTokenClassification:()=>n.BertForTokenClassification,BertModel:()=>n.BertModel,BertPreTrainedModel:()=>n.BertPreTrainedModel,BertTokenizer:()=>r.BertTokenizer,BitImageProcessor:()=>o.BitImageProcessor,BlenderbotForConditionalGeneration:()=>n.BlenderbotForConditionalGeneration,BlenderbotModel:()=>n.BlenderbotModel,BlenderbotPreTrainedModel:()=>n.BlenderbotPreTrainedModel,BlenderbotSmallForConditionalGeneration:()=>n.BlenderbotSmallForConditionalGeneration,BlenderbotSmallModel:()=>n.BlenderbotSmallModel,BlenderbotSmallPreTrainedModel:()=>n.BlenderbotSmallPreTrainedModel,BlenderbotSmallTokenizer:()=>r.BlenderbotSmallTokenizer,BlenderbotTokenizer:()=>r.BlenderbotTokenizer,BloomForCausalLM:()=>n.BloomForCausalLM,BloomModel:()=>n.BloomModel,BloomPreTrainedModel:()=>n.BloomPreTrainedModel,BloomTokenizer:()=>r.BloomTokenizer,CLIPFeatureExtractor:()=>o.CLIPFeatureExtractor,CLIPImageProcessor:()=>o.CLIPImageProcessor,CLIPModel:()=>n.CLIPModel,CLIPPreTrainedModel:()=>n.CLIPPreTrainedModel,CLIPSegForImageSegmentation:()=>n.CLIPSegForImageSegmentation,CLIPSegModel:()=>n.CLIPSegModel,CLIPSegPreTrainedModel:()=>n.CLIPSegPreTrainedModel,CLIPTextModelWithProjection:()=>n.CLIPTextModelWithProjection,CLIPTokenizer:()=>r.CLIPTokenizer,CLIPVisionModelWithProjection:()=>n.CLIPVisionModelWithProjection,CamembertForMaskedLM:()=>n.CamembertForMaskedLM,CamembertForQuestionAnswering:()=>n.CamembertForQuestionAnswering,CamembertForSequenceClassification:()=>n.CamembertForSequenceClassification,CamembertForTokenClassification:()=>n.CamembertForTokenClassification,CamembertModel:()=>n.CamembertModel,CamembertPreTrainedModel:()=>n.CamembertPreTrainedModel,CamembertTokenizer:()=>r.CamembertTokenizer,CausalLMOutput:()=>n.CausalLMOutput,CausalLMOutputWithPast:()=>n.CausalLMOutputWithPast,ChineseCLIPFeatureExtractor:()=>o.ChineseCLIPFeatureExtractor,ChineseCLIPModel:()=>n.ChineseCLIPModel,ChineseCLIPPreTrainedModel:()=>n.ChineseCLIPPreTrainedModel,ClapAudioModelWithProjection:()=>n.ClapAudioModelWithProjection,ClapFeatureExtractor:()=>o.ClapFeatureExtractor,ClapModel:()=>n.ClapModel,ClapPreTrainedModel:()=>n.ClapPreTrainedModel,ClapTextModelWithProjection:()=>n.ClapTextModelWithProjection,CodeGenForCausalLM:()=>n.CodeGenForCausalLM,CodeGenModel:()=>n.CodeGenModel,CodeGenPreTrainedModel:()=>n.CodeGenPreTrainedModel,CodeGenTokenizer:()=>r.CodeGenTokenizer,CodeLlamaTokenizer:()=>r.CodeLlamaTokenizer,CohereTokenizer:()=>r.CohereTokenizer,ConvBertForMaskedLM:()=>n.ConvBertForMaskedLM,ConvBertForQuestionAnswering:()=>n.ConvBertForQuestionAnswering,ConvBertForSequenceClassification:()=>n.ConvBertForSequenceClassification,ConvBertForTokenClassification:()=>n.ConvBertForTokenClassification,ConvBertModel:()=>n.ConvBertModel,ConvBertPreTrainedModel:()=>n.ConvBertPreTrainedModel,ConvBertTokenizer:()=>r.ConvBertTokenizer,ConvNextFeatureExtractor:()=>o.ConvNextFeatureExtractor,ConvNextForImageClassification:()=>n.ConvNextForImageClassification,ConvNextImageProcessor:()=>o.ConvNextImageProcessor,ConvNextModel:()=>n.ConvNextModel,ConvNextPreTrainedModel:()=>n.ConvNextPreTrainedModel,ConvNextV2ForImageClassification:()=>n.ConvNextV2ForImageClassification,ConvNextV2Model:()=>n.ConvNextV2Model,ConvNextV2PreTrainedModel:()=>n.ConvNextV2PreTrainedModel,DPTFeatureExtractor:()=>o.DPTFeatureExtractor,DPTForDepthEstimation:()=>n.DPTForDepthEstimation,DPTImageProcessor:()=>o.DPTImageProcessor,DPTModel:()=>n.DPTModel,DPTPreTrainedModel:()=>n.DPTPreTrainedModel,DebertaForMaskedLM:()=>n.DebertaForMaskedLM,DebertaForQuestionAnswering:()=>n.DebertaForQuestionAnswering,DebertaForSequenceClassification:()=>n.DebertaForSequenceClassification,DebertaForTokenClassification:()=>n.DebertaForTokenClassification,DebertaModel:()=>n.DebertaModel,DebertaPreTrainedModel:()=>n.DebertaPreTrainedModel,DebertaTokenizer:()=>r.DebertaTokenizer,DebertaV2ForMaskedLM:()=>n.DebertaV2ForMaskedLM,DebertaV2ForQuestionAnswering:()=>n.DebertaV2ForQuestionAnswering,DebertaV2ForSequenceClassification:()=>n.DebertaV2ForSequenceClassification,DebertaV2ForTokenClassification:()=>n.DebertaV2ForTokenClassification,DebertaV2Model:()=>n.DebertaV2Model,DebertaV2PreTrainedModel:()=>n.DebertaV2PreTrainedModel,DebertaV2Tokenizer:()=>r.DebertaV2Tokenizer,DeiTFeatureExtractor:()=>o.DeiTFeatureExtractor,DeiTForImageClassification:()=>n.DeiTForImageClassification,DeiTModel:()=>n.DeiTModel,DeiTPreTrainedModel:()=>n.DeiTPreTrainedModel,DepthAnythingForDepthEstimation:()=>n.DepthAnythingForDepthEstimation,DepthAnythingPreTrainedModel:()=>n.DepthAnythingPreTrainedModel,DepthEstimationPipeline:()=>t.DepthEstimationPipeline,DetrFeatureExtractor:()=>o.DetrFeatureExtractor,DetrForObjectDetection:()=>n.DetrForObjectDetection,DetrForSegmentation:()=>n.DetrForSegmentation,DetrModel:()=>n.DetrModel,DetrObjectDetectionOutput:()=>n.DetrObjectDetectionOutput,DetrPreTrainedModel:()=>n.DetrPreTrainedModel,DetrSegmentationOutput:()=>n.DetrSegmentationOutput,Dinov2ForImageClassification:()=>n.Dinov2ForImageClassification,Dinov2Model:()=>n.Dinov2Model,Dinov2PreTrainedModel:()=>n.Dinov2PreTrainedModel,DistilBertForMaskedLM:()=>n.DistilBertForMaskedLM,DistilBertForQuestionAnswering:()=>n.DistilBertForQuestionAnswering,DistilBertForSequenceClassification:()=>n.DistilBertForSequenceClassification,DistilBertForTokenClassification:()=>n.DistilBertForTokenClassification,DistilBertModel:()=>n.DistilBertModel,DistilBertPreTrainedModel:()=>n.DistilBertPreTrainedModel,DistilBertTokenizer:()=>r.DistilBertTokenizer,DocumentQuestionAnsweringPipeline:()=>t.DocumentQuestionAnsweringPipeline,DonutFeatureExtractor:()=>o.DonutFeatureExtractor,DonutSwinModel:()=>n.DonutSwinModel,DonutSwinPreTrainedModel:()=>n.DonutSwinPreTrainedModel,EfficientNetForImageClassification:()=>n.EfficientNetForImageClassification,EfficientNetImageProcessor:()=>o.EfficientNetImageProcessor,EfficientNetModel:()=>n.EfficientNetModel,EfficientNetPreTrainedModel:()=>n.EfficientNetPreTrainedModel,ElectraForMaskedLM:()=>n.ElectraForMaskedLM,ElectraForQuestionAnswering:()=>n.ElectraForQuestionAnswering,ElectraForSequenceClassification:()=>n.ElectraForSequenceClassification,ElectraForTokenClassification:()=>n.ElectraForTokenClassification,ElectraModel:()=>n.ElectraModel,ElectraPreTrainedModel:()=>n.ElectraPreTrainedModel,ElectraTokenizer:()=>r.ElectraTokenizer,EsmForMaskedLM:()=>n.EsmForMaskedLM,EsmForSequenceClassification:()=>n.EsmForSequenceClassification,EsmForTokenClassification:()=>n.EsmForTokenClassification,EsmModel:()=>n.EsmModel,EsmPreTrainedModel:()=>n.EsmPreTrainedModel,EsmTokenizer:()=>r.EsmTokenizer,FFT:()=>c.FFT,FalconForCausalLM:()=>n.FalconForCausalLM,FalconModel:()=>n.FalconModel,FalconPreTrainedModel:()=>n.FalconPreTrainedModel,FalconTokenizer:()=>r.FalconTokenizer,FeatureExtractionPipeline:()=>t.FeatureExtractionPipeline,FeatureExtractor:()=>o.FeatureExtractor,FillMaskPipeline:()=>t.FillMaskPipeline,GLPNFeatureExtractor:()=>o.GLPNFeatureExtractor,GLPNForDepthEstimation:()=>n.GLPNForDepthEstimation,GLPNModel:()=>n.GLPNModel,GLPNPreTrainedModel:()=>n.GLPNPreTrainedModel,GPT2LMHeadModel:()=>n.GPT2LMHeadModel,GPT2Model:()=>n.GPT2Model,GPT2PreTrainedModel:()=>n.GPT2PreTrainedModel,GPT2Tokenizer:()=>r.GPT2Tokenizer,GPTBigCodeForCausalLM:()=>n.GPTBigCodeForCausalLM,GPTBigCodeModel:()=>n.GPTBigCodeModel,GPTBigCodePreTrainedModel:()=>n.GPTBigCodePreTrainedModel,GPTJForCausalLM:()=>n.GPTJForCausalLM,GPTJModel:()=>n.GPTJModel,GPTJPreTrainedModel:()=>n.GPTJPreTrainedModel,GPTNeoForCausalLM:()=>n.GPTNeoForCausalLM,GPTNeoModel:()=>n.GPTNeoModel,GPTNeoPreTrainedModel:()=>n.GPTNeoPreTrainedModel,GPTNeoXForCausalLM:()=>n.GPTNeoXForCausalLM,GPTNeoXModel:()=>n.GPTNeoXModel,GPTNeoXPreTrainedModel:()=>n.GPTNeoXPreTrainedModel,GPTNeoXTokenizer:()=>r.GPTNeoXTokenizer,GemmaTokenizer:()=>r.GemmaTokenizer,Grok1Tokenizer:()=>r.Grok1Tokenizer,HerbertTokenizer:()=>r.HerbertTokenizer,HubertForCTC:()=>n.HubertForCTC,HubertForSequenceClassification:()=>n.HubertForSequenceClassification,HubertModel:()=>n.HubertModel,HubertPreTrainedModel:()=>n.HubertPreTrainedModel,ImageClassificationPipeline:()=>t.ImageClassificationPipeline,ImageFeatureExtractionPipeline:()=>t.ImageFeatureExtractionPipeline,ImageFeatureExtractor:()=>o.ImageFeatureExtractor,ImageMattingOutput:()=>n.ImageMattingOutput,ImageSegmentationPipeline:()=>t.ImageSegmentationPipeline,ImageToImagePipeline:()=>t.ImageToImagePipeline,ImageToTextPipeline:()=>t.ImageToTextPipeline,LlamaForCausalLM:()=>n.LlamaForCausalLM,LlamaModel:()=>n.LlamaModel,LlamaPreTrainedModel:()=>n.LlamaPreTrainedModel,LlamaTokenizer:()=>r.LlamaTokenizer,LlavaForConditionalGeneration:()=>n.LlavaForConditionalGeneration,LlavaPreTrainedModel:()=>n.LlavaPreTrainedModel,LongT5ForConditionalGeneration:()=>n.LongT5ForConditionalGeneration,LongT5Model:()=>n.LongT5Model,LongT5PreTrainedModel:()=>n.LongT5PreTrainedModel,M2M100ForConditionalGeneration:()=>n.M2M100ForConditionalGeneration,M2M100Model:()=>n.M2M100Model,M2M100PreTrainedModel:()=>n.M2M100PreTrainedModel,M2M100Tokenizer:()=>r.M2M100Tokenizer,MBart50Tokenizer:()=>r.MBart50Tokenizer,MBartForCausalLM:()=>n.MBartForCausalLM,MBartForConditionalGeneration:()=>n.MBartForConditionalGeneration,MBartForSequenceClassification:()=>n.MBartForSequenceClassification,MBartModel:()=>n.MBartModel,MBartPreTrainedModel:()=>n.MBartPreTrainedModel,MBartTokenizer:()=>r.MBartTokenizer,MPNetForMaskedLM:()=>n.MPNetForMaskedLM,MPNetForQuestionAnswering:()=>n.MPNetForQuestionAnswering,MPNetForSequenceClassification:()=>n.MPNetForSequenceClassification,MPNetForTokenClassification:()=>n.MPNetForTokenClassification,MPNetModel:()=>n.MPNetModel,MPNetPreTrainedModel:()=>n.MPNetPreTrainedModel,MPNetTokenizer:()=>r.MPNetTokenizer,MT5ForConditionalGeneration:()=>n.MT5ForConditionalGeneration,MT5Model:()=>n.MT5Model,MT5PreTrainedModel:()=>n.MT5PreTrainedModel,MarianMTModel:()=>n.MarianMTModel,MarianModel:()=>n.MarianModel,MarianPreTrainedModel:()=>n.MarianPreTrainedModel,MarianTokenizer:()=>r.MarianTokenizer,MaskedLMOutput:()=>n.MaskedLMOutput,MistralForCausalLM:()=>n.MistralForCausalLM,MistralModel:()=>n.MistralModel,MistralPreTrainedModel:()=>n.MistralPreTrainedModel,MobileBertForMaskedLM:()=>n.MobileBertForMaskedLM,MobileBertForQuestionAnswering:()=>n.MobileBertForQuestionAnswering,MobileBertForSequenceClassification:()=>n.MobileBertForSequenceClassification,MobileBertModel:()=>n.MobileBertModel,MobileBertPreTrainedModel:()=>n.MobileBertPreTrainedModel,MobileBertTokenizer:()=>r.MobileBertTokenizer,MobileViTFeatureExtractor:()=>o.MobileViTFeatureExtractor,MobileViTForImageClassification:()=>n.MobileViTForImageClassification,MobileViTModel:()=>n.MobileViTModel,MobileViTPreTrainedModel:()=>n.MobileViTPreTrainedModel,ModelOutput:()=>n.ModelOutput,MptForCausalLM:()=>n.MptForCausalLM,MptModel:()=>n.MptModel,MptPreTrainedModel:()=>n.MptPreTrainedModel,MusicgenForCausalLM:()=>n.MusicgenForCausalLM,MusicgenForConditionalGeneration:()=>n.MusicgenForConditionalGeneration,MusicgenModel:()=>n.MusicgenModel,MusicgenPreTrainedModel:()=>n.MusicgenPreTrainedModel,NllbTokenizer:()=>r.NllbTokenizer,NomicBertModel:()=>n.NomicBertModel,NomicBertPreTrainedModel:()=>n.NomicBertPreTrainedModel,NougatImageProcessor:()=>o.NougatImageProcessor,NougatTokenizer:()=>r.NougatTokenizer,OPTForCausalLM:()=>n.OPTForCausalLM,OPTModel:()=>n.OPTModel,OPTPreTrainedModel:()=>n.OPTPreTrainedModel,ObjectDetectionPipeline:()=>t.ObjectDetectionPipeline,OwlViTFeatureExtractor:()=>o.OwlViTFeatureExtractor,OwlViTForObjectDetection:()=>n.OwlViTForObjectDetection,OwlViTModel:()=>n.OwlViTModel,OwlViTPreTrainedModel:()=>n.OwlViTPreTrainedModel,OwlViTProcessor:()=>o.OwlViTProcessor,Owlv2ForObjectDetection:()=>n.Owlv2ForObjectDetection,Owlv2ImageProcessor:()=>o.Owlv2ImageProcessor,Owlv2Model:()=>n.Owlv2Model,Owlv2PreTrainedModel:()=>n.Owlv2PreTrainedModel,PhiForCausalLM:()=>n.PhiForCausalLM,PhiModel:()=>n.PhiModel,PhiPreTrainedModel:()=>n.PhiPreTrainedModel,Pipeline:()=>t.Pipeline,PreTrainedModel:()=>n.PreTrainedModel,PreTrainedTokenizer:()=>r.PreTrainedTokenizer,PretrainedConfig:()=>a.PretrainedConfig,PretrainedMixin:()=>n.PretrainedMixin,Processor:()=>o.Processor,QuestionAnsweringModelOutput:()=>n.QuestionAnsweringModelOutput,QuestionAnsweringPipeline:()=>t.QuestionAnsweringPipeline,Qwen2ForCausalLM:()=>n.Qwen2ForCausalLM,Qwen2Model:()=>n.Qwen2Model,Qwen2PreTrainedModel:()=>n.Qwen2PreTrainedModel,Qwen2Tokenizer:()=>r.Qwen2Tokenizer,RawImage:()=>d.RawImage,ResNetForImageClassification:()=>n.ResNetForImageClassification,ResNetModel:()=>n.ResNetModel,ResNetPreTrainedModel:()=>n.ResNetPreTrainedModel,RoFormerForMaskedLM:()=>n.RoFormerForMaskedLM,RoFormerForQuestionAnswering:()=>n.RoFormerForQuestionAnswering,RoFormerForSequenceClassification:()=>n.RoFormerForSequenceClassification,RoFormerForTokenClassification:()=>n.RoFormerForTokenClassification,RoFormerModel:()=>n.RoFormerModel,RoFormerPreTrainedModel:()=>n.RoFormerPreTrainedModel,RoFormerTokenizer:()=>r.RoFormerTokenizer,RobertaForMaskedLM:()=>n.RobertaForMaskedLM,RobertaForQuestionAnswering:()=>n.RobertaForQuestionAnswering,RobertaForSequenceClassification:()=>n.RobertaForSequenceClassification,RobertaForTokenClassification:()=>n.RobertaForTokenClassification,RobertaModel:()=>n.RobertaModel,RobertaPreTrainedModel:()=>n.RobertaPreTrainedModel,RobertaTokenizer:()=>r.RobertaTokenizer,SamImageProcessor:()=>o.SamImageProcessor,SamImageSegmentationOutput:()=>n.SamImageSegmentationOutput,SamModel:()=>n.SamModel,SamPreTrainedModel:()=>n.SamPreTrainedModel,SamProcessor:()=>o.SamProcessor,SeamlessM4TFeatureExtractor:()=>o.SeamlessM4TFeatureExtractor,SegformerFeatureExtractor:()=>o.SegformerFeatureExtractor,SegformerForImageClassification:()=>n.SegformerForImageClassification,SegformerForSemanticSegmentation:()=>n.SegformerForSemanticSegmentation,SegformerModel:()=>n.SegformerModel,SegformerPreTrainedModel:()=>n.SegformerPreTrainedModel,Seq2SeqLMOutput:()=>n.Seq2SeqLMOutput,SequenceClassifierOutput:()=>n.SequenceClassifierOutput,SiglipImageProcessor:()=>o.SiglipImageProcessor,SiglipModel:()=>n.SiglipModel,SiglipPreTrainedModel:()=>n.SiglipPreTrainedModel,SiglipTextModel:()=>n.SiglipTextModel,SiglipTokenizer:()=>r.SiglipTokenizer,SiglipVisionModel:()=>n.SiglipVisionModel,SpeechT5FeatureExtractor:()=>o.SpeechT5FeatureExtractor,SpeechT5ForSpeechToText:()=>n.SpeechT5ForSpeechToText,SpeechT5ForTextToSpeech:()=>n.SpeechT5ForTextToSpeech,SpeechT5HifiGan:()=>n.SpeechT5HifiGan,SpeechT5Model:()=>n.SpeechT5Model,SpeechT5PreTrainedModel:()=>n.SpeechT5PreTrainedModel,SpeechT5Processor:()=>o.SpeechT5Processor,SpeechT5Tokenizer:()=>r.SpeechT5Tokenizer,SqueezeBertForMaskedLM:()=>n.SqueezeBertForMaskedLM,SqueezeBertForQuestionAnswering:()=>n.SqueezeBertForQuestionAnswering,SqueezeBertForSequenceClassification:()=>n.SqueezeBertForSequenceClassification,SqueezeBertModel:()=>n.SqueezeBertModel,SqueezeBertPreTrainedModel:()=>n.SqueezeBertPreTrainedModel,SqueezeBertTokenizer:()=>r.SqueezeBertTokenizer,StableLmForCausalLM:()=>n.StableLmForCausalLM,StableLmModel:()=>n.StableLmModel,StableLmPreTrainedModel:()=>n.StableLmPreTrainedModel,Starcoder2ForCausalLM:()=>n.Starcoder2ForCausalLM,Starcoder2Model:()=>n.Starcoder2Model,Starcoder2PreTrainedModel:()=>n.Starcoder2PreTrainedModel,SummarizationPipeline:()=>t.SummarizationPipeline,Swin2SRForImageSuperResolution:()=>n.Swin2SRForImageSuperResolution,Swin2SRImageProcessor:()=>o.Swin2SRImageProcessor,Swin2SRModel:()=>n.Swin2SRModel,Swin2SRPreTrainedModel:()=>n.Swin2SRPreTrainedModel,SwinForImageClassification:()=>n.SwinForImageClassification,SwinModel:()=>n.SwinModel,SwinPreTrainedModel:()=>n.SwinPreTrainedModel,T5ForConditionalGeneration:()=>n.T5ForConditionalGeneration,T5Model:()=>n.T5Model,T5PreTrainedModel:()=>n.T5PreTrainedModel,T5Tokenizer:()=>r.T5Tokenizer,TableTransformerForObjectDetection:()=>n.TableTransformerForObjectDetection,TableTransformerModel:()=>n.TableTransformerModel,TableTransformerObjectDetectionOutput:()=>n.TableTransformerObjectDetectionOutput,TableTransformerPreTrainedModel:()=>n.TableTransformerPreTrainedModel,Tensor:()=>u.Tensor,Text2TextGenerationPipeline:()=>t.Text2TextGenerationPipeline,TextClassificationPipeline:()=>t.TextClassificationPipeline,TextGenerationPipeline:()=>t.TextGenerationPipeline,TextToAudioPipeline:()=>t.TextToAudioPipeline,TokenClassificationPipeline:()=>t.TokenClassificationPipeline,TokenClassifierOutput:()=>n.TokenClassifierOutput,TokenizerModel:()=>r.TokenizerModel,TrOCRForCausalLM:()=>n.TrOCRForCausalLM,TrOCRPreTrainedModel:()=>n.TrOCRPreTrainedModel,TranslationPipeline:()=>t.TranslationPipeline,UniSpeechForCTC:()=>n.UniSpeechForCTC,UniSpeechForSequenceClassification:()=>n.UniSpeechForSequenceClassification,UniSpeechModel:()=>n.UniSpeechModel,UniSpeechPreTrainedModel:()=>n.UniSpeechPreTrainedModel,UniSpeechSatForAudioFrameClassification:()=>n.UniSpeechSatForAudioFrameClassification,UniSpeechSatForCTC:()=>n.UniSpeechSatForCTC,UniSpeechSatForSequenceClassification:()=>n.UniSpeechSatForSequenceClassification,UniSpeechSatModel:()=>n.UniSpeechSatModel,UniSpeechSatPreTrainedModel:()=>n.UniSpeechSatPreTrainedModel,ViTFeatureExtractor:()=>o.ViTFeatureExtractor,ViTForImageClassification:()=>n.ViTForImageClassification,ViTImageProcessor:()=>o.ViTImageProcessor,ViTModel:()=>n.ViTModel,ViTPreTrainedModel:()=>n.ViTPreTrainedModel,VisionEncoderDecoderModel:()=>n.VisionEncoderDecoderModel,VitMatteForImageMatting:()=>n.VitMatteForImageMatting,VitMatteImageProcessor:()=>o.VitMatteImageProcessor,VitMattePreTrainedModel:()=>n.VitMattePreTrainedModel,VitsModel:()=>n.VitsModel,VitsModelOutput:()=>n.VitsModelOutput,VitsPreTrainedModel:()=>n.VitsPreTrainedModel,VitsTokenizer:()=>r.VitsTokenizer,Wav2Vec2BertForCTC:()=>n.Wav2Vec2BertForCTC,Wav2Vec2BertForSequenceClassification:()=>n.Wav2Vec2BertForSequenceClassification,Wav2Vec2BertModel:()=>n.Wav2Vec2BertModel,Wav2Vec2BertPreTrainedModel:()=>n.Wav2Vec2BertPreTrainedModel,Wav2Vec2CTCTokenizer:()=>r.Wav2Vec2CTCTokenizer,Wav2Vec2FeatureExtractor:()=>o.Wav2Vec2FeatureExtractor,Wav2Vec2ForAudioFrameClassification:()=>n.Wav2Vec2ForAudioFrameClassification,Wav2Vec2ForCTC:()=>n.Wav2Vec2ForCTC,Wav2Vec2ForSequenceClassification:()=>n.Wav2Vec2ForSequenceClassification,Wav2Vec2Model:()=>n.Wav2Vec2Model,Wav2Vec2PreTrainedModel:()=>n.Wav2Vec2PreTrainedModel,Wav2Vec2ProcessorWithLM:()=>o.Wav2Vec2ProcessorWithLM,WavLMForAudioFrameClassification:()=>n.WavLMForAudioFrameClassification,WavLMForCTC:()=>n.WavLMForCTC,WavLMForSequenceClassification:()=>n.WavLMForSequenceClassification,WavLMForXVector:()=>n.WavLMForXVector,WavLMModel:()=>n.WavLMModel,WavLMPreTrainedModel:()=>n.WavLMPreTrainedModel,WhisperFeatureExtractor:()=>o.WhisperFeatureExtractor,WhisperForConditionalGeneration:()=>n.WhisperForConditionalGeneration,WhisperModel:()=>n.WhisperModel,WhisperPreTrainedModel:()=>n.WhisperPreTrainedModel,WhisperProcessor:()=>o.WhisperProcessor,WhisperTokenizer:()=>r.WhisperTokenizer,XLMForQuestionAnswering:()=>n.XLMForQuestionAnswering,XLMForSequenceClassification:()=>n.XLMForSequenceClassification,XLMForTokenClassification:()=>n.XLMForTokenClassification,XLMModel:()=>n.XLMModel,XLMPreTrainedModel:()=>n.XLMPreTrainedModel,XLMRobertaForMaskedLM:()=>n.XLMRobertaForMaskedLM,XLMRobertaForQuestionAnswering:()=>n.XLMRobertaForQuestionAnswering,XLMRobertaForSequenceClassification:()=>n.XLMRobertaForSequenceClassification,XLMRobertaForTokenClassification:()=>n.XLMRobertaForTokenClassification,XLMRobertaModel:()=>n.XLMRobertaModel,XLMRobertaPreTrainedModel:()=>n.XLMRobertaPreTrainedModel,XLMRobertaTokenizer:()=>r.XLMRobertaTokenizer,XLMTokenizer:()=>r.XLMTokenizer,XLMWithLMHeadModel:()=>n.XLMWithLMHeadModel,XVectorOutput:()=>n.XVectorOutput,YolosFeatureExtractor:()=>o.YolosFeatureExtractor,YolosForObjectDetection:()=>n.YolosForObjectDetection,YolosModel:()=>n.YolosModel,YolosObjectDetectionOutput:()=>n.YolosObjectDetectionOutput,YolosPreTrainedModel:()=>n.YolosPreTrainedModel,ZeroShotAudioClassificationPipeline:()=>t.ZeroShotAudioClassificationPipeline,ZeroShotClassificationPipeline:()=>t.ZeroShotClassificationPipeline,ZeroShotImageClassificationPipeline:()=>t.ZeroShotImageClassificationPipeline,ZeroShotObjectDetectionPipeline:()=>t.ZeroShotObjectDetectionPipeline,bankers_round:()=>c.bankers_round,cat:()=>u.cat,cos_sim:()=>c.cos_sim,dot:()=>c.dot,dynamicTimeWarping:()=>u.dynamicTimeWarping,env:()=>e.env,full:()=>u.full,full_like:()=>u.full_like,getPerf:()=>n.getPerf,getTopItems:()=>c.getTopItems,hanning:()=>l.hanning,interpolate:()=>u.interpolate,interpolate_4d:()=>u.interpolate_4d,interpolate_data:()=>c.interpolate_data,layer_norm:()=>u.layer_norm,log_softmax:()=>c.log_softmax,magnitude:()=>c.magnitude,max:()=>c.max,mean:()=>u.mean,mean_pooling:()=>u.mean_pooling,medianFilter:()=>c.medianFilter,mel_filter_bank:()=>l.mel_filter_bank,min:()=>c.min,ones:()=>u.ones,ones_like:()=>u.ones_like,permute:()=>u.permute,permute_data:()=>c.permute_data,pipeline:()=>t.pipeline,quantize_embeddings:()=>u.quantize_embeddings,read_audio:()=>l.read_audio,round:()=>c.round,softmax:()=>c.softmax,spectrogram:()=>l.spectrogram,stack:()=>u.stack,std_mean:()=>u.std_mean,window_function:()=>l.window_function,zeros:()=>u.zeros,zeros_like:()=>u.zeros_like});var e=i(/*! ./env.js */"./src/env.js"),t=i(/*! ./pipelines.js */"./src/pipelines.js"),n=i(/*! ./models.js */"./src/models.js"),r=i(/*! ./tokenizers.js */"./src/tokenizers.js"),o=i(/*! ./processors.js */"./src/processors.js"),a=i(/*! ./configs.js */"./src/configs.js"),l=i(/*! ./utils/audio.js */"./src/utils/audio.js"),d=i(/*! ./utils/image.js */"./src/utils/image.js"),u=i(/*! ./utils/tensor.js */"./src/utils/tensor.js"),c=i(/*! ./utils/maths.js */"./src/utils/maths.js"),p=i(/*! ./generation/streamers.js */"./src/generation/streamers.js")})();var o=s.ASTFeatureExtractor,a=s.ASTForAudioClassification,l=s.ASTModel,d=s.ASTPreTrainedModel,u=s.AlbertForMaskedLM,c=s.AlbertForQuestionAnswering,p=s.AlbertForSequenceClassification,h=s.AlbertModel,f=s.AlbertPreTrainedModel,m=s.AlbertTokenizer,g=s.AudioClassificationPipeline,_=s.AutoConfig,w=s.AutoModel,y=s.AutoModelForAudioClassification,b=s.AutoModelForAudioFrameClassification,v=s.AutoModelForCTC,x=s.AutoModelForCausalLM,M=s.AutoModelForDepthEstimation,T=s.AutoModelForDocumentQuestionAnswering,k=s.AutoModelForImageClassification,$=s.AutoModelForImageFeatureExtraction,S=s.AutoModelForImageMatting,C=s.AutoModelForImageSegmentation,P=s.AutoModelForImageToImage,E=s.AutoModelForMaskGeneration,A=s.AutoModelForMaskedLM,F=s.AutoModelForObjectDetection,I=s.AutoModelForQuestionAnswering,z=s.AutoModelForSemanticSegmentation,B=s.AutoModelForSeq2SeqLM,O=s.AutoModelForSequenceClassification,L=s.AutoModelForSpeechSeq2Seq,D=s.AutoModelForTextToSpectrogram,R=s.AutoModelForTextToWaveform,N=s.AutoModelForTokenClassification,V=s.AutoModelForVision2Seq,j=s.AutoModelForXVector,U=s.AutoModelForZeroShotObjectDetection,G=s.AutoProcessor,q=s.AutoTokenizer,W=s.AutomaticSpeechRecognitionPipeline,H=s.BartForConditionalGeneration,X=s.BartForSequenceClassification,Q=s.BartModel,K=s.BartPretrainedModel,Y=s.BartTokenizer,Z=s.BaseModelOutput,J=s.BaseStreamer,ee=s.BeitFeatureExtractor,te=s.BeitForImageClassification,ne=s.BeitModel,re=s.BeitPreTrainedModel,ie=s.BertForMaskedLM,se=s.BertForQuestionAnswering,oe=s.BertForSequenceClassification,ae=s.BertForTokenClassification,le=s.BertModel,de=s.BertPreTrainedModel,ue=s.BertTokenizer,ce=s.BitImageProcessor,pe=s.BlenderbotForConditionalGeneration,he=s.BlenderbotModel,fe=s.BlenderbotPreTrainedModel,me=s.BlenderbotSmallForConditionalGeneration,ge=s.BlenderbotSmallModel,_e=s.BlenderbotSmallPreTrainedModel,we=s.BlenderbotSmallTokenizer,ye=s.BlenderbotTokenizer,be=s.BloomForCausalLM,ve=s.BloomModel,xe=s.BloomPreTrainedModel,Me=s.BloomTokenizer,Te=s.CLIPFeatureExtractor,ke=s.CLIPImageProcessor,$e=s.CLIPModel,Se=s.CLIPPreTrainedModel,Ce=s.CLIPSegForImageSegmentation,Pe=s.CLIPSegModel,Ee=s.CLIPSegPreTrainedModel,Ae=s.CLIPTextModelWithProjection,Fe=s.CLIPTokenizer,Ie=s.CLIPVisionModelWithProjection,ze=s.CamembertForMaskedLM,Be=s.CamembertForQuestionAnswering,Oe=s.CamembertForSequenceClassification,Le=s.CamembertForTokenClassification,De=s.CamembertModel,Re=s.CamembertPreTrainedModel,Ne=s.CamembertTokenizer,Ve=s.CausalLMOutput,je=s.CausalLMOutputWithPast,Ue=s.ChineseCLIPFeatureExtractor,Ge=s.ChineseCLIPModel,qe=s.ChineseCLIPPreTrainedModel,We=s.ClapAudioModelWithProjection,He=s.ClapFeatureExtractor,Xe=s.ClapModel,Qe=s.ClapPreTrainedModel,Ke=s.ClapTextModelWithProjection,Ye=s.CodeGenForCausalLM,Ze=s.CodeGenModel,Je=s.CodeGenPreTrainedModel,et=s.CodeGenTokenizer,tt=s.CodeLlamaTokenizer,nt=s.CohereTokenizer,rt=s.ConvBertForMaskedLM,it=s.ConvBertForQuestionAnswering,st=s.ConvBertForSequenceClassification,ot=s.ConvBertForTokenClassification,at=s.ConvBertModel,lt=s.ConvBertPreTrainedModel,dt=s.ConvBertTokenizer,ut=s.ConvNextFeatureExtractor,ct=s.ConvNextForImageClassification,pt=s.ConvNextImageProcessor,ht=s.ConvNextModel,ft=s.ConvNextPreTrainedModel,mt=s.ConvNextV2ForImageClassification,gt=s.ConvNextV2Model,_t=s.ConvNextV2PreTrainedModel,wt=s.DPTFeatureExtractor,yt=s.DPTForDepthEstimation,bt=s.DPTImageProcessor,vt=s.DPTModel,xt=s.DPTPreTrainedModel,Mt=s.DebertaForMaskedLM,Tt=s.DebertaForQuestionAnswering,kt=s.DebertaForSequenceClassification,$t=s.DebertaForTokenClassification,St=s.DebertaModel,Ct=s.DebertaPreTrainedModel,Pt=s.DebertaTokenizer,Et=s.DebertaV2ForMaskedLM,At=s.DebertaV2ForQuestionAnswering,Ft=s.DebertaV2ForSequenceClassification,It=s.DebertaV2ForTokenClassification,zt=s.DebertaV2Model,Bt=s.DebertaV2PreTrainedModel,Ot=s.DebertaV2Tokenizer,Lt=s.DeiTFeatureExtractor,Dt=s.DeiTForImageClassification,Rt=s.DeiTModel,Nt=s.DeiTPreTrainedModel,Vt=s.DepthAnythingForDepthEstimation,jt=s.DepthAnythingPreTrainedModel,Ut=s.DepthEstimationPipeline,Gt=s.DetrFeatureExtractor,qt=s.DetrForObjectDetection,Wt=s.DetrForSegmentation,Ht=s.DetrModel,Xt=s.DetrObjectDetectionOutput,Qt=s.DetrPreTrainedModel,Kt=s.DetrSegmentationOutput,Yt=s.Dinov2ForImageClassification,Zt=s.Dinov2Model,Jt=s.Dinov2PreTrainedModel,en=s.DistilBertForMaskedLM,tn=s.DistilBertForQuestionAnswering,nn=s.DistilBertForSequenceClassification,rn=s.DistilBertForTokenClassification,sn=s.DistilBertModel,on=s.DistilBertPreTrainedModel,an=s.DistilBertTokenizer,ln=s.DocumentQuestionAnsweringPipeline,dn=s.DonutFeatureExtractor,un=s.DonutSwinModel,cn=s.DonutSwinPreTrainedModel,pn=s.EfficientNetForImageClassification,hn=s.EfficientNetImageProcessor,fn=s.EfficientNetModel,mn=s.EfficientNetPreTrainedModel,gn=s.ElectraForMaskedLM,_n=s.ElectraForQuestionAnswering,wn=s.ElectraForSequenceClassification,yn=s.ElectraForTokenClassification,bn=s.ElectraModel,vn=s.ElectraPreTrainedModel,xn=s.ElectraTokenizer,Mn=s.EsmForMaskedLM,Tn=s.EsmForSequenceClassification,kn=s.EsmForTokenClassification,$n=s.EsmModel,Sn=s.EsmPreTrainedModel,Cn=s.EsmTokenizer,Pn=s.FFT,En=s.FalconForCausalLM,An=s.FalconModel,Fn=s.FalconPreTrainedModel,In=s.FalconTokenizer,zn=s.FeatureExtractionPipeline,Bn=s.FeatureExtractor,On=s.FillMaskPipeline,Ln=s.GLPNFeatureExtractor,Dn=s.GLPNForDepthEstimation,Rn=s.GLPNModel,Nn=s.GLPNPreTrainedModel,Vn=s.GPT2LMHeadModel,jn=s.GPT2Model,Un=s.GPT2PreTrainedModel,Gn=s.GPT2Tokenizer,qn=s.GPTBigCodeForCausalLM,Wn=s.GPTBigCodeModel,Hn=s.GPTBigCodePreTrainedModel,Xn=s.GPTJForCausalLM,Qn=s.GPTJModel,Kn=s.GPTJPreTrainedModel,Yn=s.GPTNeoForCausalLM,Zn=s.GPTNeoModel,Jn=s.GPTNeoPreTrainedModel,er=s.GPTNeoXForCausalLM,tr=s.GPTNeoXModel,nr=s.GPTNeoXPreTrainedModel,rr=s.GPTNeoXTokenizer,ir=s.GemmaTokenizer,sr=s.Grok1Tokenizer,or=s.HerbertTokenizer,ar=s.HubertForCTC,lr=s.HubertForSequenceClassification,dr=s.HubertModel,ur=s.HubertPreTrainedModel,cr=s.ImageClassificationPipeline,pr=s.ImageFeatureExtractionPipeline,hr=s.ImageFeatureExtractor,fr=s.ImageMattingOutput,mr=s.ImageSegmentationPipeline,gr=s.ImageToImagePipeline,_r=s.ImageToTextPipeline,wr=s.LlamaForCausalLM,yr=s.LlamaModel,br=s.LlamaPreTrainedModel,vr=s.LlamaTokenizer,xr=s.LlavaForConditionalGeneration,Mr=s.LlavaPreTrainedModel,Tr=s.LongT5ForConditionalGeneration,kr=s.LongT5Model,$r=s.LongT5PreTrainedModel,Sr=s.M2M100ForConditionalGeneration,Cr=s.M2M100Model,Pr=s.M2M100PreTrainedModel,Er=s.M2M100Tokenizer,Ar=s.MBart50Tokenizer,Fr=s.MBartForCausalLM,Ir=s.MBartForConditionalGeneration,zr=s.MBartForSequenceClassification,Br=s.MBartModel,Or=s.MBartPreTrainedModel,Lr=s.MBartTokenizer,Dr=s.MPNetForMaskedLM,Rr=s.MPNetForQuestionAnswering,Nr=s.MPNetForSequenceClassification,Vr=s.MPNetForTokenClassification,jr=s.MPNetModel,Ur=s.MPNetPreTrainedModel,Gr=s.MPNetTokenizer,qr=s.MT5ForConditionalGeneration,Wr=s.MT5Model,Hr=s.MT5PreTrainedModel,Xr=s.MarianMTModel,Qr=s.MarianModel,Kr=s.MarianPreTrainedModel,Yr=s.MarianTokenizer,Zr=s.MaskedLMOutput,Jr=s.MistralForCausalLM,ei=s.MistralModel,ti=s.MistralPreTrainedModel,ni=s.MobileBertForMaskedLM,ri=s.MobileBertForQuestionAnswering,ii=s.MobileBertForSequenceClassification,si=s.MobileBertModel,oi=s.MobileBertPreTrainedModel,ai=s.MobileBertTokenizer,li=s.MobileViTFeatureExtractor,di=s.MobileViTForImageClassification,ui=s.MobileViTModel,ci=s.MobileViTPreTrainedModel,pi=s.ModelOutput,hi=s.MptForCausalLM,fi=s.MptModel,mi=s.MptPreTrainedModel,gi=s.MusicgenForCausalLM,_i=s.MusicgenForConditionalGeneration,wi=s.MusicgenModel,yi=s.MusicgenPreTrainedModel,bi=s.NllbTokenizer,vi=s.NomicBertModel,xi=s.NomicBertPreTrainedModel,Mi=s.NougatImageProcessor,Ti=s.NougatTokenizer,ki=s.OPTForCausalLM,$i=s.OPTModel,Si=s.OPTPreTrainedModel,Ci=s.ObjectDetectionPipeline,Pi=s.OwlViTFeatureExtractor,Ei=s.OwlViTForObjectDetection,Ai=s.OwlViTModel,Fi=s.OwlViTPreTrainedModel,Ii=s.OwlViTProcessor,zi=s.Owlv2ForObjectDetection,Bi=s.Owlv2ImageProcessor,Oi=s.Owlv2Model,Li=s.Owlv2PreTrainedModel,Di=s.PhiForCausalLM,Ri=s.PhiModel,Ni=s.PhiPreTrainedModel,Vi=s.Pipeline,ji=s.PreTrainedModel,Ui=s.PreTrainedTokenizer,Gi=s.PretrainedConfig,qi=s.PretrainedMixin,Wi=s.Processor,Hi=s.QuestionAnsweringModelOutput,Xi=s.QuestionAnsweringPipeline,Qi=s.Qwen2ForCausalLM,Ki=s.Qwen2Model,Yi=s.Qwen2PreTrainedModel,Zi=s.Qwen2Tokenizer,Ji=s.RawImage,es=s.ResNetForImageClassification,ts=s.ResNetModel,ns=s.ResNetPreTrainedModel,rs=s.RoFormerForMaskedLM,is=s.RoFormerForQuestionAnswering,ss=s.RoFormerForSequenceClassification,os=s.RoFormerForTokenClassification,as=s.RoFormerModel,ls=s.RoFormerPreTrainedModel,ds=s.RoFormerTokenizer,us=s.RobertaForMaskedLM,cs=s.RobertaForQuestionAnswering,ps=s.RobertaForSequenceClassification,hs=s.RobertaForTokenClassification,fs=s.RobertaModel,ms=s.RobertaPreTrainedModel,gs=s.RobertaTokenizer,_s=s.SamImageProcessor,ws=s.SamImageSegmentationOutput,ys=s.SamModel,bs=s.SamPreTrainedModel,vs=s.SamProcessor,xs=s.SeamlessM4TFeatureExtractor,Ms=s.SegformerFeatureExtractor,Ts=s.SegformerForImageClassification,ks=s.SegformerForSemanticSegmentation,$s=s.SegformerModel,Ss=s.SegformerPreTrainedModel,Cs=s.Seq2SeqLMOutput,Ps=s.SequenceClassifierOutput,Es=s.SiglipImageProcessor,As=s.SiglipModel,Fs=s.SiglipPreTrainedModel,Is=s.SiglipTextModel,zs=s.SiglipTokenizer,Bs=s.SiglipVisionModel,Os=s.SpeechT5FeatureExtractor,Ls=s.SpeechT5ForSpeechToText,Ds=s.SpeechT5ForTextToSpeech,Rs=s.SpeechT5HifiGan,Ns=s.SpeechT5Model,Vs=s.SpeechT5PreTrainedModel,js=s.SpeechT5Processor,Us=s.SpeechT5Tokenizer,Gs=s.SqueezeBertForMaskedLM,qs=s.SqueezeBertForQuestionAnswering,Ws=s.SqueezeBertForSequenceClassification,Hs=s.SqueezeBertModel,Xs=s.SqueezeBertPreTrainedModel,Qs=s.SqueezeBertTokenizer,Ks=s.StableLmForCausalLM,Ys=s.StableLmModel,Zs=s.StableLmPreTrainedModel,Js=s.Starcoder2ForCausalLM,eo=s.Starcoder2Model,to=s.Starcoder2PreTrainedModel,no=s.SummarizationPipeline,ro=s.Swin2SRForImageSuperResolution,io=s.Swin2SRImageProcessor,so=s.Swin2SRModel,oo=s.Swin2SRPreTrainedModel,ao=s.SwinForImageClassification,lo=s.SwinModel,uo=s.SwinPreTrainedModel,co=s.T5ForConditionalGeneration,po=s.T5Model,ho=s.T5PreTrainedModel,fo=s.T5Tokenizer,mo=s.TableTransformerForObjectDetection,go=s.TableTransformerModel,_o=s.TableTransformerObjectDetectionOutput,wo=s.TableTransformerPreTrainedModel,yo=s.Tensor,bo=s.Text2TextGenerationPipeline,vo=s.TextClassificationPipeline,xo=s.TextGenerationPipeline,Mo=s.TextToAudioPipeline,To=s.TokenClassificationPipeline,ko=s.TokenClassifierOutput,$o=s.TokenizerModel,So=s.TrOCRForCausalLM,Co=s.TrOCRPreTrainedModel,Po=s.TranslationPipeline,Eo=s.UniSpeechForCTC,Ao=s.UniSpeechForSequenceClassification,Fo=s.UniSpeechModel,Io=s.UniSpeechPreTrainedModel,zo=s.UniSpeechSatForAudioFrameClassification,Bo=s.UniSpeechSatForCTC,Oo=s.UniSpeechSatForSequenceClassification,Lo=s.UniSpeechSatModel,Do=s.UniSpeechSatPreTrainedModel,Ro=s.ViTFeatureExtractor,No=s.ViTForImageClassification,Vo=s.ViTImageProcessor,jo=s.ViTModel,Uo=s.ViTPreTrainedModel,Go=s.VisionEncoderDecoderModel,qo=s.VitMatteForImageMatting,Wo=s.VitMatteImageProcessor,Ho=s.VitMattePreTrainedModel,Xo=s.VitsModel,Qo=s.VitsModelOutput,Ko=s.VitsPreTrainedModel,Yo=s.VitsTokenizer,Zo=s.Wav2Vec2BertForCTC,Jo=s.Wav2Vec2BertForSequenceClassification,ea=s.Wav2Vec2BertModel,ta=s.Wav2Vec2BertPreTrainedModel,na=s.Wav2Vec2CTCTokenizer,ra=s.Wav2Vec2FeatureExtractor,ia=s.Wav2Vec2ForAudioFrameClassification,sa=s.Wav2Vec2ForCTC,oa=s.Wav2Vec2ForSequenceClassification,aa=s.Wav2Vec2Model,la=s.Wav2Vec2PreTrainedModel,da=s.Wav2Vec2ProcessorWithLM,ua=s.WavLMForAudioFrameClassification,ca=s.WavLMForCTC,pa=s.WavLMForSequenceClassification,ha=s.WavLMForXVector,fa=s.WavLMModel,ma=s.WavLMPreTrainedModel,ga=s.WhisperFeatureExtractor,_a=s.WhisperForConditionalGeneration,wa=s.WhisperModel,ya=s.WhisperPreTrainedModel,ba=s.WhisperProcessor,va=s.WhisperTokenizer,xa=s.XLMForQuestionAnswering,Ma=s.XLMForSequenceClassification,Ta=s.XLMForTokenClassification,ka=s.XLMModel,$a=s.XLMPreTrainedModel,Sa=s.XLMRobertaForMaskedLM,Ca=s.XLMRobertaForQuestionAnswering,Pa=s.XLMRobertaForSequenceClassification,Ea=s.XLMRobertaForTokenClassification,Aa=s.XLMRobertaModel,Fa=s.XLMRobertaPreTrainedModel,Ia=s.XLMRobertaTokenizer,za=s.XLMTokenizer,Ba=s.XLMWithLMHeadModel,Oa=s.XVectorOutput,La=s.YolosFeatureExtractor,Da=s.YolosForObjectDetection,Ra=s.YolosModel,Na=s.YolosObjectDetectionOutput,Va=s.YolosPreTrainedModel,ja=s.ZeroShotAudioClassificationPipeline,Ua=s.ZeroShotClassificationPipeline,Ga=s.ZeroShotImageClassificationPipeline,qa=s.ZeroShotObjectDetectionPipeline,Wa=s.bankers_round,Ha=s.cat,Xa=s.cos_sim,Qa=s.dot,Ka=s.dynamicTimeWarping,Ya=s.env,Za=s.full,Ja=s.full_like,el=s.getPerf,tl=s.getTopItems,nl=s.hanning,rl=s.interpolate,il=s.interpolate_4d,sl=s.interpolate_data,ol=s.layer_norm,al=s.log_softmax,ll=s.magnitude,dl=s.max,ul=s.mean,cl=s.mean_pooling,pl=s.medianFilter,hl=s.mel_filter_bank,fl=s.min,ml=s.ones,gl=s.ones_like,_l=s.permute,wl=s.permute_data,yl=s.pipeline,bl=s.quantize_embeddings,vl=s.read_audio,xl=s.round,Ml=s.softmax,Tl=s.spectrogram,kl=s.stack,$l=s.std_mean,Sl=s.window_function,Cl=s.zeros,Pl=s.zeros_like;export{o as ASTFeatureExtractor,a as ASTForAudioClassification,l as ASTModel,d as ASTPreTrainedModel,u as AlbertForMaskedLM,c as AlbertForQuestionAnswering,p as AlbertForSequenceClassification,h as AlbertModel,f as AlbertPreTrainedModel,m as AlbertTokenizer,g as AudioClassificationPipeline,_ as AutoConfig,w as AutoModel,y as AutoModelForAudioClassification,b as AutoModelForAudioFrameClassification,v as AutoModelForCTC,x as AutoModelForCausalLM,M as AutoModelForDepthEstimation,T as AutoModelForDocumentQuestionAnswering,k as AutoModelForImageClassification,$ as AutoModelForImageFeatureExtraction,S as AutoModelForImageMatting,C as AutoModelForImageSegmentation,P as AutoModelForImageToImage,E as AutoModelForMaskGeneration,A as AutoModelForMaskedLM,F as AutoModelForObjectDetection,I as AutoModelForQuestionAnswering,z as AutoModelForSemanticSegmentation,B as AutoModelForSeq2SeqLM,O as AutoModelForSequenceClassification,L as AutoModelForSpeechSeq2Seq,D as AutoModelForTextToSpectrogram,R as AutoModelForTextToWaveform,N as AutoModelForTokenClassification,V as AutoModelForVision2Seq,j as AutoModelForXVector,U as AutoModelForZeroShotObjectDetection,G as AutoProcessor,q as AutoTokenizer,W as AutomaticSpeechRecognitionPipeline,H as BartForConditionalGeneration,X as BartForSequenceClassification,Q as BartModel,K as BartPretrainedModel,Y as BartTokenizer,Z as BaseModelOutput,J as BaseStreamer,ee as BeitFeatureExtractor,te as BeitForImageClassification,ne as BeitModel,re as BeitPreTrainedModel,ie as BertForMaskedLM,se as BertForQuestionAnswering,oe as BertForSequenceClassification,ae as BertForTokenClassification,le as BertModel,de as BertPreTrainedModel,ue as BertTokenizer,ce as BitImageProcessor,pe as BlenderbotForConditionalGeneration,he as BlenderbotModel,fe as BlenderbotPreTrainedModel,me as BlenderbotSmallForConditionalGeneration,ge as BlenderbotSmallModel,_e as BlenderbotSmallPreTrainedModel,we as BlenderbotSmallTokenizer,ye as BlenderbotTokenizer,be as BloomForCausalLM,ve as BloomModel,xe as BloomPreTrainedModel,Me as BloomTokenizer,Te as CLIPFeatureExtractor,ke as CLIPImageProcessor,$e as CLIPModel,Se as CLIPPreTrainedModel,Ce as CLIPSegForImageSegmentation,Pe as CLIPSegModel,Ee as CLIPSegPreTrainedModel,Ae as CLIPTextModelWithProjection,Fe as CLIPTokenizer,Ie as CLIPVisionModelWithProjection,ze as CamembertForMaskedLM,Be as CamembertForQuestionAnswering,Oe as CamembertForSequenceClassification,Le as CamembertForTokenClassification,De as CamembertModel,Re as CamembertPreTrainedModel,Ne as CamembertTokenizer,Ve as CausalLMOutput,je as CausalLMOutputWithPast,Ue as ChineseCLIPFeatureExtractor,Ge as ChineseCLIPModel,qe as ChineseCLIPPreTrainedModel,We as ClapAudioModelWithProjection,He as ClapFeatureExtractor,Xe as ClapModel,Qe as ClapPreTrainedModel,Ke as ClapTextModelWithProjection,Ye as CodeGenForCausalLM,Ze as CodeGenModel,Je as CodeGenPreTrainedModel,et as CodeGenTokenizer,tt as CodeLlamaTokenizer,nt as CohereTokenizer,rt as ConvBertForMaskedLM,it as ConvBertForQuestionAnswering,st as ConvBertForSequenceClassification,ot as ConvBertForTokenClassification,at as ConvBertModel,lt as ConvBertPreTrainedModel,dt as ConvBertTokenizer,ut as ConvNextFeatureExtractor,ct as ConvNextForImageClassification,pt as ConvNextImageProcessor,ht as ConvNextModel,ft as ConvNextPreTrainedModel,mt as ConvNextV2ForImageClassification,gt as ConvNextV2Model,_t as ConvNextV2PreTrainedModel,wt as DPTFeatureExtractor,yt as DPTForDepthEstimation,bt as DPTImageProcessor,vt as DPTModel,xt as DPTPreTrainedModel,Mt as DebertaForMaskedLM,Tt as DebertaForQuestionAnswering,kt as DebertaForSequenceClassification,$t as DebertaForTokenClassification,St as DebertaModel,Ct as DebertaPreTrainedModel,Pt as DebertaTokenizer,Et as DebertaV2ForMaskedLM,At as DebertaV2ForQuestionAnswering,Ft as DebertaV2ForSequenceClassification,It as DebertaV2ForTokenClassification,zt as DebertaV2Model,Bt as DebertaV2PreTrainedModel,Ot as DebertaV2Tokenizer,Lt as DeiTFeatureExtractor,Dt as DeiTForImageClassification,Rt as DeiTModel,Nt as DeiTPreTrainedModel,Vt as DepthAnythingForDepthEstimation,jt as DepthAnythingPreTrainedModel,Ut as DepthEstimationPipeline,Gt as DetrFeatureExtractor,qt as DetrForObjectDetection,Wt as DetrForSegmentation,Ht as DetrModel,Xt as DetrObjectDetectionOutput,Qt as DetrPreTrainedModel,Kt as DetrSegmentationOutput,Yt as Dinov2ForImageClassification,Zt as Dinov2Model,Jt as Dinov2PreTrainedModel,en as DistilBertForMaskedLM,tn as DistilBertForQuestionAnswering,nn as DistilBertForSequenceClassification,rn as DistilBertForTokenClassification,sn as DistilBertModel,on as DistilBertPreTrainedModel,an as DistilBertTokenizer,ln as DocumentQuestionAnsweringPipeline,dn as DonutFeatureExtractor,un as DonutSwinModel,cn as DonutSwinPreTrainedModel,pn as EfficientNetForImageClassification,hn as EfficientNetImageProcessor,fn as EfficientNetModel,mn as EfficientNetPreTrainedModel,gn as ElectraForMaskedLM,_n as ElectraForQuestionAnswering,wn as ElectraForSequenceClassification,yn as ElectraForTokenClassification,bn as ElectraModel,vn as ElectraPreTrainedModel,xn as ElectraTokenizer,Mn as EsmForMaskedLM,Tn as EsmForSequenceClassification,kn as EsmForTokenClassification,$n as EsmModel,Sn as EsmPreTrainedModel,Cn as EsmTokenizer,Pn as FFT,En as FalconForCausalLM,An as FalconModel,Fn as FalconPreTrainedModel,In as FalconTokenizer,zn as FeatureExtractionPipeline,Bn as FeatureExtractor,On as FillMaskPipeline,Ln as GLPNFeatureExtractor,Dn as GLPNForDepthEstimation,Rn as GLPNModel,Nn as GLPNPreTrainedModel,Vn as GPT2LMHeadModel,jn as GPT2Model,Un as GPT2PreTrainedModel,Gn as GPT2Tokenizer,qn as GPTBigCodeForCausalLM,Wn as GPTBigCodeModel,Hn as GPTBigCodePreTrainedModel,Xn as GPTJForCausalLM,Qn as GPTJModel,Kn as GPTJPreTrainedModel,Yn as GPTNeoForCausalLM,Zn as GPTNeoModel,Jn as GPTNeoPreTrainedModel,er as GPTNeoXForCausalLM,tr as GPTNeoXModel,nr as GPTNeoXPreTrainedModel,rr as GPTNeoXTokenizer,ir as GemmaTokenizer,sr as Grok1Tokenizer,or as HerbertTokenizer,ar as HubertForCTC,lr as HubertForSequenceClassification,dr as HubertModel,ur as HubertPreTrainedModel,cr as ImageClassificationPipeline,pr as ImageFeatureExtractionPipeline,hr as ImageFeatureExtractor,fr as ImageMattingOutput,mr as ImageSegmentationPipeline,gr as ImageToImagePipeline,_r as ImageToTextPipeline,wr as LlamaForCausalLM,yr as LlamaModel,br as LlamaPreTrainedModel,vr as LlamaTokenizer,xr as LlavaForConditionalGeneration,Mr as LlavaPreTrainedModel,Tr as LongT5ForConditionalGeneration,kr as LongT5Model,$r as LongT5PreTrainedModel,Sr as M2M100ForConditionalGeneration,Cr as M2M100Model,Pr as M2M100PreTrainedModel,Er as M2M100Tokenizer,Ar as MBart50Tokenizer,Fr as MBartForCausalLM,Ir as MBartForConditionalGeneration,zr as MBartForSequenceClassification,Br as MBartModel,Or as MBartPreTrainedModel,Lr as MBartTokenizer,Dr as MPNetForMaskedLM,Rr as MPNetForQuestionAnswering,Nr as MPNetForSequenceClassification,Vr as MPNetForTokenClassification,jr as MPNetModel,Ur as MPNetPreTrainedModel,Gr as MPNetTokenizer,qr as MT5ForConditionalGeneration,Wr as MT5Model,Hr as MT5PreTrainedModel,Xr as MarianMTModel,Qr as MarianModel,Kr as MarianPreTrainedModel,Yr as MarianTokenizer,Zr as MaskedLMOutput,Jr as MistralForCausalLM,ei as MistralModel,ti as MistralPreTrainedModel,ni as MobileBertForMaskedLM,ri as MobileBertForQuestionAnswering,ii as MobileBertForSequenceClassification,si as MobileBertModel,oi as MobileBertPreTrainedModel,ai as MobileBertTokenizer,li as MobileViTFeatureExtractor,di as MobileViTForImageClassification,ui as MobileViTModel,ci as MobileViTPreTrainedModel,pi as ModelOutput,hi as MptForCausalLM,fi as MptModel,mi as MptPreTrainedModel,gi as MusicgenForCausalLM,_i as MusicgenForConditionalGeneration,wi as MusicgenModel,yi as MusicgenPreTrainedModel,bi as NllbTokenizer,vi as NomicBertModel,xi as NomicBertPreTrainedModel,Mi as NougatImageProcessor,Ti as NougatTokenizer,ki as OPTForCausalLM,$i as OPTModel,Si as OPTPreTrainedModel,Ci as ObjectDetectionPipeline,Pi as OwlViTFeatureExtractor,Ei as OwlViTForObjectDetection,Ai as OwlViTModel,Fi as OwlViTPreTrainedModel,Ii as OwlViTProcessor,zi as Owlv2ForObjectDetection,Bi as Owlv2ImageProcessor,Oi as Owlv2Model,Li as Owlv2PreTrainedModel,Di as PhiForCausalLM,Ri as PhiModel,Ni as PhiPreTrainedModel,Vi as Pipeline,ji as PreTrainedModel,Ui as PreTrainedTokenizer,Gi as PretrainedConfig,qi as PretrainedMixin,Wi as Processor,Hi as QuestionAnsweringModelOutput,Xi as QuestionAnsweringPipeline,Qi as Qwen2ForCausalLM,Ki as Qwen2Model,Yi as Qwen2PreTrainedModel,Zi as Qwen2Tokenizer,Ji as RawImage,es as ResNetForImageClassification,ts as ResNetModel,ns as ResNetPreTrainedModel,rs as RoFormerForMaskedLM,is as RoFormerForQuestionAnswering,ss as RoFormerForSequenceClassification,os as RoFormerForTokenClassification,as as RoFormerModel,ls as RoFormerPreTrainedModel,ds as RoFormerTokenizer,us as RobertaForMaskedLM,cs as RobertaForQuestionAnswering,ps as RobertaForSequenceClassification,hs as RobertaForTokenClassification,fs as RobertaModel,ms as RobertaPreTrainedModel,gs as RobertaTokenizer,_s as SamImageProcessor,ws as SamImageSegmentationOutput,ys as SamModel,bs as SamPreTrainedModel,vs as SamProcessor,xs as SeamlessM4TFeatureExtractor,Ms as SegformerFeatureExtractor,Ts as SegformerForImageClassification,ks as SegformerForSemanticSegmentation,$s as SegformerModel,Ss as SegformerPreTrainedModel,Cs as Seq2SeqLMOutput,Ps as SequenceClassifierOutput,Es as SiglipImageProcessor,As as SiglipModel,Fs as SiglipPreTrainedModel,Is as SiglipTextModel,zs as SiglipTokenizer,Bs as SiglipVisionModel,Os as SpeechT5FeatureExtractor,Ls as SpeechT5ForSpeechToText,Ds as SpeechT5ForTextToSpeech,Rs as SpeechT5HifiGan,Ns as SpeechT5Model,Vs as SpeechT5PreTrainedModel,js as SpeechT5Processor,Us as SpeechT5Tokenizer,Gs as SqueezeBertForMaskedLM,qs as SqueezeBertForQuestionAnswering,Ws as SqueezeBertForSequenceClassification,Hs as SqueezeBertModel,Xs as SqueezeBertPreTrainedModel,Qs as SqueezeBertTokenizer,Ks as StableLmForCausalLM,Ys as StableLmModel,Zs as StableLmPreTrainedModel,Js as Starcoder2ForCausalLM,eo as Starcoder2Model,to as Starcoder2PreTrainedModel,no as SummarizationPipeline,ro as Swin2SRForImageSuperResolution,io as Swin2SRImageProcessor,so as Swin2SRModel,oo as Swin2SRPreTrainedModel,ao as SwinForImageClassification,lo as SwinModel,uo as SwinPreTrainedModel,co as T5ForConditionalGeneration,po as T5Model,ho as T5PreTrainedModel,fo as T5Tokenizer,mo as TableTransformerForObjectDetection,go as TableTransformerModel,_o as TableTransformerObjectDetectionOutput,wo as TableTransformerPreTrainedModel,yo as Tensor,bo as Text2TextGenerationPipeline,vo as TextClassificationPipeline,xo as TextGenerationPipeline,Mo as TextToAudioPipeline,To as TokenClassificationPipeline,ko as TokenClassifierOutput,$o as TokenizerModel,So as TrOCRForCausalLM,Co as TrOCRPreTrainedModel,Po as TranslationPipeline,Eo as UniSpeechForCTC,Ao as UniSpeechForSequenceClassification,Fo as UniSpeechModel,Io as UniSpeechPreTrainedModel,zo as UniSpeechSatForAudioFrameClassification,Bo as UniSpeechSatForCTC,Oo as UniSpeechSatForSequenceClassification,Lo as UniSpeechSatModel,Do as UniSpeechSatPreTrainedModel,Ro as ViTFeatureExtractor,No as ViTForImageClassification,Vo as ViTImageProcessor,jo as ViTModel,Uo as ViTPreTrainedModel,Go as VisionEncoderDecoderModel,qo as VitMatteForImageMatting,Wo as VitMatteImageProcessor,Ho as VitMattePreTrainedModel,Xo as VitsModel,Qo as VitsModelOutput,Ko as VitsPreTrainedModel,Yo as VitsTokenizer,Zo as Wav2Vec2BertForCTC,Jo as Wav2Vec2BertForSequenceClassification,ea as Wav2Vec2BertModel,ta as Wav2Vec2BertPreTrainedModel,na as Wav2Vec2CTCTokenizer,ra as Wav2Vec2FeatureExtractor,ia as Wav2Vec2ForAudioFrameClassification,sa as Wav2Vec2ForCTC,oa as Wav2Vec2ForSequenceClassification,aa as Wav2Vec2Model,la as Wav2Vec2PreTrainedModel,da as Wav2Vec2ProcessorWithLM,ua as WavLMForAudioFrameClassification,ca as WavLMForCTC,pa as WavLMForSequenceClassification,ha as WavLMForXVector,fa as WavLMModel,ma as WavLMPreTrainedModel,ga as WhisperFeatureExtractor,_a as WhisperForConditionalGeneration,wa as WhisperModel,ya as WhisperPreTrainedModel,ba as WhisperProcessor,va as WhisperTokenizer,xa as XLMForQuestionAnswering,Ma as XLMForSequenceClassification,Ta as XLMForTokenClassification,ka as XLMModel,$a as XLMPreTrainedModel,Sa as XLMRobertaForMaskedLM,Ca as XLMRobertaForQuestionAnswering,Pa as XLMRobertaForSequenceClassification,Ea as XLMRobertaForTokenClassification,Aa as XLMRobertaModel,Fa as XLMRobertaPreTrainedModel,Ia as XLMRobertaTokenizer,za as XLMTokenizer,Ba as XLMWithLMHeadModel,Oa as XVectorOutput,La as YolosFeatureExtractor,Da as YolosForObjectDetection,Ra as YolosModel,Na as YolosObjectDetectionOutput,Va as YolosPreTrainedModel,ja as ZeroShotAudioClassificationPipeline,Ua as ZeroShotClassificationPipeline,Ga as ZeroShotImageClassificationPipeline,qa as ZeroShotObjectDetectionPipeline,Wa as bankers_round,Ha as cat,Xa as cos_sim,Qa as dot,Ka as dynamicTimeWarping,Ya as env,Za as full,Ja as full_like,el as getPerf,tl as getTopItems,nl as hanning,rl as interpolate,il as interpolate_4d,sl as interpolate_data,ol as layer_norm,al as log_softmax,ll as magnitude,dl as max,ul as mean,cl as mean_pooling,pl as medianFilter,hl as mel_filter_bank,fl as min,ml as ones,gl as ones_like,_l as permute,wl as permute_data,yl as pipeline,bl as quantize_embeddings,vl as read_audio,xl as round,Ml as softmax,Tl as spectrogram,kl as stack,$l as std_mean,Sl as window_function,Cl as zeros,Pl as zeros_like};
//# sourceMappingURL=transformers.min.js.map